{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "yimWu26AtZCX",
        "Qo-v8SV_uC_9",
        "qssdQnif4hDM",
        "B38yfKyyAfqK",
        "hMwP-ocXKfcs",
        "A4wdEpcbSsya",
        "6x9icM6GXPQm",
        "Xe5Vfzgfh5Hb",
        "hvlo3m6zpR54",
        "WRbqpIOUtTTe",
        "IhgMoIuZToQF",
        "NhaYKphoW7ix"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# https://grok.com/c/71470a46-9c00-4561-8b8d-357bc30a3276"
      ],
      "metadata": {
        "id": "k4U881g1IcVY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# To validate/expand (e.g., VIF for multicollinearity, mutual information for categoricals)\n",
        "\n",
        "This code computes VIF (multicollinearity, VIF >5 bad), mutual information (for categoricals, >0.2 good), RFE (wrapper ranking), and Lasso (embedded coefficients)."
      ],
      "metadata": {
        "id": "yimWu26AtZCX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_selection import mutual_info_regression, RFE\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "from sklearn.linear_model import LinearRegression, Lasso\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "import numpy as np\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/englian1123/KL-High-Rise-Data/refs/heads/main/KLHighRise.csv\"\n",
        "df = pd.read_csv(url)\n",
        "df.rename(columns={'TransactionPrice  ': 'TransactionPrice'}, inplace=True)\n",
        "\n",
        "# More robust extraction of numerical values from 'ParcelArea'\n",
        "df['Parcel_sq_m'] = df['ParcelArea'].astype(str).str.extract(r'(\\d+\\.?\\d*)')\n",
        "df['Parcel_sq_m'] = pd.to_numeric(df['Parcel_sq_m'], errors='coerce')\n",
        "\n",
        "df['Price_per_sq_m'] = df['TransactionPrice'] / df['Parcel_sq_m']\n",
        "df['Year'] = pd.to_datetime(df['TransactionDate'], format='%b-%y').dt.year\n",
        "\n",
        "# Numerical VIF (multicollinearity)\n",
        "num_df = df[['Parcel_sq_m', 'UnitLevel', 'Year']].copy()\n",
        "\n",
        "# Explicitly convert all columns to numeric, coercing errors\n",
        "for col in num_df.columns:\n",
        "    num_df[col] = pd.to_numeric(num_df[col], errors='coerce')\n",
        "\n",
        "# Replace infinite values with NaN, then fill all NaN values with the mean of each column\n",
        "num_df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "num_df.fillna(num_df.mean(), inplace=True)\n",
        "\n",
        "\n",
        "vif_data = pd.DataFrame()\n",
        "vif_data[\"feature\"] = num_df.columns\n",
        "vif_data[\"VIF\"] = [variance_inflation_factor(num_df.values, i) for i in range(len(num_df.columns))]\n",
        "print(\"VIF for Numerical Features:\\n\", vif_data)\n",
        "\n",
        "\n",
        "# Mutual Info for categorical (encode first)\n",
        "encoder = OneHotEncoder(sparse_output=False)\n",
        "cat_encoded = encoder.fit_transform(df[['Mukim']])\n",
        "\n",
        "feature_names = encoder.get_feature_names_out()\n",
        "mi = mutual_info_regression(cat_encoded, df['TransactionPrice'])\n",
        "mi_series = pd.Series(mi, index=feature_names).sort_values(ascending=False)\n",
        "print(\"Mutual Information with Price (Categorical):\\n\", mi_series)\n",
        "\n",
        "df_temp = df.copy()\n",
        "df_temp['Tenure_encoded'] = df['Tenure'].map({'Freehold': 1, 'Leasehold': 0})\n",
        "# Manual Target Encoding for SchemeName\n",
        "scheme_mean = df.groupby('SchemeName')['TransactionPrice'].mean().apply(np.log)\n",
        "df_temp['SchemeName_encoded'] = df['SchemeName'].map(scheme_mean)\n",
        "\n",
        "# Calculate Mutual Information\n",
        "# Reshape the features to be 2D arrays\n",
        "tenure_mi = mutual_info_regression(df_temp[['Tenure_encoded']], df_temp['TransactionPrice'], random_state=42)[0]\n",
        "scheme_name_mi = mutual_info_regression(df_temp[['SchemeName_encoded']], df_temp['TransactionPrice'], random_state=42)[0]\n",
        "\n",
        "print(f\"Mutual Information between Tenure and TransactionPrice: {tenure_mi:.4f}\")\n",
        "print(f\"Mutual Information between Scheme_Name_encoded and TransactionPrice: {scheme_name_mi:.4f}\")\n",
        "\n",
        "# Prepare data for RFE and Lasso\n",
        "X = pd.concat([num_df, pd.DataFrame(cat_encoded, columns=feature_names)], axis=1)\n",
        "y = df['TransactionPrice']\n",
        "\n",
        "# Scale features for Lasso\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Wrapper: RFE with LinearRegression (top 5 features)\n",
        "model = LinearRegression()\n",
        "rfe = RFE(model, n_features_to_select=5)\n",
        "rfe.fit(X, y)\n",
        "rfe_ranking = pd.Series(rfe.ranking_, index=X.columns).sort_values()\n",
        "print(\"RFE Ranking (lower better):\\n\", rfe_ranking)\n",
        "\n",
        "# Embedded: Lasso feature importance (coef)\n",
        "lasso = Lasso(alpha=1.0, max_iter=10000) # Increased alpha\n",
        "lasso.fit(X_scaled, y) # Fit Lasso on scaled data\n",
        "lasso_coef = pd.Series(lasso.coef_, index=X.columns).abs().sort_values(ascending=False)\n",
        "print(\"Lasso Coefficients (abs, higher importance):\\n\", lasso_coef)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ou3pa-VjhBYQ",
        "outputId": "01033f38-3ba4-494d-cf0e-1815350cef70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VIF for Numerical Features:\n",
            "        feature       VIF\n",
            "0  Parcel_sq_m  4.356693\n",
            "1    UnitLevel  3.091104\n",
            "2         Year  6.116326\n",
            "Mutual Information with Price (Categorical):\n",
            " Mukim_Mukim Setapak               0.069921\n",
            "Mukim_Mukim Batu                  0.060125\n",
            "Mukim_Mukim Petaling              0.055499\n",
            "Mukim_Mukim Kuala Lumpur          0.041355\n",
            "Mukim_Kuala Lumpur Town Centre    0.021901\n",
            "Mukim_Mukim Cheras                0.005598\n",
            "Mukim_Mukim Ulu Kelang            0.001859\n",
            "Mukim_Mukim Ampang                0.000000\n",
            "dtype: float64\n",
            "Mutual Information between Tenure and TransactionPrice: 0.1047\n",
            "Mutual Information between Scheme_Name_encoded and TransactionPrice: 1.5727\n",
            "RFE Ranking (lower better):\n",
            " Mukim_Kuala Lumpur Town Centre    1\n",
            "Mukim_Mukim Kuala Lumpur          1\n",
            "Mukim_Mukim Batu                  1\n",
            "Mukim_Mukim Ampang                1\n",
            "Mukim_Mukim Setapak               1\n",
            "Mukim_Mukim Petaling              2\n",
            "Mukim_Mukim Cheras                3\n",
            "Parcel_sq_m                       4\n",
            "UnitLevel                         5\n",
            "Year                              6\n",
            "Mukim_Mukim Ulu Kelang            7\n",
            "dtype: int64\n",
            "Lasso Coefficients (abs, higher importance):\n",
            " Parcel_sq_m                       791163.506395\n",
            "UnitLevel                          77490.517545\n",
            "Mukim_Mukim Kuala Lumpur           72106.533824\n",
            "Mukim_Kuala Lumpur Town Centre     65007.354450\n",
            "Mukim_Mukim Setapak                35788.531937\n",
            "Mukim_Mukim Ampang                 16370.028558\n",
            "Mukim_Mukim Cheras                 13316.727552\n",
            "Mukim_Mukim Petaling               12937.057629\n",
            "Mukim_Mukim Batu                    9098.535395\n",
            "Year                                7630.396838\n",
            "Mukim_Mukim Ulu Kelang               916.058636\n",
            "dtype: float64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.225e+12, tolerance: 1.353e+12\n",
            "  model = cd_fast.enet_coordinate_descent(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_selection import RFE, mutual_info_regression\n",
        "from sklearn.linear_model import LinearRegression, Lasso\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "\n",
        "# Load and preprocess\n",
        "url = \"https://raw.githubusercontent.com/englian1123/KL-High-Rise-Data/refs/heads/main/KLHighRise.csv\"\n",
        "df = pd.read_csv(url)\n",
        "df.rename(columns={'TransactionPrice  ': 'TransactionPrice', 'Parcel Area': 'ParcelArea', 'Scheme Name/Area': 'SchemeName'}, inplace=True)\n",
        "df['ParcelArea'] = df['ParcelArea'].astype(str).str.extract(r'(\\d+\\.?\\d*)').astype(np.float32)\n",
        "df['Tenure'] = df['Tenure'].map({'Freehold': 1, 'Leasehold': 0}).fillna(0).astype(np.float32)\n",
        "\n",
        "# Drop low-count Mukims\n",
        "low_count_mukims = ['Mukim Cheras', 'Mukim Ampang', 'Mukim Ulu Kelang']\n",
        "df = df[~df['Mukim'].isin(low_count_mukims)].reset_index(drop=True)\n",
        "\n",
        "# Outlier capping (90th percentile)\n",
        "price_cap = df['TransactionPrice'].quantile(0.90)\n",
        "df['TransactionPrice'] = np.clip(df['TransactionPrice'], 0, price_cap).astype(np.float32)\n",
        "area_cap = df['ParcelArea'].quantile(0.90)\n",
        "df['ParcelArea'] = np.clip(df['ParcelArea'], 0, area_cap).astype(np.float32)\n",
        "\n",
        "# Log-transform\n",
        "df['TransactionPrice'] = np.log1p(df['TransactionPrice']).astype(np.float32)\n",
        "df['ParcelArea'] = np.log1p(df['ParcelArea']).astype(np.float32)\n",
        "\n",
        "# Target encode SchemeName\n",
        "scheme_encoding = df.groupby('SchemeName')['TransactionPrice'].mean().astype(np.float32)\n",
        "df['Scheme_Name_encoded'] = df['SchemeName'].map(scheme_encoding).fillna(scheme_encoding.mean()).astype(np.float32)\n",
        "\n",
        "# Add Year\n",
        "df['TransactionDate'] = pd.to_datetime(df['TransactionDate'], format='%b-%y')\n",
        "df['Year'] = df['TransactionDate'].dt.year.astype(np.float32)\n",
        "\n",
        "# Clean UnitLevel\n",
        "unit_level_map = {'03A': 4, '12B': 12, '13A': 14, '23A': 24, '33A': 34, '43A': 44, '53A': 54,\n",
        "                  'B': 0, 'D': 0, 'G': 0, 'LG': 0, 'MZ': 0, 'P': 0, 'UG': 0,\n",
        "                  '1/5/2025': 0, '2/3/2025': 0, '1/4/2025': 0}\n",
        "df['UnitLevel_clean'] = df['UnitLevel'].replace(unit_level_map)\n",
        "unit_level_mean = pd.to_numeric(df['UnitLevel_clean'], errors='coerce').mean()\n",
        "df['UnitLevel_clean'] = pd.to_numeric(df['UnitLevel_clean'], errors='coerce').fillna(unit_level_mean).astype(np.float32)\n",
        "df['UnitLevel_binned'] = pd.cut(df['UnitLevel_clean'], bins=[-float('inf'), 10, 20, float('inf')], labels=['Low', 'Mid', 'High'])\n",
        "level_dummies = pd.get_dummies(df['UnitLevel_binned'], prefix='UnitLevel', dtype=np.float32)\n",
        "\n",
        "# Setapak interactions\n",
        "mukim_dummies = pd.get_dummies(df['Mukim'], prefix='Mukim', dtype=np.float32)\n",
        "df['Mukim_Mukim Setapak_Tenure'] = (mukim_dummies.get('Mukim_Mukim Setapak', pd.Series(0, index=df.index)) * df['Tenure']).astype(np.float32)\n",
        "df['Mukim_Mukim Setapak_ParcelArea'] = (mukim_dummies.get('Mukim_Mukim Setapak', pd.Series(0, index=df.index)) * df['ParcelArea']).astype(np.float32)\n",
        "\n",
        "# Combine relevant features for analysis\n",
        "# Use target encoded SchemeName, numerical ParcelArea, Year, Tenure, and one-hot encoded Mukim\n",
        "features_combined = ['Scheme_Name_encoded', 'ParcelArea', 'Year', 'Tenure','UnitLevel_clean']\n",
        "X_combined = df[features_combined]\n",
        "mukim_dummies = pd.get_dummies(df['Mukim'], prefix='Mukim', dtype=np.float32)\n",
        "X_combined = pd.concat([X_combined, mukim_dummies], axis=1).astype(np.float32)\n",
        "\n",
        "y = df['TransactionPrice'].astype(np.float32)\n",
        "\n",
        "# Mutual Information Analysis\n",
        "mi_scores = mutual_info_regression(X_combined, y, random_state=42)\n",
        "mi_series = pd.Series(mi_scores, index=X_combined.columns).sort_values(ascending=False)\n",
        "print(\"Mutual Information Scores (Combined Features vs. TransactionPrice):\")\n",
        "print(mi_series)\n",
        "print(\"\\n\")\n",
        "\n",
        "\n",
        "# VIF analysis\n",
        "# Add a constant to the feature set for VIF calculation\n",
        "X_vif = X_combined.copy()\n",
        "# Drop one of the Mukim dummy variables to avoid perfect multicollinearity with the constant\n",
        "X_vif = X_vif.drop('Mukim_Mukim Batu', axis=1) # Dropping one arbitrary Mukim column\n",
        "X_vif['const'] = 1\n",
        "vif_data = pd.DataFrame()\n",
        "vif_data['feature'] = X_vif.columns\n",
        "vif_data['VIF'] = [variance_inflation_factor(X_vif.values, i) for i in range(X_vif.shape[1])]\n",
        "print(\"VIF Analysis (Combined Features - Dropped one Mukim column):\")\n",
        "print(vif_data.round(2))\n",
        "print(\"\\n\")\n",
        "\n",
        "# RFE analysis (using Linear Regression as the estimator)\n",
        "model = LinearRegression()\n",
        "# RFE needs a target variable for ranking\n",
        "rfe = RFE(model, n_features_to_select=len(X_combined.columns)) # Select all features initially\n",
        "rfe.fit(X_combined, y)\n",
        "\n",
        "rfe_ranking = pd.Series(rfe.ranking_, index=X_combined.columns).sort_values()\n",
        "print(\"RFE Ranking (Combined Features):\")\n",
        "print(rfe_ranking)\n",
        "print(\"\\n\")\n",
        "\n",
        "# Lasso coefficients\n",
        "# Need to scale features for Lasso\n",
        "scaler_lasso = RobustScaler()\n",
        "X_scaled_lasso = scaler_lasso.fit_transform(X_combined).astype(np.float32)\n",
        "\n",
        "lasso = Lasso(alpha=0.001) # You might need to tune alpha\n",
        "lasso.fit(X_scaled_lasso, y)\n",
        "\n",
        "lasso_coef = pd.Series(lasso.coef_, index=X_combined.columns).sort_values(ascending=False)\n",
        "print(\"Lasso Coefficients (Combined Features):\")\n",
        "print(lasso_coef)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N5ZENZ8Zh526",
        "outputId": "cd1e1767-75de-4999-923e-44395394548e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/numpy/_core/fromnumeric.py:57: FutureWarning: Downcasting behavior in Series and DataFrame methods 'where', 'mask', and 'clip' is deprecated. In a future version this will not infer object dtypes or cast all-round floats to integers. Instead call result.infer_objects(copy=False) for object inference, or cast round floats explicitly. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  return bound(*args, **kwds)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mutual Information Scores (Combined Features vs. TransactionPrice):\n",
            "Scheme_Name_encoded               1.595100\n",
            "ParcelArea                        1.095919\n",
            "UnitLevel_clean                   0.274738\n",
            "Tenure                            0.170416\n",
            "Year                              0.129252\n",
            "Mukim_Mukim Setapak               0.118921\n",
            "Mukim_Mukim Batu                  0.115475\n",
            "Mukim_Mukim Petaling              0.107210\n",
            "Mukim_Mukim Kuala Lumpur          0.076641\n",
            "Mukim_Kuala Lumpur Town Centre    0.064861\n",
            "dtype: float64\n",
            "\n",
            "\n",
            "VIF Analysis (Combined Features - Dropped one Mukim column):\n",
            "                          feature         VIF\n",
            "0             Scheme_Name_encoded        2.59\n",
            "1                      ParcelArea        2.11\n",
            "2                            Year        1.03\n",
            "3                          Tenure        1.30\n",
            "4                 UnitLevel_clean        1.16\n",
            "5  Mukim_Kuala Lumpur Town Centre        1.32\n",
            "6        Mukim_Mukim Kuala Lumpur        1.60\n",
            "7            Mukim_Mukim Petaling        1.55\n",
            "8             Mukim_Mukim Setapak        1.61\n",
            "9                           const  3665319.46\n",
            "\n",
            "\n",
            "RFE Ranking (Combined Features):\n",
            "Scheme_Name_encoded               1\n",
            "ParcelArea                        1\n",
            "Year                              1\n",
            "Tenure                            1\n",
            "UnitLevel_clean                   1\n",
            "Mukim_Kuala Lumpur Town Centre    1\n",
            "Mukim_Mukim Batu                  1\n",
            "Mukim_Mukim Kuala Lumpur          1\n",
            "Mukim_Mukim Petaling              1\n",
            "Mukim_Mukim Setapak               1\n",
            "dtype: int64\n",
            "\n",
            "\n",
            "Lasso Coefficients (Combined Features):\n",
            "Scheme_Name_encoded               0.795053\n",
            "ParcelArea                        0.148257\n",
            "UnitLevel_clean                   0.033981\n",
            "Mukim_Mukim Kuala Lumpur          0.010686\n",
            "Mukim_Kuala Lumpur Town Centre    0.002610\n",
            "Year                              0.001744\n",
            "Tenure                           -0.000000\n",
            "Mukim_Mukim Batu                 -0.000000\n",
            "Mukim_Mukim Petaling             -0.000000\n",
            "Mukim_Mukim Setapak              -0.012317\n",
            "dtype: float32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Calculate the correlation matrix\n",
        "correlation_matrix = X_combined.corr()\n",
        "\n",
        "# Plot the correlation heatmap\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=.5)\n",
        "plt.title('Correlation Heatmap of Combined Features')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 768
        },
        "id": "ZohYaMDblRhJ",
        "outputId": "012e76d6-8daa-47e8-cb02-85e43d9f517a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x800 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Combine features and the target variable\n",
        "X_combined_with_target = X_combined.copy()\n",
        "X_combined_with_target['TransactionPrice'] = y\n",
        "\n",
        "# Calculate the correlation matrix including the target\n",
        "correlation_matrix_with_target = X_combined_with_target.corr()\n",
        "\n",
        "# Plot the correlation heatmap\n",
        "plt.figure(figsize=(12, 10))\n",
        "sns.heatmap(correlation_matrix_with_target, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=.5)\n",
        "plt.title('Correlation Heatmap of Combined Features and TransactionPrice')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 789
        },
        "id": "_F4srzGTm675",
        "outputId": "fcfc4d04-aceb-4143-ef90-e581156abeca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1000 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_selection import mutual_info_regression\n",
        "\n",
        "# Load data\n",
        "url = \"https://raw.githubusercontent.com/englian1123/KL-High-Rise-Data/refs/heads/main/KLHighRise.csv\"\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "# Preprocess necessary columns for mutual information calculation\n",
        "df.rename(columns={'TransactionPrice  ': 'TransactionPrice', 'Parcel Area': 'ParcelArea', 'Scheme Name/Area': 'SchemeName'}, inplace=True)\n",
        "df['Tenure'] = df['Tenure'].map({'Freehold': 1, 'Leasehold': 0}).fillna(0).astype(np.float32)\n",
        "\n",
        "# Target encode SchemeName for mutual information calculation\n",
        "# Use a copy to avoid SettingWithCopyWarning\n",
        "df_temp = df.copy()\n",
        "scheme_encoding_temp = df_temp.groupby('SchemeName')['TransactionPrice'].mean().astype(np.float32)\n",
        "df_temp['Scheme_Name_encoded'] = df_temp['SchemeName'].map(scheme_encoding_temp).fillna(scheme_encoding_temp.mean()).astype(np.float32)\n",
        "\n",
        "# Calculate Mutual Information\n",
        "# Reshape the features to be 2D arrays\n",
        "tenure_mi = mutual_info_regression(df_temp[['Tenure']], df_temp['TransactionPrice'], random_state=42)[0]\n",
        "scheme_name_mi = mutual_info_regression(df_temp[['Scheme_Name_encoded']], df_temp['TransactionPrice'], random_state=42)[0]\n",
        "\n",
        "print(f\"Mutual Information between Tenure and TransactionPrice: {tenure_mi:.4f}\")\n",
        "print(f\"Mutual Information between Scheme_Name_encoded and TransactionPrice: {scheme_name_mi:.4f}\")\n",
        "\n",
        "# Calculate mutual information between Tenure_encoded and Scheme_Name_encoded\n",
        "# Treat Tenure_encoded as a discrete variable for this calculation if appropriate,\n",
        "# or use continuous if preferred (mutual_info_regression supports both)\n",
        "# Assuming mutual_info_regression is suitable for both continuous-continuous and discrete-continuous.\n",
        "# If Tenure is strictly binary, mutual_info_classif might be more theoretically appropriate if comparing against categorical target,\n",
        "# but here we are comparing feature vs feature, so mutual_info_regression is used for consistency with other features.\n",
        "tenure_scheme_mi = mutual_info_regression(df_temp[['Tenure']], df_temp['Scheme_Name_encoded'], random_state=42)[0]\n",
        "\n",
        "print(f\"Mutual Information between Tenure and Scheme_Name_encoded: {tenure_scheme_mi:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8rHtPK_kby1A",
        "outputId": "ff6574c3-cf96-45bb-a6e3-8f6cb8c89f90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mutual Information between Tenure and TransactionPrice: 0.1123\n",
            "Mutual Information between Scheme_Name_encoded and TransactionPrice: 1.5647\n",
            "Mutual Information between Tenure and Scheme_Name_encoded: 0.6376\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required libraries\n",
        "!pip install seaborn pandas matplotlib\n",
        "\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define the data\n",
        "# data = {\n",
        "#     \"Feature\": [\n",
        "#         \"Scheme_Name_encoded\", \"ParcelArea\", \"Mukim_Mukim Batu\", \"UnitLevel_clean\",\n",
        "#         \"Tenure\", \"Year\", \"Mukim_Mukim Kuala Lumpur\", \"Mukim_Kuala Lumpur Town Centre\",\n",
        "#         \"Mukim_Mukim Petaling\", \"Mukim_Mukim Setapak\"\n",
        "#     ],\n",
        "#     \"Mutual_Info_Score\": [1, 0.687053476, 0.07239358, 0.172238731, 0.106837189, 0.081030656,\n",
        "#                           0.048047771, 0.040662654, 0.067212087, 0.074553946],\n",
        "#     \"Lasso_Score\": [1, 0.186474361, 0, 0.042740547, 0, 0.002193564, 0.013440613,\n",
        "#                     0.0032828, 0, -0.015492049],\n",
        "#     \"Correlation_Score\": [1, 0.810526316, 0.273684211, 0.252631579, 0.347368421,\n",
        "#                           0.042105263, 0.242105263, 0.136842105, 0.189473684, -0.273684211],\n",
        "#     \"VIF_Score\": [0, 0.185328185, 1, 0.552123552, 0.498069498, 0.602316602,\n",
        "#                   0.382239382, 0.49034749, 0.401544402, 0.378378378],\n",
        "#     \"RFE_Score\": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
        "# }\n",
        "data = {\n",
        "    \"Feature\": [\n",
        "        \"Scheme_Name_encoded\", \"ParcelArea\", \"Mukim_Mukim Batu\", \"UnitLevel_clean\",\n",
        "        \"Tenure\", \"Year\", \"Mukim_Mukim Kuala Lumpur\", \"Mukim_Kuala Lumpur Town Centre\",\n",
        "        \"Mukim_Mukim Petaling\", \"Mukim_Mukim Setapak\"\n",
        "    ],\n",
        "    \"Mutual_Info_Score\": [1, 0.687053476, 0.07239358, 0.172238731, 0.106837189, 0.081030656,\n",
        "                          0.048047771, 0.040662654, 0.067212087, 0.074553946],\n",
        "    \"Lasso_Score\": [1, 0.186474361, 0, 0.042740547, 0, 0.002193564, 0.013440613,\n",
        "                    0.0032828, 0, 0.015492049],\n",
        "    \"Correlation_Score\": [1, 0.810526316, 0.273684211, 0.252631579, 0.347368421,\n",
        "                          0.042105263, 0.242105263, 0.136842105, 0.189473684, 0.273684211],\n",
        "    \"VIF_Score\": [0, 0.185328185, 1, 0.552123552, 0.498069498, 0.602316602,\n",
        "                  0.382239382, 0.49034749, 0.401544402, 0.378378378],\n",
        "    \"RFE_Score\": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
        "}\n",
        "\n",
        "# Create DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Set Feature as index for heatmap\n",
        "df.set_index(\"Feature\", inplace=True)\n",
        "\n",
        "# Plot heatmap\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.heatmap(df, annot=True, cmap=\"viridis\", linewidths=0.5)\n",
        "plt.title(\"Heatmap of Feature Selection Scores\", fontsize=14)\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        },
        "id": "1nFZSVku1nYS",
        "outputId": "7e5ea7cf-f45b-4cec-fa3b-96d9ce3f93e7"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.12/dist-packages (0.13.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: numpy!=1.24.0,>=1.20 in /usr/local/lib/python3.12/dist-packages (from seaborn) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.61.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from sklearn.metrics import r2_score, mean_squared_error\n",
        "import joblib\n",
        "import statsmodels.api as sm\n",
        "\n",
        "# Load and preprocess\n",
        "url = \"https://raw.githubusercontent.com/englian1123/KL-High-Rise-Data/refs/heads/main/KLHighRise.csv\"\n",
        "df = pd.read_csv(url)\n",
        "df['ParcelArea'] = df['ParcelArea'].astype(str).str.extract('(\\d+\\.?\\d*)').astype(np.float32)\n",
        "df['Tenure'] = df['Tenure'].map({'Freehold': 1, 'Leasehold': 0}).fillna(0).astype(np.float32)\n",
        "\n",
        "\n",
        "# Outlier capping\n",
        "price_cap = df['TransactionPrice'].quantile(0.90)\n",
        "df['TransactionPrice'] = np.clip(df['TransactionPrice'], 0, price_cap).astype(np.float32)\n",
        "area_cap = df['ParcelArea'].quantile(0.90)\n",
        "df['ParcelArea'] = np.clip(df['ParcelArea'], 0, area_cap).astype(np.float32)\n",
        "\n",
        "# Log-transform\n",
        "df['TransactionPrice'] = np.log1p(df['TransactionPrice']).astype(np.float32)\n",
        "df['ParcelArea'] = np.log1p(df['ParcelArea']).astype(np.float32)\n",
        "\n",
        "# Target encode SchemeName\n",
        "scheme_encoding = df.groupby('SchemeName')['TransactionPrice'].mean().astype(np.float32)\n",
        "df['Scheme_Name_encoded'] = df['SchemeName'].map(scheme_encoding).fillna(scheme_encoding.mean()).astype(np.float32)\n",
        "\n",
        "# Perform one-hot encoding for 'Mukim\n",
        "df = pd.get_dummies(df, columns=['Mukim'], drop_first=True, dtype=np.float32)\n",
        "\n",
        "# Show encoded Mukim columns\n",
        "print(\"Encoded Mukim columns:\")\n",
        "print([col for col in df.columns if col.startswith('Mukim_')])\n",
        "\n",
        "\n",
        "# Clean UnitLevel\n",
        "unit_level_map = {'03A': 4, '12B': 12, '13A': 14, '23A': 24, '33A': 34, '43A': 44, '53A': 54,\n",
        "                  'B': 0, 'D': 0, 'G': 0, 'LG': 0, 'MZ': 0, 'P': 0, 'UG': 0,\n",
        "                  '1/5/2025': 0, '2/3/2025': 0, '1/4/2025': 0}\n",
        "df['UnitLevel_clean'] = df['UnitLevel'].replace(unit_level_map)\n",
        "unit_level_mean = pd.to_numeric(df['UnitLevel_clean'], errors='coerce').mean()\n",
        "df['UnitLevel_clean'] = pd.to_numeric(df['UnitLevel_clean'], errors='coerce').fillna(unit_level_mean).astype(np.float32)\n",
        "df['UnitLevel_binned'] = pd.cut(df['UnitLevel_clean'], bins=[-float('inf'), 10, 20, float('inf')], labels=['Low', 'Mid', 'High'])\n",
        "level_dummies = pd.get_dummies(df['UnitLevel_binned'], prefix='UnitLevel', dtype=np.float32)\n",
        "\n",
        "\n",
        "# Selected features based on ranking\n",
        "selected_features = ['Scheme_Name_encoded', 'ParcelArea', 'Mukim_Mukim Batu', 'UnitLevel_clean', 'Tenure']\n",
        "\n",
        "\n",
        "# Define X and y\n",
        "X = df[selected_features]\n",
        "y = df['TransactionPrice']  # Replace 'Price' with your target column name if different\n",
        "\n",
        "# Convert X to a NumPy array\n",
        "X = X.values\n",
        "\n",
        "# Add constant for intercept\n",
        "X = sm.add_constant(X)\n",
        "\n",
        "# Build OLS model\n",
        "model = sm.OLS(y, X).fit()\n",
        "\n",
        "# Print summary\n",
        "print(model.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A9ytX6zM24_K",
        "outputId": "9e45754c-5f8b-4608-97dd-e8507d9dd15f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<>:12: SyntaxWarning: invalid escape sequence '\\d'\n",
            "<>:12: SyntaxWarning: invalid escape sequence '\\d'\n",
            "/tmp/ipython-input-3910798891.py:12: SyntaxWarning: invalid escape sequence '\\d'\n",
            "  df['ParcelArea'] = df['ParcelArea'].astype(str).str.extract('(\\d+\\.?\\d*)').astype(np.float32)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoded Mukim columns:\n",
            "['Mukim_Mukim Ampang', 'Mukim_Mukim Batu', 'Mukim_Mukim Cheras', 'Mukim_Mukim Kuala Lumpur', 'Mukim_Mukim Petaling', 'Mukim_Mukim Setapak', 'Mukim_Mukim Ulu Kelang']\n",
            "                            OLS Regression Results                            \n",
            "==============================================================================\n",
            "Dep. Variable:       TransactionPrice   R-squared:                       0.923\n",
            "Model:                            OLS   Adj. R-squared:                  0.923\n",
            "Method:                 Least Squares   F-statistic:                 3.431e+04\n",
            "Date:                Wed, 05 Nov 2025   Prob (F-statistic):               0.00\n",
            "Time:                        12:41:51   Log-Likelihood:                 5053.5\n",
            "No. Observations:               14392   AIC:                        -1.009e+04\n",
            "Df Residuals:                   14386   BIC:                        -1.005e+04\n",
            "Df Model:                           5                                         \n",
            "Covariance Type:            nonrobust                                         \n",
            "==============================================================================\n",
            "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------\n",
            "const          0.2857      0.036      8.022      0.000       0.216       0.356\n",
            "x1             0.8520      0.004    229.030      0.000       0.845       0.859\n",
            "x2             0.3505      0.006     56.856      0.000       0.338       0.363\n",
            "x3            -0.0034      0.003     -0.995      0.320      -0.010       0.003\n",
            "x4             0.0022      0.000     15.213      0.000       0.002       0.002\n",
            "x5            -0.0044      0.003     -1.375      0.169      -0.011       0.002\n",
            "==============================================================================\n",
            "Omnibus:                     4847.622   Durbin-Watson:                   1.755\n",
            "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           267255.739\n",
            "Skew:                          -0.825   Prob(JB):                         0.00\n",
            "Kurtosis:                      24.046   Cond. No.                         548.\n",
            "==============================================================================\n",
            "\n",
            "Notes:\n",
            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Linear Regression Testing"
      ],
      "metadata": {
        "id": "ICMl3kwrYcku"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from sklearn.metrics import r2_score, mean_squared_error\n",
        "import joblib\n",
        "\n",
        "# Load and preprocess\n",
        "url = \"https://raw.githubusercontent.com/englian1123/KL-High-Rise-Data/refs/heads/main/KLHighRise.csv\"\n",
        "df = pd.read_csv(url)\n",
        "df.rename(columns={'TransactionPrice  ': 'TransactionPrice', 'Parcel Area': 'ParcelArea', 'Scheme Name/Area': 'SchemeName'}, inplace=True)\n",
        "df['ParcelArea'] = df['ParcelArea'].astype(str).str.extract('(\\d+\\.?\\d*)').astype(np.float32)\n",
        "df['Tenure'] = df['Tenure'].map({'Freehold': 1, 'Leasehold': 0}).fillna(0).astype(np.float32)\n",
        "\n",
        "# Drop low-count Mukims\n",
        "low_count_mukims = ['Mukim Cheras', 'Mukim Ampang', 'Mukim Ulu Kelang']\n",
        "df = df[~df['Mukim'].isin(low_count_mukims)].reset_index(drop=True)\n",
        "\n",
        "# Outlier capping\n",
        "price_cap = df['TransactionPrice'].quantile(0.90)\n",
        "df['TransactionPrice'] = np.clip(df['TransactionPrice'], 0, price_cap).astype(np.float32)\n",
        "area_cap = df['ParcelArea'].quantile(0.90)\n",
        "df['ParcelArea'] = np.clip(df['ParcelArea'], 0, area_cap).astype(np.float32)\n",
        "\n",
        "# Log-transform\n",
        "df['TransactionPrice'] = np.log1p(df['TransactionPrice']).astype(np.float32)\n",
        "df['ParcelArea'] = np.log1p(df['ParcelArea']).astype(np.float32)\n",
        "\n",
        "# Target encode SchemeName\n",
        "scheme_encoding = df.groupby('SchemeName')['TransactionPrice'].mean().astype(np.float32)\n",
        "df['Scheme_Name_encoded'] = df['SchemeName'].map(scheme_encoding).fillna(scheme_encoding.mean()).astype(np.float32)\n",
        "\n",
        "# Add Year\n",
        "df['TransactionDate'] = pd.to_datetime(df['TransactionDate'], format='%b-%y')\n",
        "df['Year'] = df['TransactionDate'].dt.year.astype(np.float32)\n",
        "\n",
        "# Clean UnitLevel\n",
        "unit_level_map = {'03A': 4, '12B': 12, '13A': 14, '23A': 24, '33A': 34, '43A': 44, '53A': 54,\n",
        "                  'B': 0, 'D': 0, 'G': 0, 'LG': 0, 'MZ': 0, 'P': 0, 'UG': 0,\n",
        "                  '1/5/2025': 0, '2/3/2025': 0, '1/4/2025': 0}\n",
        "df['UnitLevel_clean'] = df['UnitLevel'].replace(unit_level_map)\n",
        "unit_level_mean = pd.to_numeric(df['UnitLevel_clean'], errors='coerce').mean()\n",
        "df['UnitLevel_clean'] = pd.to_numeric(df['UnitLevel_clean'], errors='coerce').fillna(unit_level_mean).astype(np.float32)\n",
        "df['UnitLevel_binned'] = pd.cut(df['UnitLevel_clean'], bins=[-float('inf'), 10, 20, float('inf')], labels=['Low', 'Mid', 'High'])\n",
        "level_dummies = pd.get_dummies(df['UnitLevel_binned'], prefix='UnitLevel', dtype=np.float32)\n",
        "\n",
        "# Setapak interactions\n",
        "mukim_dummies = pd.get_dummies(df['Mukim'], prefix='Mukim', dtype=np.float32)\n",
        "df['Mukim_Mukim Setapak_Tenure'] = (mukim_dummies.get('Mukim_Mukim Setapak', pd.Series(0, index=df.index)) * df['Tenure']).astype(np.float32)\n",
        "df['Mukim_Mukim Setapak_ParcelArea'] = (mukim_dummies.get('Mukim_Mukim Setapak', pd.Series(0, index=df.index)) * df['ParcelArea']).astype(np.float32)\n",
        "\n",
        "# Features\n",
        "features = ['Scheme_Name_encoded', 'ParcelArea', 'Year', 'Mukim_Mukim Setapak_Tenure',\n",
        "            'Mukim_Mukim Setapak_ParcelArea', 'UnitLevel_High']\n",
        "X = pd.concat([df[['Scheme_Name_encoded', 'ParcelArea', 'Year']],\n",
        "               df[['Mukim_Mukim Setapak_Tenure', 'Mukim_Mukim Setapak_ParcelArea']],\n",
        "               level_dummies[['UnitLevel_High']]], axis=1).astype(np.float32)\n",
        "y = df['TransactionPrice'].astype(np.float32)\n",
        "\n",
        "# Split data\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Scale features\n",
        "scaler = RobustScaler()\n",
        "X_train[['Scheme_Name_encoded', 'ParcelArea', 'Year']] = scaler.fit_transform(X_train[['Scheme_Name_encoded', 'ParcelArea', 'Year']]).astype(np.float32)\n",
        "X_test[['Scheme_Name_encoded', 'ParcelArea', 'Year']] = scaler.transform(X_test[['Scheme_Name_encoded', 'ParcelArea', 'Year']]).astype(np.float32)\n",
        "\n",
        "# Train MLR\n",
        "mlr_model = LinearRegression()\n",
        "mlr_model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate models\n",
        "y_pred_mlr = mlr_model.predict(X_test)\n",
        "mlr_r2 = r2_score(y_test, y_pred_mlr)\n",
        "mlr_rmse_log = np.sqrt(mean_squared_error(y_test, y_pred_mlr))\n",
        "mlr_rmse_rm = np.sqrt(mean_squared_error(np.expm1(y_test), np.expm1(y_pred_mlr)))\n",
        "\n",
        "print(\"MLR R:\", mlr_r2)\n",
        "print(\"MLR RMSE (log-scale):\", mlr_rmse_log)\n",
        "print(\"MLR RMSE (RM):\", mlr_rmse_rm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HE7prdkXX5_Q",
        "outputId": "c9e8aad5-7c2c-4c26-e2ef-e0917861fd6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<>:12: SyntaxWarning: invalid escape sequence '\\d'\n",
            "<>:12: SyntaxWarning: invalid escape sequence '\\d'\n",
            "/tmp/ipython-input-2321029256.py:12: SyntaxWarning: invalid escape sequence '\\d'\n",
            "  df['ParcelArea'] = df['ParcelArea'].astype(str).str.extract('(\\d+\\.?\\d*)').astype(np.float32)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MLR R: 0.9214620590209961\n",
            "MLR RMSE (log-scale): 0.1749208852630052\n",
            "MLR RMSE (RM): 137423.127253021\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/numpy/_core/fromnumeric.py:57: FutureWarning: Downcasting behavior in Series and DataFrame methods 'where', 'mask', and 'clip' is deprecated. In a future version this will not infer object dtypes or cast all-round floats to integers. Instead call result.infer_objects(copy=False) for object inference, or cast round floats explicitly. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  return bound(*args, **kwds)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# To finalize feature selection and test model performance\n",
        "\n",
        "*   Caps outliers (95th percentile for Price, Parcel_sq_m).\n",
        "*   Encodes Mukim (one-hot), Tenure (binary).\n",
        "*   Normalizes numericals.\n",
        "*   Trains RandomForest, reports R, RMSE, feature importance, and 5-fold CV.\n",
        "\n"
      ],
      "metadata": {
        "id": "Qo-v8SV_uC_9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import r2_score, mean_squared_error\n",
        "import numpy as np\n",
        "\n",
        "# Load and preprocess\n",
        "url = \"https://raw.githubusercontent.com/englian1123/KL-High-Rise-Data/refs/heads/main/KLHighRise.csv\"\n",
        "df = pd.read_csv(url)\n",
        "df.rename(columns={'TransactionPrice  ': 'TransactionPrice'}, inplace=True)\n",
        "# Convert 'ParcelArea' to string before extracting numerical values\n",
        "df['Parcel_sq_m'] = df['ParcelArea'].astype(str).str.extract('(\\d+\\.?\\d*)')\n",
        "df['Parcel_sq_m'] = pd.to_numeric(df['Parcel_sq_m'], errors='coerce')\n",
        "\n",
        "df['Year'] = pd.to_datetime(df['TransactionDate'], format='%b-%y').dt.year\n",
        "df['Tenure'] = df['Tenure'].map({'Freehold': 1, 'Leasehold': 0})\n",
        "\n",
        "# Handle outliers (cap at 95th percentile)\n",
        "price_cap = df['TransactionPrice'].quantile(0.95)\n",
        "df['TransactionPrice'] = np.clip(df['TransactionPrice'], 0, price_cap)\n",
        "area_cap = df['Parcel_sq_m'].quantile(0.95)\n",
        "df['Parcel_sq_m'] = np.clip(df['Parcel_sq_m'], 0, area_cap)\n",
        "\n",
        "# Features and target\n",
        "features = ['Parcel_sq_m', 'UnitLevel', 'Year', 'Tenure'] + [col for col in pd.get_dummies(df['Mukim']).columns]\n",
        "X = pd.concat([df[['Parcel_sq_m', 'UnitLevel', 'Year', 'Tenure']], pd.get_dummies(df['Mukim'])], axis=1)\n",
        "y = df['TransactionPrice']\n",
        "\n",
        "# Convert 'UnitLevel' to numeric, coercing errors to NaN and fill NaN with mean\n",
        "X['UnitLevel'] = pd.to_numeric(X['UnitLevel'], errors='coerce')\n",
        "X['UnitLevel'].fillna(X['UnitLevel'].mean(), inplace=True)\n",
        "\n",
        "\n",
        "# Scale numerical features\n",
        "scaler = StandardScaler()\n",
        "X[['Parcel_sq_m', 'UnitLevel', 'Year']] = scaler.fit_transform(X[['Parcel_sq_m', 'UnitLevel', 'Year']])\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# RandomForest model\n",
        "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "rf.fit(X_train, y_train)\n",
        "y_pred = rf.predict(X_test)\n",
        "print(\"R:\", r2_score(y_test, y_pred))\n",
        "print(\"RMSE:\", np.sqrt(mean_squared_error(y_test, y_pred)))\n",
        "\n",
        "# Feature importance\n",
        "importance = pd.Series(rf.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
        "print(\"RandomForest Feature Importance:\\n\", importance)\n",
        "\n",
        "# Cross-validation\n",
        "cv_scores = cross_val_score(rf, X, y, cv=5, scoring='r2')\n",
        "print(\"5-Fold CV R:\", cv_scores.mean(), \"\", cv_scores.std())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zwMZ7119uEyy",
        "outputId": "996c9841-4fd3-49b4-a116-bb7bf07f98e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<>:13: SyntaxWarning: invalid escape sequence '\\d'\n",
            "<>:13: SyntaxWarning: invalid escape sequence '\\d'\n",
            "/tmp/ipython-input-2335392999.py:13: SyntaxWarning: invalid escape sequence '\\d'\n",
            "  df['Parcel_sq_m'] = df['ParcelArea'].astype(str).str.extract('(\\d+\\.?\\d*)')\n",
            "/usr/local/lib/python3.12/dist-packages/numpy/_core/fromnumeric.py:57: FutureWarning: Downcasting behavior in Series and DataFrame methods 'where', 'mask', and 'clip' is deprecated. In a future version this will not infer object dtypes or cast all-round floats to integers. Instead call result.infer_objects(copy=False) for object inference, or cast round floats explicitly. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  return bound(*args, **kwds)\n",
            "/tmp/ipython-input-2335392999.py:32: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  X['UnitLevel'].fillna(X['UnitLevel'].mean(), inplace=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R: 0.8907590430719847\n",
            "RMSE: 207115.40117892373\n",
            "RandomForest Feature Importance:\n",
            " Parcel_sq_m                 0.845469\n",
            "UnitLevel                   0.071998\n",
            "Year                        0.022722\n",
            "Kuala Lumpur Town Centre    0.014631\n",
            "Mukim Setapak               0.010639\n",
            "Tenure                      0.010014\n",
            "Mukim Kuala Lumpur          0.009401\n",
            "Mukim Batu                  0.008164\n",
            "Mukim Petaling              0.005056\n",
            "Mukim Cheras                0.000967\n",
            "Mukim Ampang                0.000851\n",
            "Mukim Ulu Kelang            0.000088\n",
            "dtype: float64\n",
            "5-Fold CV R: 0.8296369211633794  0.019605327181787226\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# To optimize the model and test refined features\n",
        "\n",
        "*  Aggregates low-count Mukims (Cheras, Ampang, Ulu Kelang) into Other.\n",
        "*  Adds Month for seasonality.\n",
        "*  Log-transforms Price and Parcel_sq_m to handle skewness.\n",
        "*  Tests RandomForest and GradientBoosting (Huber loss for robustness).\n",
        "*  Tunes hyperparameters (e.g., max_depth, n_estimators).\n",
        "*  Reports R, RMSE (back-transformed), feature importance, and CV."
      ],
      "metadata": {
        "id": "qssdQnif4hDM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import r2_score, mean_squared_error\n",
        "\n",
        "# Load and preprocess\n",
        "url = \"https://raw.githubusercontent.com/englian1123/KL-High-Rise-Data/refs/heads/main/KLHighRise.csv\"\n",
        "df = pd.read_csv(url)\n",
        "df.rename(columns={'TransactionPrice  ': 'TransactionPrice'}, inplace=True)\n",
        "# Convert 'ParcelArea' to string before extracting numerical values\n",
        "df['Parcel_sq_m'] = df['ParcelArea'].astype(str).str.extract('(\\d+\\.?\\d*)')\n",
        "df['Parcel_sq_m'] = pd.to_numeric(df['Parcel_sq_m'], errors='coerce')\n",
        "\n",
        "df['Year'] = pd.to_datetime(df['TransactionDate'], format='%b-%y').dt.year\n",
        "df['Month'] = pd.to_datetime(df['TransactionDate'], format='%b-%y').dt.month\n",
        "df['Tenure'] = df['Tenure'].map({'Freehold': 1, 'Leasehold': 0})\n",
        "\n",
        "# Aggregate low-count Mukims\n",
        "low_count_mukims = ['Mukim Cheras', 'Mukim Ampang', 'Mukim Ulu Kelang']\n",
        "df['Mukim'] = df['Mukim'].apply(lambda x: 'Other' if x in low_count_mukims else x)\n",
        "\n",
        "# Log-transform to handle skewness\n",
        "df['TransactionPrice'] = np.log1p(df['TransactionPrice'])\n",
        "df['Parcel_sq_m'] = np.log1p(df['Parcel_sq_m'])\n",
        "\n",
        "# Features and target\n",
        "features = ['Parcel_sq_m', 'UnitLevel', 'Year', 'Month', 'Tenure'] + [col for col in pd.get_dummies(df['Mukim']).columns]\n",
        "X = pd.concat([df[['Parcel_sq_m', 'UnitLevel', 'Year', 'Month', 'Tenure']], pd.get_dummies(df['Mukim'])], axis=1)\n",
        "y = df['TransactionPrice']\n",
        "\n",
        "# Convert 'UnitLevel' to numeric, coercing errors to NaN and fill NaN with mean\n",
        "X['UnitLevel'] = pd.to_numeric(X['UnitLevel'], errors='coerce')\n",
        "X['UnitLevel'].fillna(X['UnitLevel'].mean(), inplace=True)\n",
        "\n",
        "# Scale numerical features\n",
        "scaler = StandardScaler()\n",
        "X[['Parcel_sq_m', 'UnitLevel', 'Year', 'Month']] = scaler.fit_transform(X[['Parcel_sq_m', 'UnitLevel', 'Year', 'Month']])\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# RandomForest with hyperparameter tuning\n",
        "rf = RandomForestRegressor(n_estimators=200, max_depth=20, min_samples_split=5, random_state=42)\n",
        "rf.fit(X_train, y_train)\n",
        "y_pred_rf = rf.predict(X_test)\n",
        "print(\"RandomForest R:\", r2_score(y_test, y_pred_rf))\n",
        "print(\"RandomForest RMSE:\", np.sqrt(mean_squared_error(np.expm1(y_test), np.expm1(y_pred_rf))))  # Back-transform for RMSE\n",
        "\n",
        "# GradientBoosting for robustness\n",
        "gb = GradientBoostingRegressor(n_estimators=200, max_depth=5, learning_rate=0.1, loss='huber', random_state=42)\n",
        "gb.fit(X_train, y_train)\n",
        "y_pred_gb = gb.predict(X_test)\n",
        "print(\"GradientBoosting R:\", r2_score(y_test, y_pred_gb))\n",
        "print(\"GradientBoosting RMSE:\", np.sqrt(mean_squared_error(np.expm1(y_test), np.expm1(y_pred_gb))))\n",
        "\n",
        "# Feature importance\n",
        "importance_rf = pd.Series(rf.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
        "print(\"RandomForest Feature Importance:\\n\", importance_rf)\n",
        "importance_gb = pd.Series(gb.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
        "print(\"GradientBoosting Feature Importance:\\n\", importance_gb)\n",
        "\n",
        "# Cross-validation\n",
        "cv_rf = cross_val_score(rf, X, y, cv=5, scoring='r2')\n",
        "print(\"RandomForest 5-Fold CV R:\", cv_rf.mean(), \"\", cv_rf.std())\n",
        "cv_gb = cross_val_score(gb, X, y, cv=5, scoring='r2')\n",
        "print(\"GradientBoosting 5-Fold CV R:\", cv_gb.mean(), \"\", cv_gb.std())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DvPPmFb34lzL",
        "outputId": "726b1738-f637-4298-e6e7-24e061d2c5b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<>:13: SyntaxWarning: invalid escape sequence '\\d'\n",
            "<>:13: SyntaxWarning: invalid escape sequence '\\d'\n",
            "/tmp/ipython-input-3288200054.py:13: SyntaxWarning: invalid escape sequence '\\d'\n",
            "  df['Parcel_sq_m'] = df['ParcelArea'].astype(str).str.extract('(\\d+\\.?\\d*)')\n",
            "/tmp/ipython-input-3288200054.py:35: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  X['UnitLevel'].fillna(X['UnitLevel'].mean(), inplace=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RandomForest R: 0.8793000969755397\n",
            "RandomForest RMSE: 316850.3280900017\n",
            "GradientBoosting R: 0.8644919020606323\n",
            "GradientBoosting RMSE: 352790.76851604943\n",
            "RandomForest Feature Importance:\n",
            " Parcel_sq_m                 0.797921\n",
            "UnitLevel                   0.070884\n",
            "Month                       0.025875\n",
            "Mukim Setapak               0.022354\n",
            "Year                        0.020138\n",
            "Tenure                      0.015695\n",
            "Kuala Lumpur Town Centre    0.014803\n",
            "Mukim Kuala Lumpur          0.011896\n",
            "Mukim Batu                  0.009832\n",
            "Mukim Petaling              0.005532\n",
            "Other                       0.005070\n",
            "dtype: float64\n",
            "GradientBoosting Feature Importance:\n",
            " Parcel_sq_m                 0.839844\n",
            "UnitLevel                   0.066660\n",
            "Mukim Setapak               0.020278\n",
            "Tenure                      0.015744\n",
            "Mukim Kuala Lumpur          0.014905\n",
            "Mukim Batu                  0.012502\n",
            "Kuala Lumpur Town Centre    0.012099\n",
            "Year                        0.006700\n",
            "Mukim Petaling              0.004858\n",
            "Month                       0.004519\n",
            "Other                       0.001892\n",
            "dtype: float64\n",
            "RandomForest 5-Fold CV R: 0.7884251140296453  0.05731442941331571\n",
            "GradientBoosting 5-Fold CV R: 0.7729533232381038  0.07600448986254635\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# To improve performance (reduce RMSE, overfitting)\n",
        "\n",
        "*   Replaces Month with Quarter to reduce noise (4 categories vs. 12).\n",
        "*   Uses stricter capping (99th percentile) and RobustScaler.\n",
        "*   Optimizes RandomForest with GridSearchCV.\n",
        "*   Retests GradientBoosting with lower learning_rate for stability.\n",
        "*   Reports R, RMSE, importance, and CV.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "B38yfKyyAfqK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from sklearn.metrics import r2_score, mean_squared_error\n",
        "\n",
        "# Load and preprocess\n",
        "url = \"https://raw.githubusercontent.com/englian1123/KL-High-Rise-Data/refs/heads/main/KLHighRise.csv\"\n",
        "df = pd.read_csv(url)\n",
        "df.rename(columns={'TransactionPrice  ': 'TransactionPrice'}, inplace=True)\n",
        "# Convert 'ParcelArea' to string before extracting numerical values\n",
        "df['Parcel_sq_m'] = df['ParcelArea'].astype(str).str.extract('(\\d+\\.?\\d*)')\n",
        "df['Parcel_sq_m'] = pd.to_numeric(df['Parcel_sq_m'], errors='coerce')\n",
        "\n",
        "df['Year'] = pd.to_datetime(df['TransactionDate'], format='%b-%y').dt.year\n",
        "df['Month'] = pd.to_datetime(df['TransactionDate'], format='%b-%y').dt.month\n",
        "df['Quarter'] = pd.to_datetime(df['TransactionDate'], format='%b-%y').dt.quarter\n",
        "df['Tenure'] = df['Tenure'].map({'Freehold': 1, 'Leasehold': 0})\n",
        "\n",
        "# Aggregate low-count Mukims\n",
        "low_count_mukims = ['Mukim Cheras', 'Mukim Ampang', 'Mukim Ulu Kelang']\n",
        "df['Mukim'] = df['Mukim'].apply(lambda x: 'Other' if x in low_count_mukims else x)\n",
        "\n",
        "# Stricter outlier capping (99th percentile)\n",
        "price_cap = df['TransactionPrice'].quantile(0.99)\n",
        "df['TransactionPrice'] = np.clip(df['TransactionPrice'], 0, price_cap)\n",
        "area_cap = df['Parcel_sq_m'].quantile(0.99)\n",
        "df['Parcel_sq_m'] = np.clip(df['Parcel_sq_m'], 0, area_cap)\n",
        "\n",
        "# Log-transform\n",
        "df['TransactionPrice'] = np.log1p(df['TransactionPrice'])\n",
        "df['Parcel_sq_m'] = np.log1p(df['Parcel_sq_m'])\n",
        "\n",
        "# Features (drop Month, add Quarter)\n",
        "features = ['Parcel_sq_m', 'UnitLevel', 'Year', 'Quarter', 'Tenure'] + [col for col in pd.get_dummies(df['Mukim']).columns]\n",
        "X = pd.concat([df[['Parcel_sq_m', 'UnitLevel', 'Year', 'Quarter', 'Tenure']], pd.get_dummies(df['Mukim'])], axis=1)\n",
        "y = df['TransactionPrice']\n",
        "\n",
        "# Convert 'UnitLevel' to numeric, coercing errors to NaN and fill NaN with mean\n",
        "X['UnitLevel'] = pd.to_numeric(X['UnitLevel'], errors='coerce')\n",
        "X['UnitLevel'].fillna(X['UnitLevel'].mean(), inplace=True)\n",
        "\n",
        "# Robust scaling\n",
        "scaler = RobustScaler()\n",
        "X[['Parcel_sq_m', 'UnitLevel', 'Year', 'Quarter']] = scaler.fit_transform(X[['Parcel_sq_m', 'UnitLevel', 'Year', 'Quarter']])\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# RandomForest with GridSearchCV\n",
        "rf = RandomForestRegressor(random_state=42)\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200],\n",
        "    'max_depth': [10, 15, 20],\n",
        "    'min_samples_split': [5, 10]\n",
        "}\n",
        "grid_rf = GridSearchCV(rf, param_grid, cv=5, scoring='r2', n_jobs=-1)\n",
        "grid_rf.fit(X_train, y_train)\n",
        "y_pred_rf = grid_rf.predict(X_test)\n",
        "print(\"Best RandomForest Params:\", grid_rf.best_params_)\n",
        "print(\"RandomForest R:\", r2_score(y_test, y_pred_rf))\n",
        "print(\"RandomForest RMSE:\", np.sqrt(mean_squared_error(np.expm1(y_test), np.expm1(y_pred_rf))))\n",
        "\n",
        "# GradientBoosting with Huber loss\n",
        "gb = GradientBoostingRegressor(loss='huber', n_estimators=200, max_depth=5, learning_rate=0.05, random_state=42)\n",
        "gb.fit(X_train, y_train)\n",
        "y_pred_gb = gb.predict(X_test)\n",
        "print(\"GradientBoosting R:\", r2_score(y_test, y_pred_gb))\n",
        "print(\"GradientBoosting RMSE:\", np.sqrt(mean_squared_error(np.expm1(y_test), np.expm1(y_pred_gb))))\n",
        "\n",
        "# Feature importance\n",
        "importance_rf = pd.Series(grid_rf.best_estimator_.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
        "print(\"RandomForest Feature Importance:\\n\", importance_rf)\n",
        "importance_gb = pd.Series(gb.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
        "print(\"GradientBoosting Feature Importance:\\n\", importance_gb)\n",
        "\n",
        "# Cross-validation\n",
        "cv_rf = cross_val_score(grid_rf.best_estimator_, X, y, cv=5, scoring='r2')\n",
        "print(\"RandomForest 5-Fold CV R:\", cv_rf.mean(), \"\", cv_rf.std())\n",
        "cv_gb = cross_val_score(gb, X, y, cv=5, scoring='r2')\n",
        "print(\"GradientBoosting 5-Fold CV R:\", cv_gb.mean(), \"\", cv_gb.std())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "se54rRXjA47Q",
        "outputId": "ba7c102d-60b0-446f-8141-3d74f26ade0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<>:13: SyntaxWarning: invalid escape sequence '\\d'\n",
            "<>:13: SyntaxWarning: invalid escape sequence '\\d'\n",
            "/tmp/ipython-input-857963266.py:13: SyntaxWarning: invalid escape sequence '\\d'\n",
            "  df['Parcel_sq_m'] = df['ParcelArea'].astype(str).str.extract('(\\d+\\.?\\d*)')\n",
            "/usr/local/lib/python3.12/dist-packages/numpy/_core/fromnumeric.py:57: FutureWarning: Downcasting behavior in Series and DataFrame methods 'where', 'mask', and 'clip' is deprecated. In a future version this will not infer object dtypes or cast all-round floats to integers. Instead call result.infer_objects(copy=False) for object inference, or cast round floats explicitly. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  return bound(*args, **kwds)\n",
            "/tmp/ipython-input-857963266.py:42: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  X['UnitLevel'].fillna(X['UnitLevel'].mean(), inplace=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best RandomForest Params: {'max_depth': 15, 'min_samples_split': 5, 'n_estimators': 200}\n",
            "RandomForest R: 0.8762306266988277\n",
            "RandomForest RMSE: 254579.70034600073\n",
            "GradientBoosting R: 0.845153943156455\n",
            "GradientBoosting RMSE: 292818.0516736684\n",
            "RandomForest Feature Importance:\n",
            " Parcel_sq_m                 0.810560\n",
            "UnitLevel                   0.071381\n",
            "Mukim Setapak               0.023180\n",
            "Year                        0.020012\n",
            "Tenure                      0.016294\n",
            "Kuala Lumpur Town Centre    0.015045\n",
            "Quarter                     0.012981\n",
            "Mukim Batu                  0.010113\n",
            "Mukim Kuala Lumpur          0.009430\n",
            "Mukim Petaling              0.005654\n",
            "Other                       0.005349\n",
            "dtype: float64\n",
            "GradientBoosting Feature Importance:\n",
            " Parcel_sq_m                 0.853794\n",
            "UnitLevel                   0.065014\n",
            "Mukim Setapak               0.018048\n",
            "Tenure                      0.015547\n",
            "Mukim Kuala Lumpur          0.013973\n",
            "Mukim Batu                  0.012051\n",
            "Kuala Lumpur Town Centre    0.011635\n",
            "Mukim Petaling              0.003605\n",
            "Year                        0.003546\n",
            "Other                       0.002006\n",
            "Quarter                     0.000782\n",
            "dtype: float64\n",
            "RandomForest 5-Fold CV R: 0.7861228661572385  0.057116755646143845\n",
            "GradientBoosting 5-Fold CV R: 0.7680339115827067  0.070221273508875\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# To further reduce RMSE and overfitting\n",
        "\n",
        "\n",
        "*  Drops Year, Quarter to test overfitting reduction (VIF = 6.12 for Year).\n",
        "*  Uses 98th percentile capping for stricter outlier control.\n",
        "*  Tests XGBoost with quantile loss (median focus) to improve suburban price predictions.\n",
        "*  Optimizes RandomForest with broader GridSearchCV.\n",
        "Reports R, RMSE, importance, and CV."
      ],
      "metadata": {
        "id": "hMwP-ocXKfcs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from sklearn.metrics import r2_score, mean_squared_error\n",
        "\n",
        "# Load and preprocess\n",
        "url = \"https://raw.githubusercontent.com/englian1123/KL-High-Rise-Data/refs/heads/main/KLHighRise.csv\"\n",
        "df = pd.read_csv(url)\n",
        "df.rename(columns={'TransactionPrice  ': 'TransactionPrice'}, inplace=True)\n",
        "# Convert 'ParcelArea' to string before extracting numerical values\n",
        "df['Parcel_sq_m'] = df['ParcelArea'].astype(str).str.extract('(\\d+\\.?\\d*)').astype(float)\n",
        "df['Year'] = pd.to_datetime(df['TransactionDate'], format='%b-%y').dt.year\n",
        "df['Quarter'] = pd.to_datetime(df['TransactionDate'], format='%b-%y').dt.quarter\n",
        "df['Tenure'] = df['Tenure'].map({'Freehold': 1, 'Leasehold': 0})\n",
        "\n",
        "# Aggregate low-count Mukims\n",
        "low_count_mukims = ['Mukim Cheras', 'Mukim Ampang', 'Mukim Ulu Kelang']\n",
        "df['Mukim'] = df['Mukim'].apply(lambda x: 'Other' if x in low_count_mukims else x)\n",
        "\n",
        "# Stricter outlier capping (98th percentile)\n",
        "price_cap = df['TransactionPrice'].quantile(0.98)\n",
        "df['TransactionPrice'] = np.clip(df['TransactionPrice'], 0, price_cap)\n",
        "area_cap = df['Parcel_sq_m'].quantile(0.98)\n",
        "df['Parcel_sq_m'] = np.clip(df['Parcel_sq_m'], 0, area_cap)\n",
        "\n",
        "# Log-transform\n",
        "df['TransactionPrice'] = np.log1p(df['TransactionPrice'])\n",
        "df['Parcel_sq_m'] = np.log1p(df['Parcel_sq_m'])\n",
        "\n",
        "# Features (drop Year, Quarter for testing)\n",
        "features = ['Parcel_sq_m', 'UnitLevel', 'Tenure'] + [col for col in pd.get_dummies(df['Mukim']).columns]\n",
        "X = pd.concat([df[['Parcel_sq_m', 'UnitLevel', 'Tenure']], pd.get_dummies(df['Mukim'])], axis=1)\n",
        "y = df['TransactionPrice']\n",
        "\n",
        "# Convert 'UnitLevel' to numeric, coercing errors to NaN and fill NaN with mean\n",
        "X['UnitLevel'] = pd.to_numeric(X['UnitLevel'], errors='coerce')\n",
        "X['UnitLevel'].fillna(X['UnitLevel'].mean(), inplace=True)\n",
        "\n",
        "# Robust scaling\n",
        "scaler = RobustScaler()\n",
        "X[['Parcel_sq_m', 'UnitLevel']] = scaler.fit_transform(X[['Parcel_sq_m', 'UnitLevel']])\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# RandomForest with GridSearchCV\n",
        "rf = RandomForestRegressor(random_state=42)\n",
        "param_grid = {\n",
        "    'n_estimators': [200, 300],\n",
        "    'max_depth': [10, 15],\n",
        "    'min_samples_split': [10, 20]\n",
        "}\n",
        "grid_rf = GridSearchCV(rf, param_grid, cv=5, scoring='r2', n_jobs=-1)\n",
        "grid_rf.fit(X_train, y_train)\n",
        "y_pred_rf = grid_rf.predict(X_test)\n",
        "print(\"Best RandomForest Params:\", grid_rf.best_params_)\n",
        "print(\"RandomForest R:\", r2_score(y_test, y_pred_rf))\n",
        "print(\"RandomForest RMSE:\", np.sqrt(mean_squared_error(np.expm1(y_test), np.expm1(y_pred_rf))))\n",
        "\n",
        "# XGBoost with quantile loss\n",
        "xgb = XGBRegressor(objective='reg:quantileerror', quantile_alpha=0.5, n_estimators=200, max_depth=5, learning_rate=0.05, random_state=42)\n",
        "xgb.fit(X_train, y_train)\n",
        "y_pred_xgb = xgb.predict(X_test)\n",
        "print(\"XGBoost R:\", r2_score(y_test, y_pred_xgb))\n",
        "print(\"XGBoost RMSE:\", np.sqrt(mean_squared_error(np.expm1(y_test), np.expm1(y_pred_xgb))))\n",
        "\n",
        "# Feature importance\n",
        "importance_rf = pd.Series(grid_rf.best_estimator_.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
        "print(\"RandomForest Feature Importance:\\n\", importance_rf)\n",
        "importance_xgb = pd.Series(xgb.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
        "print(\"XGBoost Feature Importance:\\n\", importance_xgb)\n",
        "\n",
        "# Cross-validation\n",
        "cv_rf = cross_val_score(grid_rf.best_estimator_, X, y, cv=5, scoring='r2')\n",
        "print(\"RandomForest 5-Fold CV R:\", cv_rf.mean(), \"\", cv_rf.std())\n",
        "cv_xgb = cross_val_score(xgb, X, y, cv=5, scoring='r2')\n",
        "print(\"XGBoost 5-Fold CV R:\", cv_xgb.mean(), \"\", cv_xgb.std())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q7PPusomKvsa",
        "outputId": "293ef169-553d-4066-f99f-515245985362"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<>:14: SyntaxWarning: invalid escape sequence '\\d'\n",
            "<>:14: SyntaxWarning: invalid escape sequence '\\d'\n",
            "/tmp/ipython-input-290084585.py:14: SyntaxWarning: invalid escape sequence '\\d'\n",
            "  df['Parcel_sq_m'] = df['ParcelArea'].astype(str).str.extract('(\\d+\\.?\\d*)').astype(float)\n",
            "/tmp/ipython-input-290084585.py:40: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  X['UnitLevel'].fillna(X['UnitLevel'].mean(), inplace=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best RandomForest Params: {'max_depth': 15, 'min_samples_split': 10, 'n_estimators': 300}\n",
            "RandomForest R: 0.8782316791685606\n",
            "RandomForest RMSE: 239262.30940159122\n",
            "XGBoost R: 0.7896949759534738\n",
            "XGBoost RMSE: 295563.6738051206\n",
            "RandomForest Feature Importance:\n",
            " Parcel_sq_m                 0.833057\n",
            "UnitLevel                   0.078195\n",
            "Mukim Setapak               0.024631\n",
            "Tenure                      0.017127\n",
            "Kuala Lumpur Town Centre    0.015603\n",
            "Mukim Batu                  0.010189\n",
            "Mukim Kuala Lumpur          0.009555\n",
            "Mukim Petaling              0.005963\n",
            "Other                       0.005679\n",
            "dtype: float64\n",
            "XGBoost Feature Importance:\n",
            " Parcel_sq_m                 0.376675\n",
            "Mukim Setapak               0.145549\n",
            "Mukim Batu                  0.127818\n",
            "Mukim Kuala Lumpur          0.066659\n",
            "Tenure                      0.062251\n",
            "UnitLevel                   0.060998\n",
            "Kuala Lumpur Town Centre    0.054646\n",
            "Other                       0.054044\n",
            "Mukim Petaling              0.051360\n",
            "dtype: float32\n",
            "RandomForest 5-Fold CV R: 0.7766003772897112  0.06336039701627941\n",
            "XGBoost 5-Fold CV R: 0.7234231227466547  0.08471504327127026\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Optimization**\n",
        "\n",
        "*  Uses quantile_alpha=0.5 for XGBoost (median focus).\n",
        "*  Increases suburban weights (2.0).\n",
        "*  Stronger regularization (max_depth=4, min_samples_split=30).\n",
        "*  Drops Other Mukim option included in comments if needed."
      ],
      "metadata": {
        "id": "Hp3JJlxPPIKO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from sklearn.metrics import r2_score, mean_squared_error\n",
        "\n",
        "# Load and preprocess\n",
        "url = \"https://raw.githubusercontent.com/englian1123/KL-High-Rise-Data/refs/heads/main/KLHighRise.csv\"\n",
        "df = pd.read_csv(url)\n",
        "df.rename(columns={'TransactionPrice  ': 'TransactionPrice'}, inplace=True)\n",
        "df['Parcel_sq_m'] = df['ParcelArea'].astype(str).str.extract('(\\d+\\.?\\d*)').astype(float)\n",
        "df['Tenure'] = df['Tenure'].map({'Freehold': 1, 'Leasehold': 0})\n",
        "\n",
        "# Aggregate low-count Mukims\n",
        "low_count_mukims = ['Mukim Cheras', 'Mukim Ampang', 'Mukim Ulu Kelang']\n",
        "df['Mukim'] = df['Mukim'].apply(lambda x: 'Other' if x in low_count_mukims else x)\n",
        "\n",
        "# Outlier capping (97th percentile)\n",
        "price_cap = df['TransactionPrice'].quantile(0.97)\n",
        "df['TransactionPrice'] = np.clip(df['TransactionPrice'], 0, price_cap)\n",
        "area_cap = df['Parcel_sq_m'].quantile(0.97)\n",
        "df['Parcel_sq_m'] = np.clip(df['Parcel_sq_m'], 0, area_cap)\n",
        "\n",
        "# Log-transform\n",
        "df['TransactionPrice'] = np.log1p(df['TransactionPrice'])\n",
        "df['Parcel_sq_m'] = np.log1p(df['Parcel_sq_m'])\n",
        "\n",
        "# Mukim * Tenure interaction\n",
        "mukim_dummies = pd.get_dummies(df['Mukim'], prefix='Mukim')\n",
        "for col in mukim_dummies.columns:\n",
        "    df[f'{col}_Tenure'] = mukim_dummies[col] * df['Tenure']\n",
        "\n",
        "# Features\n",
        "features = ['Parcel_sq_m', 'UnitLevel', 'Tenure'] + list(mukim_dummies.columns) + [f'{col}_Tenure' for col in mukim_dummies.columns]\n",
        "X = pd.concat([df[['Parcel_sq_m', 'UnitLevel', 'Tenure']], mukim_dummies, df[[f'{col}_Tenure' for col in mukim_dummies.columns]]], axis=1)\n",
        "y = df['TransactionPrice']\n",
        "\n",
        "# Convert UnitLevel to numeric\n",
        "X['UnitLevel'] = pd.to_numeric(X['UnitLevel'], errors='coerce')\n",
        "X['UnitLevel'].fillna(X['UnitLevel'].mean(), inplace=True)\n",
        "\n",
        "# Robust scaling\n",
        "scaler = RobustScaler()\n",
        "X[['Parcel_sq_m', 'UnitLevel']] = scaler.fit_transform(X[['Parcel_sq_m', 'UnitLevel']])\n",
        "\n",
        "# Sample weights\n",
        "weights = df['Mukim'].apply(lambda x: 2.0 if x in ['Mukim Setapak', 'Mukim Petaling'] else 1.0)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test, w_train, w_test = train_test_split(X, y, weights, test_size=0.2, random_state=42)\n",
        "\n",
        "# XGBoost with tuned quantile loss\n",
        "xgb = XGBRegressor(objective='reg:quantileerror', quantile_alpha=0.5, n_estimators=300, max_depth=4, learning_rate=0.02, random_state=42)\n",
        "xgb.fit(X_train, y_train, sample_weight=w_train)\n",
        "y_pred_xgb = xgb.predict(X_test)\n",
        "print(\"XGBoost R:\", r2_score(y_test, y_pred_xgb))\n",
        "print(\"XGBoost RMSE:\", np.sqrt(mean_squared_error(np.expm1(y_test), np.expm1(y_pred_xgb))))\n",
        "\n",
        "# RandomForest\n",
        "rf = RandomForestRegressor(n_estimators=300, max_depth=10, min_samples_split=30, random_state=42)\n",
        "rf.fit(X_train, y_train, sample_weight=w_train)\n",
        "y_pred_rf = rf.predict(X_test)\n",
        "print(\"RandomForest R:\", r2_score(y_test, y_pred_rf))\n",
        "print(\"RandomForest RMSE:\", np.sqrt(mean_squared_error(np.expm1(y_test), np.expm1(y_pred_rf))))\n",
        "\n",
        "# Feature importance\n",
        "importance_xgb = pd.Series(xgb.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
        "print(\"XGBoost Feature Importance:\\n\", importance_xgb)\n",
        "importance_rf = pd.Series(rf.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
        "print(\"RandomForest Feature Importance:\\n\", importance_rf)\n",
        "\n",
        "# Cross-validation\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "cv_xgb_scores = []\n",
        "cv_rf_scores = []\n",
        "\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train_fold, X_test_fold = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train_fold, y_test_fold = y.iloc[train_index], y.iloc[test_index]\n",
        "    weights_train_fold, weights_test_fold = weights.iloc[train_index], weights.iloc[test_index]\n",
        "\n",
        "    # XGBoost\n",
        "    xgb_fold = XGBRegressor(objective='reg:quantileerror', quantile_alpha=0.5, n_estimators=300, max_depth=4, learning_rate=0.02, random_state=42)\n",
        "    xgb_fold.fit(X_train_fold, y_train_fold, sample_weight=weights_train_fold)\n",
        "    y_pred_xgb_fold = xgb_fold.predict(X_test_fold)\n",
        "    cv_xgb_scores.append(r2_score(y_test_fold, y_pred_xgb_fold, sample_weight=weights_test_fold))\n",
        "\n",
        "    # RandomForest\n",
        "    rf_fold = RandomForestRegressor(n_estimators=300, max_depth=10, min_samples_split=30, random_state=42)\n",
        "    rf_fold.fit(X_train_fold, y_train_fold, sample_weight=weights_train_fold)\n",
        "    y_pred_rf_fold = rf_fold.predict(X_test_fold)\n",
        "    cv_rf_scores.append(r2_score(y_test_fold, y_pred_rf_fold, sample_weight=weights_test_fold))\n",
        "\n",
        "print(\"XGBoost 5-Fold CV R:\", np.mean(cv_xgb_scores), \"\", np.std(cv_xgb_scores))\n",
        "print(\"RandomForest 5-Fold CV R:\", np.mean(cv_rf_scores), \"\", np.std(cv_rf_scores))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LsmFk2yMPmzY",
        "outputId": "60bfda14-4e54-4d7e-95d5-ec95d1d698c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<>:13: SyntaxWarning: invalid escape sequence '\\d'\n",
            "<>:13: SyntaxWarning: invalid escape sequence '\\d'\n",
            "/tmp/ipython-input-704576696.py:13: SyntaxWarning: invalid escape sequence '\\d'\n",
            "  df['Parcel_sq_m'] = df['ParcelArea'].astype(str).str.extract('(\\d+\\.?\\d*)').astype(float)\n",
            "/usr/local/lib/python3.12/dist-packages/numpy/_core/fromnumeric.py:57: FutureWarning: Downcasting behavior in Series and DataFrame methods 'where', 'mask', and 'clip' is deprecated. In a future version this will not infer object dtypes or cast all-round floats to integers. Instead call result.infer_objects(copy=False) for object inference, or cast round floats explicitly. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  return bound(*args, **kwds)\n",
            "/tmp/ipython-input-704576696.py:42: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  X['UnitLevel'].fillna(X['UnitLevel'].mean(), inplace=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XGBoost R: 0.7672396984310825\n",
            "XGBoost RMSE: 292856.9202428784\n",
            "RandomForest R: 0.8453533517095193\n",
            "RandomForest RMSE: 249884.48422834667\n",
            "XGBoost Feature Importance:\n",
            " Parcel_sq_m                              0.330985\n",
            "Mukim_Mukim Setapak                      0.095704\n",
            "Mukim_Mukim Batu_Tenure                  0.091845\n",
            "UnitLevel                                0.077126\n",
            "Mukim_Kuala Lumpur Town Centre_Tenure    0.062098\n",
            "Mukim_Mukim Setapak_Tenure               0.046881\n",
            "Mukim_Mukim Petaling_Tenure              0.044505\n",
            "Mukim_Mukim Kuala Lumpur                 0.043831\n",
            "Tenure                                   0.043141\n",
            "Mukim_Other                              0.041693\n",
            "Mukim_Mukim Petaling                     0.037315\n",
            "Mukim_Mukim Batu                         0.036560\n",
            "Mukim_Mukim Kuala Lumpur_Tenure          0.020085\n",
            "Mukim_Other_Tenure                       0.017542\n",
            "Mukim_Kuala Lumpur Town Centre           0.010688\n",
            "dtype: float32\n",
            "RandomForest Feature Importance:\n",
            " Parcel_sq_m                              0.861319\n",
            "UnitLevel                                0.057115\n",
            "Mukim_Mukim Setapak                      0.024424\n",
            "Mukim_Kuala Lumpur Town Centre_Tenure    0.011843\n",
            "Mukim_Mukim Batu_Tenure                  0.009931\n",
            "Tenure                                   0.007556\n",
            "Mukim_Mukim Kuala Lumpur                 0.006591\n",
            "Mukim_Mukim Petaling                     0.004705\n",
            "Mukim_Other                              0.003975\n",
            "Mukim_Kuala Lumpur Town Centre           0.003679\n",
            "Mukim_Mukim Petaling_Tenure              0.003208\n",
            "Mukim_Mukim Setapak_Tenure               0.002442\n",
            "Mukim_Mukim Kuala Lumpur_Tenure          0.001954\n",
            "Mukim_Mukim Batu                         0.000844\n",
            "Mukim_Other_Tenure                       0.000413\n",
            "dtype: float64\n",
            "XGBoost 5-Fold CV R: 0.7416907554843111  0.008289779333534057\n",
            "RandomForest 5-Fold CV R: 0.8273551553190845  0.010822088126175198\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# To improve XGBoost and reduce RMSE\n",
        "\n",
        "*   Drops Mukim_Other (low importance).\n",
        "*   Uses 96th percentile capping.\n",
        "*   Adds Mukim_Parcel_sq_m and target-encoded Scheme_Name_encoded.\n",
        "*   Uses XGBoost with squared loss, higher n_estimators (500), and tuned parameters.\n",
        "*   Increases suburban weights (2.5)."
      ],
      "metadata": {
        "id": "A4wdEpcbSsya"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from sklearn.metrics import r2_score, mean_squared_error\n",
        "\n",
        "# Load and preprocess\n",
        "url = \"https://raw.githubusercontent.com/englian1123/KL-High-Rise-Data/refs/heads/main/KLHighRise.csv\"\n",
        "df = pd.read_csv(url)\n",
        "df.rename(columns={'TransactionPrice  ': 'TransactionPrice'}, inplace=True)\n",
        "df['Parcel_sq_m'] = df['ParcelArea'].astype(str).str.extract('(\\d+\\.?\\d*)').astype(float)\n",
        "df['Tenure'] = df['Tenure'].map({'Freehold': 1, 'Leasehold': 0})\n",
        "\n",
        "# Aggregate low-count Mukims, drop Other\n",
        "low_count_mukims = ['Mukim Cheras', 'Mukim Ampang', 'Mukim Ulu Kelang']\n",
        "df['Mukim'] = df['Mukim'].apply(lambda x: 'Other' if x in low_count_mukims else x)\n",
        "df = df[df['Mukim'] != 'Other']  # Drop Other\n",
        "\n",
        "# Outlier capping (96th percentile)\n",
        "price_cap = df['TransactionPrice'].quantile(0.96)\n",
        "df['TransactionPrice'] = np.clip(df['TransactionPrice'], 0, price_cap)\n",
        "area_cap = df['Parcel_sq_m'].quantile(0.96)\n",
        "df['Parcel_sq_m'] = np.clip(df['Parcel_sq_m'], 0, area_cap)\n",
        "\n",
        "# Log-transform\n",
        "df['TransactionPrice'] = np.log1p(df['TransactionPrice'])\n",
        "df['Parcel_sq_m'] = np.log1p(df['Parcel_sq_m'])\n",
        "\n",
        "# Mukim * Tenure and Mukim * Parcel_sq_m interactions\n",
        "mukim_dummies = pd.get_dummies(df['Mukim'], prefix='Mukim')\n",
        "for col in mukim_dummies.columns:\n",
        "    df[f'{col}_Tenure'] = mukim_dummies[col] * df['Tenure']\n",
        "    df[f'{col}_Parcel_sq_m'] = mukim_dummies[col] * df['Parcel_sq_m']\n",
        "\n",
        "# Target encode Scheme Name/Area\n",
        "scheme_encoding = df.groupby('SchemeName')['TransactionPrice'].mean()\n",
        "df['Scheme_Name_encoded'] = df['SchemeName'].map(scheme_encoding)\n",
        "\n",
        "# Features\n",
        "features = ['Parcel_sq_m', 'UnitLevel', 'Tenure', 'Scheme_Name_encoded'] + list(mukim_dummies.columns) + \\\n",
        "           [f'{col}_Tenure' for col in mukim_dummies.columns] + [f'{col}_Parcel_sq_m' for col in mukim_dummies.columns]\n",
        "X = pd.concat([df[['Parcel_sq_m', 'UnitLevel', 'Tenure', 'Scheme_Name_encoded']], mukim_dummies,\n",
        "               df[[f'{col}_Tenure' for col in mukim_dummies.columns]], df[[f'{col}_Parcel_sq_m' for col in mukim_dummies.columns]]], axis=1)\n",
        "y = df['TransactionPrice']\n",
        "\n",
        "# Convert UnitLevel to numeric\n",
        "X['UnitLevel'] = pd.to_numeric(X['UnitLevel'], errors='coerce')\n",
        "X['UnitLevel'].fillna(X['UnitLevel'].mean(), inplace=True)\n",
        "\n",
        "# Robust scaling\n",
        "scaler = RobustScaler()\n",
        "X[['Parcel_sq_m', 'UnitLevel', 'Scheme_Name_encoded']] = scaler.fit_transform(X[['Parcel_sq_m', 'UnitLevel', 'Scheme_Name_encoded']])\n",
        "\n",
        "# Sample weights\n",
        "weights = df['Mukim'].apply(lambda x: 2.5 if x in ['Mukim Setapak', 'Mukim Petaling'] else 1.0)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test, w_train, w_test = train_test_split(X, y, weights, test_size=0.2, random_state=42)\n",
        "\n",
        "# XGBoost with squared loss\n",
        "xgb = XGBRegressor(objective='reg:squarederror', n_estimators=500, max_depth=3, learning_rate=0.05, random_state=42)\n",
        "xgb.fit(X_train, y_train, sample_weight=w_train)\n",
        "y_pred_xgb = xgb.predict(X_test)\n",
        "print(\"XGBoost R:\", r2_score(y_test, y_pred_xgb))\n",
        "print(\"XGBoost RMSE:\", np.sqrt(mean_squared_error(np.expm1(y_test), np.expm1(y_pred_xgb))))\n",
        "\n",
        "# RandomForest\n",
        "rf = RandomForestRegressor(n_estimators=300, max_depth=10, min_samples_split=40, random_state=42)\n",
        "rf.fit(X_train, y_train, sample_weight=w_train)\n",
        "y_pred_rf = rf.predict(X_test)\n",
        "print(\"RandomForest R:\", r2_score(y_test, y_pred_rf))\n",
        "print(\"RandomForest RMSE:\", np.sqrt(mean_squared_error(np.expm1(y_test), np.expm1(y_pred_rf))))\n",
        "\n",
        "# Feature importance\n",
        "importance_xgb = pd.Series(xgb.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
        "print(\"XGBoost Feature Importance:\\n\", importance_xgb)\n",
        "importance_rf = pd.Series(rf.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
        "print(\"RandomForest Feature Importance:\\n\", importance_rf)\n",
        "\n",
        "# Cross-validation\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "cv_xgb_scores = []\n",
        "cv_rf_scores = []\n",
        "\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train_fold, X_test_fold = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train_fold, y_test_fold = y.iloc[train_index], y.iloc[test_index]\n",
        "    weights_train_fold, weights_test_fold = weights.iloc[train_index], weights.iloc[test_index]\n",
        "\n",
        "    # XGBoost\n",
        "    xgb_fold = XGBRegressor(objective='reg:squarederror', n_estimators=500, max_depth=3, learning_rate=0.05, random_state=42)\n",
        "    xgb_fold.fit(X_train_fold, y_train_fold, sample_weight=weights_train_fold)\n",
        "    y_pred_xgb_fold = xgb_fold.predict(X_test_fold)\n",
        "    cv_xgb_scores.append(r2_score(y_test_fold, y_pred_xgb_fold, sample_weight=weights_test_fold))\n",
        "\n",
        "    # RandomForest\n",
        "    rf_fold = RandomForestRegressor(n_estimators=300, max_depth=10, min_samples_split=40, random_state=42)\n",
        "    rf_fold.fit(X_train_fold, y_train_fold, sample_weight=weights_train_fold)\n",
        "    y_pred_rf_fold = rf_fold.predict(X_test_fold)\n",
        "    cv_rf_scores.append(r2_score(y_test_fold, y_pred_rf_fold, sample_weight=weights_test_fold))\n",
        "\n",
        "print(\"XGBoost 5-Fold CV R:\", np.mean(cv_xgb_scores), \"\", np.std(cv_xgb_scores))\n",
        "print(\"RandomForest 5-Fold CV R:\", np.mean(cv_rf_scores), \"\", np.std(cv_rf_scores))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dhSOGjtLTBL3",
        "outputId": "2786e02f-8480-4d3e-bff6-8d64733f3137"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<>:13: SyntaxWarning: invalid escape sequence '\\d'\n",
            "<>:13: SyntaxWarning: invalid escape sequence '\\d'\n",
            "/tmp/ipython-input-3711318855.py:13: SyntaxWarning: invalid escape sequence '\\d'\n",
            "  df['Parcel_sq_m'] = df['ParcelArea'].astype(str).str.extract('(\\d+\\.?\\d*)').astype(float)\n",
            "/tmp/ipython-input-3711318855.py:50: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  X['UnitLevel'].fillna(X['UnitLevel'].mean(), inplace=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XGBoost R: 0.9496549341410995\n",
            "XGBoost RMSE: 149482.3500173399\n",
            "RandomForest R: 0.9536822856452295\n",
            "RandomForest RMSE: 135239.86274865468\n",
            "XGBoost Feature Importance:\n",
            " Scheme_Name_encoded                           0.650578\n",
            "Parcel_sq_m                                   0.176450\n",
            "Mukim_Kuala Lumpur Town Centre                0.029646\n",
            "Mukim_Mukim Setapak_Parcel_sq_m               0.027879\n",
            "UnitLevel                                     0.021174\n",
            "Mukim_Kuala Lumpur Town Centre_Tenure         0.017173\n",
            "Mukim_Mukim Setapak_Tenure                    0.012542\n",
            "Mukim_Mukim Setapak                           0.011541\n",
            "Mukim_Mukim Kuala Lumpur                      0.008844\n",
            "Mukim_Mukim Petaling_Tenure                   0.007185\n",
            "Mukim_Mukim Kuala Lumpur_Tenure               0.006150\n",
            "Mukim_Kuala Lumpur Town Centre_Parcel_sq_m    0.005000\n",
            "Mukim_Mukim Batu_Tenure                       0.004719\n",
            "Mukim_Mukim Batu                              0.004442\n",
            "Mukim_Mukim Petaling_Parcel_sq_m              0.004314\n",
            "Tenure                                        0.004128\n",
            "Mukim_Mukim Batu_Parcel_sq_m                  0.004064\n",
            "Mukim_Mukim Kuala Lumpur_Parcel_sq_m          0.004029\n",
            "Mukim_Mukim Petaling                          0.000143\n",
            "dtype: float32\n",
            "RandomForest Feature Importance:\n",
            " Scheme_Name_encoded                           0.889712\n",
            "Parcel_sq_m                                   0.096296\n",
            "Mukim_Mukim Setapak_Parcel_sq_m               0.005059\n",
            "UnitLevel                                     0.002780\n",
            "Mukim_Mukim Petaling_Parcel_sq_m              0.002018\n",
            "Mukim_Kuala Lumpur Town Centre_Parcel_sq_m    0.000792\n",
            "Mukim_Mukim Batu_Parcel_sq_m                  0.000789\n",
            "Mukim_Mukim Setapak_Tenure                    0.000645\n",
            "Mukim_Mukim Kuala Lumpur_Parcel_sq_m          0.000468\n",
            "Mukim_Kuala Lumpur Town Centre_Tenure         0.000356\n",
            "Mukim_Mukim Setapak                           0.000317\n",
            "Tenure                                        0.000293\n",
            "Mukim_Mukim Petaling_Tenure                   0.000147\n",
            "Mukim_Mukim Petaling                          0.000103\n",
            "Mukim_Mukim Batu_Tenure                       0.000057\n",
            "Mukim_Mukim Batu                              0.000055\n",
            "Mukim_Mukim Kuala Lumpur_Tenure               0.000051\n",
            "Mukim_Kuala Lumpur Town Centre                0.000042\n",
            "Mukim_Mukim Kuala Lumpur                      0.000019\n",
            "dtype: float64\n",
            "XGBoost 5-Fold CV R: 0.9408775747931729  0.0035822098133298148\n",
            "RandomForest 5-Fold CV R: 0.9394072329944214  0.004972434343530849\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# To fine-tune and validate suburban performance:\n",
        "\n",
        "*   Uses 95th percentile capping.\n",
        "*   Prunes low-importance Mukims (Petaling, Batu, Kuala Lumpur) and interactions.\n",
        "*   Adds binned UnitLevel (Low/Mid/High).\n",
        "*   Increases suburban weights (3.0).\n",
        "*   Tunes XGBoost (n_estimators=700, learning_rate=0.1).\n",
        "*   Validates suburban performance (Setapak/Petaling)."
      ],
      "metadata": {
        "id": "6x9icM6GXPQm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from sklearn.metrics import r2_score, mean_squared_error\n",
        "\n",
        "# Load and preprocess\n",
        "url = \"https://raw.githubusercontent.com/englian1123/KL-High-Rise-Data/refs/heads/main/KLHighRise.csv\"\n",
        "df = pd.read_csv(url)\n",
        "df.rename(columns={'TransactionPrice  ': 'TransactionPrice'}, inplace=True)\n",
        "df['Parcel_sq_m'] = df['ParcelArea'].astype(str).str.extract('(\\d+\\.?\\d*)').astype(float)\n",
        "df['Tenure'] = df['Tenure'].map({'Freehold': 1, 'Leasehold': 0})\n",
        "\n",
        "# Drop low-count Mukims\n",
        "low_count_mukims = ['Mukim Cheras', 'Mukim Ampang', 'Mukim Ulu Kelang']\n",
        "df = df[~df['Mukim'].isin(low_count_mukims)]\n",
        "\n",
        "# Outlier capping (95th percentile)\n",
        "price_cap = df['TransactionPrice'].quantile(0.95)\n",
        "df['TransactionPrice'] = np.clip(df['TransactionPrice'], 0, price_cap)\n",
        "area_cap = df['Parcel_sq_m'].quantile(0.95)\n",
        "df['Parcel_sq_m'] = np.clip(df['Parcel_sq_m'], 0, area_cap)\n",
        "\n",
        "# Log-transform\n",
        "df['TransactionPrice'] = np.log1p(df['TransactionPrice'])\n",
        "df['Parcel_sq_m'] = np.log1p(df['Parcel_sq_m'])\n",
        "\n",
        "# Target encode Scheme Name/Area\n",
        "scheme_encoding = df.groupby('SchemeName')['TransactionPrice'].mean()\n",
        "df['Scheme_Name_encoded'] = df['SchemeName'].map(scheme_encoding)\n",
        "\n",
        "# Bin UnitLevel\n",
        "\n",
        "# Map common non-numeric values\n",
        "# unit_level_map = {'Ground': 0, 'Basement': -1, 'Penthouse': 50, 'Mezzanine': 1}  # Adjust based on data\n",
        "# df['UnitLevel_clean'] = df['UnitLevel'].replace(unit_level_map)\n",
        "\n",
        "# Convert to numeric, impute with mean\n",
        "df['UnitLevel'] = pd.to_numeric(df['UnitLevel'], errors='coerce')\n",
        "df['UnitLevel'].fillna(df['UnitLevel'].mean(), inplace=True)\n",
        "# df['UnitLevel'] = pd.to_numeric(df['UnitLevel'], errors='coerce').fillna(df['UnitLevel'].mean())\n",
        "df['UnitLevel_binned'] = pd.cut(df['UnitLevel'], bins=[-float('inf'), 10, 20, float('inf')], labels=['Low', 'Mid', 'High'])\n",
        "level_dummies = pd.get_dummies(df['UnitLevel_binned'], prefix='UnitLevel')\n",
        "\n",
        "# Mukim * Tenure and Mukim * Parcel_sq_m\n",
        "mukim_dummies = pd.get_dummies(df['Mukim'], prefix='Mukim')\n",
        "for col in ['Mukim_Mukim Setapak', 'Mukim_Kuala Lumpur Town Centre']:\n",
        "    df[f'{col}_Tenure'] = mukim_dummies[col] * df['Tenure']\n",
        "    df[f'{col}_Parcel_sq_m'] = mukim_dummies[col] * df['Parcel_sq_m']\n",
        "\n",
        "# Features\n",
        "features = ['Scheme_Name_encoded', 'Parcel_sq_m', 'Tenure'] + list(mukim_dummies.columns) + \\\n",
        "           [f'{col}_Tenure' for col in ['Mukim_Mukim Setapak', 'Mukim_Kuala Lumpur Town Centre']] + \\\n",
        "           [f'{col}_Parcel_sq_m' for col in ['Mukim_Mukim Setapak', 'Mukim_Kuala Lumpur Town Centre']] + \\\n",
        "           list(level_dummies.columns)\n",
        "X = pd.concat([df[['Scheme_Name_encoded', 'Parcel_sq_m', 'Tenure']], mukim_dummies,\n",
        "               df[[f'{col}_Tenure' for col in ['Mukim_Mukim Setapak', 'Mukim_Kuala Lumpur Town Centre']]],\n",
        "               df[[f'{col}_Parcel_sq_m' for col in ['Mukim_Mukim Setapak', 'Mukim_Kuala Lumpur Town Centre']]],\n",
        "               level_dummies], axis=1)\n",
        "y = df['TransactionPrice']\n",
        "\n",
        "# Robust scaling\n",
        "scaler = RobustScaler()\n",
        "X[['Scheme_Name_encoded', 'Parcel_sq_m']] = scaler.fit_transform(X[['Scheme_Name_encoded', 'Parcel_sq_m']])\n",
        "\n",
        "# Sample weights\n",
        "weights = df['Mukim'].apply(lambda x: 3.0 if x in ['Mukim Setapak', 'Mukim Petaling'] else 1.0)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test, w_train, w_test = train_test_split(X, y, weights, test_size=0.2, random_state=42)\n",
        "\n",
        "# XGBoost\n",
        "xgb = XGBRegressor(objective='reg:squarederror', n_estimators=700, max_depth=3, learning_rate=0.1, random_state=42)\n",
        "xgb.fit(X_train, y_train, sample_weight=w_train)\n",
        "y_pred_xgb = xgb.predict(X_test)\n",
        "print(\"XGBoost R:\", r2_score(y_test, y_pred_xgb))\n",
        "print(\"XGBoost RMSE:\", np.sqrt(mean_squared_error(np.expm1(y_test), np.expm1(y_pred_xgb))))\n",
        "\n",
        "# RandomForest\n",
        "rf = RandomForestRegressor(n_estimators=300, max_depth=10, min_samples_split=50, random_state=42)\n",
        "rf.fit(X_train, y_train, sample_weight=w_train)\n",
        "y_pred_rf = rf.predict(X_test)\n",
        "print(\"RandomForest R:\", r2_score(y_test, y_pred_rf))\n",
        "print(\"RandomForest RMSE:\", np.sqrt(mean_squared_error(np.expm1(y_test), np.expm1(y_pred_rf))))\n",
        "\n",
        "# Feature importance\n",
        "importance_xgb = pd.Series(xgb.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
        "print(\"XGBoost Feature Importance:\\n\", importance_xgb)\n",
        "importance_rf = pd.Series(rf.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
        "print(\"RandomForest Feature Importance:\\n\", importance_rf)\n",
        "\n",
        "# Cross-validation\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "cv_xgb_scores = []\n",
        "cv_rf_scores = []\n",
        "\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train_fold, X_test_fold = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train_fold, y_test_fold = y.iloc[train_index], y.iloc[test_index]\n",
        "    weights_train_fold, weights_test_fold = weights.iloc[train_index], weights.iloc[test_index]\n",
        "\n",
        "    # XGBoost\n",
        "    xgb_fold = XGBRegressor(objective='reg:squarederror', n_estimators=700, max_depth=3, learning_rate=0.1, random_state=42)\n",
        "    xgb_fold.fit(X_train_fold, y_train_fold, sample_weight=weights_train_fold)\n",
        "    y_pred_xgb_fold = xgb_fold.predict(X_test_fold)\n",
        "    cv_xgb_scores.append(r2_score(y_test_fold, y_pred_xgb_fold, sample_weight=weights_test_fold))\n",
        "\n",
        "    # RandomForest\n",
        "    rf_fold = RandomForestRegressor(n_estimators=300, max_depth=10, min_samples_split=50, random_state=42)\n",
        "    rf_fold.fit(X_train_fold, y_train_fold, sample_weight=weights_train_fold)\n",
        "    y_pred_rf_fold = rf_fold.predict(X_test_fold)\n",
        "    cv_rf_scores.append(r2_score(y_test_fold, y_pred_rf_fold, sample_weight=weights_test_fold))\n",
        "\n",
        "print(\"XGBoost 5-Fold CV R:\", np.mean(cv_xgb_scores), \"\", np.std(cv_xgb_scores))\n",
        "print(\"RandomForest 5-Fold CV R:\", np.mean(cv_rf_scores), \"\", np.std(cv_rf_scores))\n",
        "\n",
        "# Validate suburban performance\n",
        "suburban_mask = df.loc[X_test.index, 'Mukim'].isin(['Mukim Setapak', 'Mukim Petaling'])\n",
        "print(\"Suburban XGBoost RMSE:\", np.sqrt(mean_squared_error(np.expm1(y_test[suburban_mask]), np.expm1(y_pred_xgb[suburban_mask]))))\n",
        "print(\"Suburban RandomForest RMSE:\", np.sqrt(mean_squared_error(np.expm1(y_test[suburban_mask]), np.expm1(y_pred_rf[suburban_mask]))))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bj3j-GZ_XZn5",
        "outputId": "849f552a-18e2-4bff-a9f3-33a94a2d43e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<>:13: SyntaxWarning: invalid escape sequence '\\d'\n",
            "<>:13: SyntaxWarning: invalid escape sequence '\\d'\n",
            "/tmp/ipython-input-872297916.py:13: SyntaxWarning: invalid escape sequence '\\d'\n",
            "  df['Parcel_sq_m'] = df['ParcelArea'].astype(str).str.extract('(\\d+\\.?\\d*)').astype(float)\n",
            "/tmp/ipython-input-872297916.py:42: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['UnitLevel'].fillna(df['UnitLevel'].mean(), inplace=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XGBoost R: 0.9570161848468173\n",
            "XGBoost RMSE: 129358.25043571152\n",
            "RandomForest R: 0.9527931712696684\n",
            "RandomForest RMSE: 129465.41997394348\n",
            "XGBoost Feature Importance:\n",
            " Scheme_Name_encoded                           0.582653\n",
            "Parcel_sq_m                                   0.142738\n",
            "Mukim_Kuala Lumpur Town Centre_Tenure         0.056382\n",
            "Mukim_Mukim Setapak                           0.052777\n",
            "Mukim_Kuala Lumpur Town Centre                0.036214\n",
            "Mukim_Mukim Setapak_Parcel_sq_m               0.032781\n",
            "UnitLevel_Mid                                 0.021703\n",
            "UnitLevel_High                                0.020957\n",
            "Mukim_Mukim Petaling                          0.010355\n",
            "Mukim_Mukim Setapak_Tenure                    0.009160\n",
            "Tenure                                        0.008389\n",
            "Mukim_Mukim Kuala Lumpur                      0.007580\n",
            "UnitLevel_Low                                 0.007336\n",
            "Mukim_Mukim Batu                              0.005620\n",
            "Mukim_Kuala Lumpur Town Centre_Parcel_sq_m    0.005355\n",
            "dtype: float32\n",
            "RandomForest Feature Importance:\n",
            " Scheme_Name_encoded                           0.889799\n",
            "Parcel_sq_m                                   0.099539\n",
            "Mukim_Mukim Setapak_Parcel_sq_m               0.006277\n",
            "Mukim_Mukim Setapak_Tenure                    0.000892\n",
            "Mukim_Kuala Lumpur Town Centre_Parcel_sq_m    0.000780\n",
            "Mukim_Mukim Petaling                          0.000676\n",
            "UnitLevel_High                                0.000411\n",
            "Tenure                                        0.000336\n",
            "Mukim_Kuala Lumpur Town Centre_Tenure         0.000312\n",
            "Mukim_Mukim Batu                              0.000293\n",
            "Mukim_Mukim Setapak                           0.000275\n",
            "UnitLevel_Low                                 0.000186\n",
            "Mukim_Mukim Kuala Lumpur                      0.000117\n",
            "UnitLevel_Mid                                 0.000054\n",
            "Mukim_Kuala Lumpur Town Centre                0.000053\n",
            "dtype: float64\n",
            "XGBoost 5-Fold CV R: 0.9414127697455568  0.004744257757354726\n",
            "RandomForest 5-Fold CV R: 0.9354128848774861  0.005415691368655272\n",
            "Suburban XGBoost RMSE: 86722.48684936762\n",
            "Suburban RandomForest RMSE: 88443.26260354606\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# To push RMSE lower and simplify:\n",
        "\n",
        "*  Uses 94th percentile capping (~800k RM, ~120 sq.m).\n",
        "*  Increases suburban weights (4.0).\n",
        "*  Implements ensemble (average RandomForest + XGBoost).\n",
        "*  Maintains pruned features and UnitLevel_binned.\n",
        "*  Evaluates ensemble performance."
      ],
      "metadata": {
        "id": "Xe5Vfzgfh5Hb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from sklearn.metrics import r2_score, mean_squared_error\n",
        "\n",
        "# Load and preprocess\n",
        "url = \"https://raw.githubusercontent.com/englian1123/KL-High-Rise-Data/refs/heads/main/KLHighRise.csv\"\n",
        "df = pd.read_csv(url)\n",
        "df.rename(columns={'TransactionPrice  ': 'TransactionPrice'}, inplace=True)\n",
        "df['Parcel_sq_m'] = df['ParcelArea'].astype(str).str.extract('(\\d+\\.?\\d*)').astype(float)\n",
        "df['Tenure'] = df['Tenure'].map({'Freehold': 1, 'Leasehold': 0})\n",
        "\n",
        "# Drop low-count Mukims\n",
        "low_count_mukims = ['Mukim Cheras', 'Mukim Ampang', 'Mukim Ulu Kelang']\n",
        "df = df[~df['Mukim'].isin(low_count_mukims)]\n",
        "\n",
        "# Outlier capping (94th percentile)\n",
        "price_cap = df['TransactionPrice'].quantile(0.94)\n",
        "df['TransactionPrice'] = np.clip(df['TransactionPrice'], 0, price_cap)\n",
        "area_cap = df['Parcel_sq_m'].quantile(0.94)\n",
        "df['Parcel_sq_m'] = np.clip(df['Parcel_sq_m'], 0, area_cap)\n",
        "\n",
        "# Log-transform\n",
        "df['TransactionPrice'] = np.log1p(df['TransactionPrice'])\n",
        "df['Parcel_sq_m'] = np.log1p(df['Parcel_sq_m'])\n",
        "\n",
        "# Target encode Scheme Name/Area\n",
        "scheme_encoding = df.groupby('SchemeName')['TransactionPrice'].mean()\n",
        "df['Scheme_Name_encoded'] = df['SchemeName'].map(scheme_encoding)\n",
        "\n",
        "# Clean UnitLevel\n",
        "#unit_level_map = {'Ground': 0, 'Basement': -1, 'Penthouse': 50, 'Mezzanine': 1}  # Adjust based on data\n",
        "#df['UnitLevel_clean'] = df['UnitLevel'].replace(unit_level_map)\n",
        "#df['UnitLevel_clean'] = pd.to_numeric(df['UnitLevel_clean'], errors='coerce').fillna(df['UnitLevel_clean'].median())\n",
        "#df['UnitLevel_binned'] = pd.cut(df['UnitLevel_clean'], bins=[-float('inf'), 10, 20, float('inf')], labels=['Low', 'Mid', 'High'])\n",
        "#level_dummies = pd.get_dummies(df['UnitLevel_binned'], prefix='UnitLevel')\n",
        "\n",
        "df['UnitLevel'] = pd.to_numeric(df['UnitLevel'], errors='coerce')\n",
        "df['UnitLevel'].fillna(df['UnitLevel'].mean(), inplace=True)\n",
        "df['UnitLevel_binned'] = pd.cut(df['UnitLevel'], bins=[-float('inf'), 10, 20, float('inf')], labels=['Low', 'Mid', 'High'])\n",
        "level_dummies = pd.get_dummies(df['UnitLevel_binned'], prefix='UnitLevel')\n",
        "\n",
        "# Mukim * Tenure and Mukim * Parcel_sq_m\n",
        "mukim_dummies = pd.get_dummies(df['Mukim'], prefix='Mukim')\n",
        "for col in ['Mukim_Mukim Setapak', 'Mukim_Kuala Lumpur Town Centre']:\n",
        "    df[f'{col}_Tenure'] = mukim_dummies[col] * df['Tenure']\n",
        "    df[f'{col}_Parcel_sq_m'] = mukim_dummies[col] * df['Parcel_sq_m']\n",
        "\n",
        "# Features\n",
        "features = ['Scheme_Name_encoded', 'Parcel_sq_m'] + \\\n",
        "           ['Mukim_Mukim Setapak', 'Mukim_Kuala Lumpur Town Centre'] + \\\n",
        "           [f'{col}_Tenure' for col in ['Mukim_Mukim Setapak', 'Mukim_Kuala Lumpur Town Centre']] + \\\n",
        "           [f'{col}_Parcel_sq_m' for col in ['Mukim_Mukim Setapak', 'Mukim_Kuala Lumpur Town Centre']] + \\\n",
        "           list(level_dummies.columns)\n",
        "X = pd.concat([df[['Scheme_Name_encoded', 'Parcel_sq_m']], mukim_dummies[['Mukim_Mukim Setapak', 'Mukim_Kuala Lumpur Town Centre']],\n",
        "               df[[f'{col}_Tenure' for col in ['Mukim_Mukim Setapak', 'Mukim_Kuala Lumpur Town Centre']]],\n",
        "               df[[f'{col}_Parcel_sq_m' for col in ['Mukim_Mukim Setapak', 'Mukim_Kuala Lumpur Town Centre']]],\n",
        "               level_dummies], axis=1)\n",
        "y = df['TransactionPrice']\n",
        "\n",
        "# Robust scaling\n",
        "scaler = RobustScaler()\n",
        "X[['Scheme_Name_encoded', 'Parcel_sq_m']] = scaler.fit_transform(X[['Scheme_Name_encoded', 'Parcel_sq_m']])\n",
        "\n",
        "# Sample weights\n",
        "weights = df['Mukim'].apply(lambda x: 4.0 if x in ['Mukim Setapak', 'Mukim Petaling'] else 1.0)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test, w_train, w_test = train_test_split(X, y, weights, test_size=0.2, random_state=42)\n",
        "\n",
        "# Ensemble: Average RandomForest and XGBoost\n",
        "xgb = XGBRegressor(objective='reg:squarederror', n_estimators=700, max_depth=3, learning_rate=0.1, random_state=42)\n",
        "rf = RandomForestRegressor(n_estimators=300, max_depth=10, min_samples_split=60, random_state=42)\n",
        "xgb.fit(X_train, y_train, sample_weight=w_train)\n",
        "rf.fit(X_train, y_train, sample_weight=w_train)\n",
        "y_pred_xgb = xgb.predict(X_test)\n",
        "y_pred_rf = rf.predict(X_test)\n",
        "y_pred_ensemble = (y_pred_xgb + y_pred_rf) / 2\n",
        "\n",
        "# Evaluate\n",
        "print(\"XGBoost R:\", r2_score(y_test, y_pred_xgb))\n",
        "print(\"XGBoost RMSE:\", np.sqrt(mean_squared_error(np.expm1(y_test), np.expm1(y_pred_xgb))))\n",
        "print(\"RandomForest R:\", r2_score(y_test, y_pred_rf))\n",
        "print(\"RandomForest RMSE:\", np.sqrt(mean_squared_error(np.expm1(y_test), np.expm1(y_pred_rf))))\n",
        "print(\"Ensemble R:\", r2_score(y_test, y_pred_ensemble))\n",
        "print(\"Ensemble RMSE:\", np.sqrt(mean_squared_error(np.expm1(y_test), np.expm1(y_pred_ensemble))))\n",
        "\n",
        "# Feature importance\n",
        "importance_xgb = pd.Series(xgb.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
        "print(\"XGBoost Feature Importance:\\n\", importance_xgb)\n",
        "importance_rf = pd.Series(rf.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
        "print(\"RandomForest Feature Importance:\\n\", importance_rf)\n",
        "\n",
        "# Cross-validation\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "cv_xgb_scores = []\n",
        "cv_rf_scores = []\n",
        "\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train_fold, X_test_fold = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train_fold, y_test_fold = y.iloc[train_index], y.iloc[test_index]\n",
        "    weights_train_fold, weights_test_fold = weights.iloc[train_index], weights.iloc[test_index]\n",
        "\n",
        "    # XGBoost\n",
        "    xgb_fold = XGBRegressor(objective='reg:squarederror', n_estimators=700, max_depth=3, learning_rate=0.1, random_state=42)\n",
        "    xgb_fold.fit(X_train_fold, y_train_fold, sample_weight=weights_train_fold)\n",
        "    y_pred_xgb_fold = xgb_fold.predict(X_test_fold)\n",
        "    cv_xgb_scores.append(r2_score(y_test_fold, y_pred_xgb_fold, sample_weight=weights_test_fold))\n",
        "\n",
        "    # RandomForest\n",
        "    rf_fold = RandomForestRegressor(n_estimators=300, max_depth=10, min_samples_split=60, random_state=42)\n",
        "    rf_fold.fit(X_train_fold, y_train_fold, sample_weight=weights_train_fold)\n",
        "    y_pred_rf_fold = rf_fold.predict(X_test_fold)\n",
        "    cv_rf_scores.append(r2_score(y_test_fold, y_pred_rf_fold, sample_weight=weights_test_fold))\n",
        "\n",
        "\n",
        "print(\"XGBoost 5-Fold CV R:\", np.mean(cv_xgb_scores), \"\", np.std(cv_xgb_scores))\n",
        "print(\"RandomForest 5-Fold CV R:\", np.mean(cv_rf_scores), \"\", np.std(cv_rf_scores))\n",
        "\n",
        "# Suburban performance\n",
        "suburban_mask = df.loc[X_test.index, 'Mukim'].isin(['Mukim Setapak', 'Mukim Petaling'])\n",
        "print(\"Suburban XGBoost RMSE:\", np.sqrt(mean_squared_error(np.expm1(y_test[suburban_mask]), np.expm1(y_pred_xgb[suburban_mask]))))\n",
        "print(\"Suburban RandomForest RMSE:\", np.sqrt(mean_squared_error(np.expm1(y_test[suburban_mask]), np.expm1(y_pred_rf[suburban_mask]))))\n",
        "print(\"Suburban Ensemble RMSE:\", np.sqrt(mean_squared_error(np.expm1(y_test[suburban_mask]), np.expm1(y_pred_ensemble[suburban_mask]))))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JwpBXxzjiH0i",
        "outputId": "a6c19381-758e-4680-f491-24f9dacc9735"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<>:13: SyntaxWarning: invalid escape sequence '\\d'\n",
            "<>:13: SyntaxWarning: invalid escape sequence '\\d'\n",
            "/tmp/ipython-input-473383716.py:13: SyntaxWarning: invalid escape sequence '\\d'\n",
            "  df['Parcel_sq_m'] = df['ParcelArea'].astype(str).str.extract('(\\d+\\.?\\d*)').astype(float)\n",
            "/tmp/ipython-input-473383716.py:42: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['UnitLevel'].fillna(df['UnitLevel'].mean(), inplace=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XGBoost R: 0.9552470734827998\n",
            "XGBoost RMSE: 124120.21976540779\n",
            "RandomForest R: 0.9510159453350601\n",
            "RandomForest RMSE: 124211.9375016077\n",
            "Ensemble R: 0.9549191932197024\n",
            "Ensemble RMSE: 122159.81397151615\n",
            "XGBoost Feature Importance:\n",
            " Scheme_Name_encoded                           0.649132\n",
            "Parcel_sq_m                                   0.159411\n",
            "Mukim_Mukim Setapak                           0.036094\n",
            "UnitLevel_High                                0.035503\n",
            "Mukim_Mukim Setapak_Parcel_sq_m               0.032023\n",
            "Mukim_Kuala Lumpur Town Centre_Tenure         0.026138\n",
            "UnitLevel_Mid                                 0.018976\n",
            "Mukim_Mukim Setapak_Tenure                    0.018910\n",
            "UnitLevel_Low                                 0.011789\n",
            "Mukim_Kuala Lumpur Town Centre                0.007158\n",
            "Mukim_Kuala Lumpur Town Centre_Parcel_sq_m    0.004866\n",
            "dtype: float32\n",
            "RandomForest Feature Importance:\n",
            " Scheme_Name_encoded                           0.899363\n",
            "Parcel_sq_m                                   0.090910\n",
            "Mukim_Mukim Setapak_Parcel_sq_m               0.006821\n",
            "Mukim_Mukim Setapak_Tenure                    0.001085\n",
            "Mukim_Kuala Lumpur Town Centre_Parcel_sq_m    0.000587\n",
            "UnitLevel_High                                0.000404\n",
            "Mukim_Kuala Lumpur Town Centre_Tenure         0.000312\n",
            "Mukim_Mukim Setapak                           0.000244\n",
            "UnitLevel_Low                                 0.000178\n",
            "UnitLevel_Mid                                 0.000054\n",
            "Mukim_Kuala Lumpur Town Centre                0.000040\n",
            "dtype: float64\n",
            "XGBoost 5-Fold CV R: 0.9358637682155116  0.0071288946482169985\n",
            "RandomForest 5-Fold CV R: 0.9287915415174819  0.006010225281137159\n",
            "Suburban XGBoost RMSE: 87012.01670185178\n",
            "Suburban RandomForest RMSE: 87527.70274417353\n",
            "Suburban Ensemble RMSE: 86453.7510859434\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# To finalize the model, incorporating Year and low-price validation\n",
        "\n",
        "*  Uses 93rd percentile capping (~750k RM, ~110 sq.m).\n",
        "*  Increases suburban weights (4.5).\n",
        "*  Adds Year to capture trends (median-imputed).\n",
        "*  Prunes UnitLevel_Low (low importance).\n",
        "*  Refines UnitLevel bins (Low 8, Mid 918, High >18).\n",
        "*  Validates low-price subset (<450k RM)."
      ],
      "metadata": {
        "id": "hvlo3m6zpR54"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from sklearn.metrics import r2_score, mean_squared_error\n",
        "\n",
        "# Load and preprocess\n",
        "url = \"https://raw.githubusercontent.com/englian1123/KL-High-Rise-Data/refs/heads/main/KLHighRise.csv\"\n",
        "df = pd.read_csv(url)\n",
        "df.rename(columns={'TransactionPrice  ': 'TransactionPrice'}, inplace=True)\n",
        "df['Parcel_sq_m'] = df['ParcelArea'].astype(str).str.extract('(\\d+\\.?\\d*)').astype(float)\n",
        "df['Tenure'] = df['Tenure'].map({'Freehold': 1, 'Leasehold': 0})\n",
        "\n",
        "# Drop low-count Mukims\n",
        "low_count_mukims = ['Mukim Cheras', 'Mukim Ampang', 'Mukim Ulu Kelang']\n",
        "df = df[~df['Mukim'].isin(low_count_mukims)]\n",
        "\n",
        "# Outlier capping (93rd percentile)\n",
        "price_cap = df['TransactionPrice'].quantile(0.93)\n",
        "df['TransactionPrice'] = np.clip(df['TransactionPrice'], 0, price_cap)\n",
        "area_cap = df['Parcel_sq_m'].quantile(0.93)\n",
        "df['Parcel_sq_m'] = np.clip(df['Parcel_sq_m'], 0, area_cap)\n",
        "\n",
        "# Log-transform\n",
        "df['TransactionPrice'] = np.log1p(df['TransactionPrice'])\n",
        "df['Parcel_sq_m'] = np.log1p(df['Parcel_sq_m'])\n",
        "\n",
        "# Target encode Scheme Name/Area\n",
        "scheme_encoding = df.groupby('SchemeName')['TransactionPrice'].mean()\n",
        "df['Scheme_Name_encoded'] = df['SchemeName'].map(scheme_encoding)\n",
        "\n",
        "# Add Year\n",
        "df['Year'] = pd.to_datetime(df['TransactionDate'], format='%b-%y').dt.year\n",
        "df['Year'] = pd.to_numeric(df['Year'], errors='coerce').fillna(df['Year'].median())\n",
        "\n",
        "# Clean UnitLevel\n",
        "#unit_level_map = {'Ground': 0, 'Basement': -1, 'Penthouse': 50, 'Mezzanine': 1}\n",
        "#df['UnitLevel_clean'] = df['UnitLevel'].replace(unit_level_map)\n",
        "#df['UnitLevel_clean'] = pd.to_numeric(df['UnitLevel_clean'], errors='coerce').fillna(df['UnitLevel_clean'].median())\n",
        "#df['UnitLevel_binned'] = pd.cut(df['UnitLevel_clean'], bins=[-float('inf'), 8, 18, float('inf')], labels=['Low', 'Mid', 'High'])\n",
        "#level_dummies = pd.get_dummies(df['UnitLevel_binned'], prefix='UnitLevel')\n",
        "\n",
        "df['UnitLevel'] = pd.to_numeric(df['UnitLevel'], errors='coerce')\n",
        "df['UnitLevel'].fillna(df['UnitLevel'].mean(), inplace=True)\n",
        "df['UnitLevel_binned'] = pd.cut(df['UnitLevel'], bins=[-float('inf'), 10, 20, float('inf')], labels=['Low', 'Mid', 'High'])\n",
        "level_dummies = pd.get_dummies(df['UnitLevel_binned'], prefix='UnitLevel')\n",
        "\n",
        "\n",
        "# Mukim * Tenure and Mukim * Parcel_sq_m\n",
        "mukim_dummies = pd.get_dummies(df['Mukim'], prefix='Mukim')\n",
        "for col in ['Mukim_Mukim Setapak', 'Mukim_Kuala Lumpur Town Centre']:\n",
        "    df[f'{col}_Tenure'] = mukim_dummies[col] * df['Tenure']\n",
        "    df[f'{col}_Parcel_sq_m'] = mukim_dummies[col] * df['Parcel_sq_m']\n",
        "\n",
        "# Features\n",
        "features = ['Scheme_Name_encoded', 'Parcel_sq_m', 'Year'] + \\\n",
        "           ['Mukim_Mukim Setapak', 'Mukim_Kuala Lumpur Town Centre'] + \\\n",
        "           [f'{col}_Tenure' for col in ['Mukim_Mukim Setapak', 'Mukim_Kuala Lumpur Town Centre']] + \\\n",
        "           [f'{col}_Parcel_sq_m' for col in ['Mukim_Mukim Setapak', 'Mukim_Kuala Lumpur Town Centre']] + \\\n",
        "           ['UnitLevel_High', 'UnitLevel_Mid']\n",
        "X = pd.concat([df[['Scheme_Name_encoded', 'Parcel_sq_m', 'Year']],\n",
        "               mukim_dummies[['Mukim_Mukim Setapak', 'Mukim_Kuala Lumpur Town Centre']],\n",
        "               df[[f'{col}_Tenure' for col in ['Mukim_Mukim Setapak', 'Mukim_Kuala Lumpur Town Centre']]],\n",
        "               df[[f'{col}_Parcel_sq_m' for col in ['Mukim_Mukim Setapak', 'Mukim_Kuala Lumpur Town Centre']]],\n",
        "               level_dummies[['UnitLevel_High', 'UnitLevel_Mid']]], axis=1)\n",
        "y = df['TransactionPrice']\n",
        "\n",
        "# Robust scaling\n",
        "scaler = RobustScaler()\n",
        "X[['Scheme_Name_encoded', 'Parcel_sq_m', 'Year']] = scaler.fit_transform(X[['Scheme_Name_encoded', 'Parcel_sq_m', 'Year']])\n",
        "\n",
        "# Sample weights\n",
        "weights = df['Mukim'].apply(lambda x: 4.5 if x in ['Mukim Setapak', 'Mukim Petaling'] else 1.0)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test, w_train, w_test = train_test_split(X, y, weights, test_size=0.2, random_state=42)\n",
        "\n",
        "# Ensemble: Average RandomForest and XGBoost\n",
        "xgb = XGBRegressor(objective='reg:squarederror', n_estimators=700, max_depth=3, learning_rate=0.1, random_state=42)\n",
        "rf = RandomForestRegressor(n_estimators=300, max_depth=10, min_samples_split=70, random_state=42)\n",
        "xgb.fit(X_train, y_train, sample_weight=w_train)\n",
        "rf.fit(X_train, y_train, sample_weight=w_train)\n",
        "y_pred_xgb = xgb.predict(X_test)\n",
        "y_pred_rf = rf.predict(X_test)\n",
        "y_pred_ensemble = (y_pred_xgb + y_pred_rf) / 2\n",
        "\n",
        "# Evaluate\n",
        "print(\"XGBoost R:\", r2_score(y_test, y_pred_xgb))\n",
        "print(\"XGBoost RMSE:\", np.sqrt(mean_squared_error(np.expm1(y_test), np.expm1(y_pred_xgb))))\n",
        "print(\"RandomForest R:\", r2_score(y_test, y_pred_rf))\n",
        "print(\"RandomForest RMSE:\", np.sqrt(mean_squared_error(np.expm1(y_test), np.expm1(y_pred_rf))))\n",
        "print(\"Ensemble R:\", r2_score(y_test, y_pred_ensemble))\n",
        "print(\"Ensemble RMSE:\", np.sqrt(mean_squared_error(np.expm1(y_test), np.expm1(y_pred_ensemble))))\n",
        "\n",
        "# Feature importance\n",
        "importance_xgb = pd.Series(xgb.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
        "print(\"XGBoost Feature Importance:\\n\", importance_xgb)\n",
        "importance_rf = pd.Series(rf.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
        "print(\"RandomForest Feature Importance:\\n\", importance_rf)\n",
        "\n",
        "# Cross-validation\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "cv_xgb_scores = []\n",
        "cv_rf_scores = []\n",
        "\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train_fold, X_test_fold = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train_fold, y_test_fold = y.iloc[train_index], y.iloc[test_index]\n",
        "    weights_train_fold, weights_test_fold = weights.iloc[train_index], weights.iloc[test_index]\n",
        "\n",
        "    # XGBoost\n",
        "    xgb_fold = XGBRegressor(objective='reg:squarederror', n_estimators=700, max_depth=3, learning_rate=0.1, random_state=42)\n",
        "    xgb_fold.fit(X_train_fold, y_train_fold, sample_weight=weights_train_fold)\n",
        "    y_pred_xgb_fold = xgb_fold.predict(X_test_fold)\n",
        "    cv_xgb_scores.append(r2_score(y_test_fold, y_pred_xgb_fold, sample_weight=weights_test_fold))\n",
        "\n",
        "    # RandomForest\n",
        "    rf_fold = RandomForestRegressor(n_estimators=300, max_depth=10, min_samples_split=70, random_state=42)\n",
        "    rf_fold.fit(X_train_fold, y_train_fold, sample_weight=weights_train_fold)\n",
        "    y_pred_rf_fold = rf_fold.predict(X_test_fold)\n",
        "    cv_rf_scores.append(r2_score(y_test_fold, y_pred_rf_fold, sample_weight=weights_test_fold))\n",
        "\n",
        "\n",
        "print(\"XGBoost 5-Fold CV R:\", np.mean(cv_xgb_scores), \"\", np.std(cv_xgb_scores))\n",
        "print(\"RandomForest 5-Fold CV R:\", np.mean(cv_rf_scores), \"\", np.std(cv_rf_scores))\n",
        "\n",
        "# Suburban and low-price performance\n",
        "suburban_mask = df.loc[X_test.index, 'Mukim'].isin(['Mukim Setapak', 'Mukim Petaling'])\n",
        "low_price_mask = np.expm1(y_test) < 450000\n",
        "print(\"Suburban XGBoost RMSE:\", np.sqrt(mean_squared_error(np.expm1(y_test[suburban_mask]), np.expm1(y_pred_xgb[suburban_mask]))))\n",
        "print(\"Suburban RandomForest RMSE:\", np.sqrt(mean_squared_error(np.expm1(y_test[suburban_mask]), np.expm1(y_pred_rf[suburban_mask]))))\n",
        "print(\"Suburban Ensemble RMSE:\", np.sqrt(mean_squared_error(np.expm1(y_test[suburban_mask]), np.expm1(y_pred_ensemble[suburban_mask]))))\n",
        "print(\"Low-Price (<450k RM) XGBoost RMSE:\", np.sqrt(mean_squared_error(np.expm1(y_test[low_price_mask]), np.expm1(y_pred_xgb[low_price_mask]))))\n",
        "print(\"Low-Price (<450k RM) RandomForest RMSE:\", np.sqrt(mean_squared_error(np.expm1(y_test[low_price_mask]), np.expm1(y_pred_rf[low_price_mask]))))\n",
        "print(\"Low-Price (<450k RM) Ensemble RMSE:\", np.sqrt(mean_squared_error(np.expm1(y_test[low_price_mask]), np.expm1(y_pred_ensemble[low_price_mask]))))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A9kplM9PpQr0",
        "outputId": "162f14a8-3260-4ab2-fd49-04b1757d17cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<>:13: SyntaxWarning: invalid escape sequence '\\d'\n",
            "<>:13: SyntaxWarning: invalid escape sequence '\\d'\n",
            "/tmp/ipython-input-790947924.py:13: SyntaxWarning: invalid escape sequence '\\d'\n",
            "  df['Parcel_sq_m'] = df['ParcelArea'].astype(str).str.extract('(\\d+\\.?\\d*)').astype(float)\n",
            "/tmp/ipython-input-790947924.py:46: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['UnitLevel'].fillna(df['UnitLevel'].mean(), inplace=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XGBoost R: 0.95238464636332\n",
            "XGBoost RMSE: 116750.17932136254\n",
            "RandomForest R: 0.9488722404139636\n",
            "RandomForest RMSE: 119820.93310400622\n",
            "Ensemble R: 0.9534289102391412\n",
            "Ensemble RMSE: 116136.61941774623\n",
            "XGBoost Feature Importance:\n",
            " Scheme_Name_encoded                           0.655416\n",
            "Parcel_sq_m                                   0.155173\n",
            "Year                                          0.055334\n",
            "Mukim_Mukim Setapak_Parcel_sq_m               0.026866\n",
            "Mukim_Kuala Lumpur Town Centre_Tenure         0.025837\n",
            "Mukim_Mukim Setapak                           0.024595\n",
            "UnitLevel_High                                0.022521\n",
            "Mukim_Mukim Setapak_Tenure                    0.012095\n",
            "UnitLevel_Mid                                 0.009910\n",
            "Mukim_Kuala Lumpur Town Centre_Parcel_sq_m    0.006358\n",
            "Mukim_Kuala Lumpur Town Centre                0.005894\n",
            "dtype: float32\n",
            "RandomForest Feature Importance:\n",
            " Scheme_Name_encoded                           0.904377\n",
            "Parcel_sq_m                                   0.085397\n",
            "Mukim_Mukim Setapak_Parcel_sq_m               0.007190\n",
            "Mukim_Mukim Setapak_Tenure                    0.000725\n",
            "Year                                          0.000667\n",
            "Mukim_Kuala Lumpur Town Centre_Parcel_sq_m    0.000500\n",
            "UnitLevel_High                                0.000479\n",
            "Mukim_Kuala Lumpur Town Centre_Tenure         0.000399\n",
            "Mukim_Mukim Setapak                           0.000191\n",
            "UnitLevel_Mid                                 0.000056\n",
            "Mukim_Kuala Lumpur Town Centre                0.000018\n",
            "dtype: float64\n",
            "XGBoost 5-Fold CV R: 0.9401814520899932  0.005916528134794484\n",
            "RandomForest 5-Fold CV R: 0.9255615466435703  0.006300839595198031\n",
            "Suburban XGBoost RMSE: 84397.71001588374\n",
            "Suburban RandomForest RMSE: 85547.94686603424\n",
            "Suburban Ensemble RMSE: 83969.33302791524\n",
            "Low-Price (<450k RM) XGBoost RMSE: 46594.16754061058\n",
            "Low-Price (<450k RM) RandomForest RMSE: 46760.68636402972\n",
            "Low-Price (<450k RM) Ensemble RMSE: 45825.26581440371\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# To finalize the model, pruning low-importance features and validating very low-price performance:\n",
        "\n",
        "*   Uses 92nd percentile capping (~700k RM, ~100 sq.m).\n",
        "*   Increases suburban weights (5.0).\n",
        "*   Prunes Mukim_Kuala Lumpur Town Centre, its interactions, and UnitLevel_Mid.\n",
        "*   Refines UnitLevel bins (Low 7, Mid 815, High >15).\n",
        "*   Validates very low-price subset (<300k RM).\n",
        "*   Uses ensemble for final predictions.\n",
        "\n"
      ],
      "metadata": {
        "id": "WRbqpIOUtTTe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from sklearn.metrics import r2_score, mean_squared_error\n",
        "\n",
        "# Load and preprocess\n",
        "url = \"https://raw.githubusercontent.com/englian1123/KL-High-Rise-Data/refs/heads/main/KLHighRise.csv\"\n",
        "df = pd.read_csv(url)\n",
        "df.rename(columns={'TransactionPrice  ': 'TransactionPrice'}, inplace=True)\n",
        "df['Parcel_sq_m'] = df['ParcelArea'].astype(str).str.extract('(\\d+\\.?\\d*)').astype(float)\n",
        "df['Tenure'] = df['Tenure'].map({'Freehold': 1, 'Leasehold': 0})\n",
        "\n",
        "# Drop low-count Mukims\n",
        "low_count_mukims = ['Mukim Cheras', 'Mukim Ampang', 'Mukim Ulu Kelang']\n",
        "df = df[~df['Mukim'].isin(low_count_mukims)]\n",
        "\n",
        "# Outlier capping (92nd percentile)\n",
        "price_cap = df['TransactionPrice'].quantile(0.92)\n",
        "df['TransactionPrice'] = np.clip(df['TransactionPrice'], 0, price_cap)\n",
        "area_cap = df['Parcel_sq_m'].quantile(0.92)\n",
        "df['Parcel_sq_m'] = np.clip(df['Parcel_sq_m'], 0, area_cap)\n",
        "\n",
        "# Log-transform\n",
        "df['TransactionPrice'] = np.log1p(df['TransactionPrice'])\n",
        "df['Parcel_sq_m'] = np.log1p(df['Parcel_sq_m'])\n",
        "\n",
        "# Target encode Scheme Name/Area\n",
        "scheme_encoding = df.groupby('SchemeName')['TransactionPrice'].mean()\n",
        "df['Scheme_Name_encoded'] = df['SchemeName'].map(scheme_encoding)\n",
        "\n",
        "# Add Year\n",
        "df['Year'] = pd.to_datetime(df['TransactionDate'], format='%b-%y').dt.year\n",
        "df['Year'] = pd.to_numeric(df['Year'], errors='coerce').fillna(df['Year'].median())\n",
        "\n",
        "# Clean UnitLevel\n",
        "#unit_level_map = {'Ground': 0, 'Basement': -1, 'Penthouse': 50, 'Mezzanine': 1}\n",
        "#df['UnitLevel_clean'] = df['UnitLevel'].replace(unit_level_map)\n",
        "#df['UnitLevel_clean'] = pd.to_numeric(df['UnitLevel_clean'], errors='coerce').fillna(df['UnitLevel_clean'].median())\n",
        "#df['UnitLevel_binned'] = pd.cut(df['UnitLevel_clean'], bins=[-float('inf'), 8, 18, float('inf')], labels=['Low', 'Mid', 'High'])\n",
        "#level_dummies = pd.get_dummies(df['UnitLevel_binned'], prefix='UnitLevel')\n",
        "\n",
        "df['UnitLevel'] = pd.to_numeric(df['UnitLevel'], errors='coerce')\n",
        "df['UnitLevel'].fillna(df['UnitLevel'].mean(), inplace=True)\n",
        "df['UnitLevel_binned'] = pd.cut(df['UnitLevel'], bins=[-float('inf'), 10, 20, float('inf')], labels=['Low', 'Mid', 'High'])\n",
        "level_dummies = pd.get_dummies(df['UnitLevel_binned'], prefix='UnitLevel')\n",
        "\n",
        "# Mukim * Tenure and Mukim * Parcel_sq_m (Setapak only)\n",
        "mukim_dummies = pd.get_dummies(df['Mukim'], prefix='Mukim')\n",
        "df['Mukim_Mukim Setapak_Tenure'] = mukim_dummies['Mukim_Mukim Setapak'] * df['Tenure']\n",
        "df['Mukim_Mukim Setapak_Parcel_sq_m'] = mukim_dummies['Mukim_Mukim Setapak'] * df['Parcel_sq_m']\n",
        "\n",
        "# Features\n",
        "features = ['Scheme_Name_encoded', 'Parcel_sq_m', 'Year', 'Mukim_Mukim Setapak',\n",
        "            'Mukim_Mukim Setapak_Tenure', 'Mukim_Mukim Setapak_Parcel_sq_m',\n",
        "            'UnitLevel_High']\n",
        "X = pd.concat([df[['Scheme_Name_encoded', 'Parcel_sq_m', 'Year']],\n",
        "               mukim_dummies[['Mukim_Mukim Setapak']],\n",
        "               df[['Mukim_Mukim Setapak_Tenure', 'Mukim_Mukim Setapak_Parcel_sq_m']],\n",
        "               level_dummies[['UnitLevel_High']]], axis=1)\n",
        "y = df['TransactionPrice']\n",
        "\n",
        "# Robust scaling\n",
        "scaler = RobustScaler()\n",
        "X[['Scheme_Name_encoded', 'Parcel_sq_m', 'Year']] = scaler.fit_transform(X[['Scheme_Name_encoded', 'Parcel_sq_m', 'Year']])\n",
        "\n",
        "# Sample weights\n",
        "weights = df['Mukim'].apply(lambda x: 5.0 if x in ['Mukim Setapak', 'Mukim Petaling'] else 1.0)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test, w_train, w_test = train_test_split(X, y, weights, test_size=0.2, random_state=42)\n",
        "\n",
        "# Ensemble: Average RandomForest and XGBoost\n",
        "xgb = XGBRegressor(objective='reg:squarederror', n_estimators=700, max_depth=2, learning_rate=0.1, random_state=42)\n",
        "rf = RandomForestRegressor(n_estimators=300, max_depth=10, min_samples_split=80, random_state=42)\n",
        "xgb.fit(X_train, y_train, sample_weight=w_train)\n",
        "rf.fit(X_train, y_train, sample_weight=w_train)\n",
        "y_pred_xgb = xgb.predict(X_test)\n",
        "y_pred_rf = rf.predict(X_test)\n",
        "y_pred_ensemble = (y_pred_xgb + y_pred_rf) / 2\n",
        "\n",
        "# Evaluate\n",
        "print(\"XGBoost R:\", r2_score(y_test, y_pred_xgb))\n",
        "print(\"XGBoost RMSE:\", np.sqrt(mean_squared_error(np.expm1(y_test), np.expm1(y_pred_xgb))))\n",
        "print(\"RandomForest R:\", r2_score(y_test, y_pred_rf))\n",
        "print(\"RandomForest RMSE:\", np.sqrt(mean_squared_error(np.expm1(y_test), np.expm1(y_pred_rf))))\n",
        "print(\"Ensemble R:\", r2_score(y_test, y_pred_ensemble))\n",
        "print(\"Ensemble RMSE:\", np.sqrt(mean_squared_error(np.expm1(y_test), np.expm1(y_pred_ensemble))))\n",
        "\n",
        "# Feature importance\n",
        "importance_xgb = pd.Series(xgb.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
        "print(\"XGBoost Feature Importance:\\n\", importance_xgb)\n",
        "importance_rf = pd.Series(rf.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
        "print(\"RandomForest Feature Importance:\\n\", importance_rf)\n",
        "\n",
        "# Cross-validation\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "cv_xgb_scores = []\n",
        "cv_rf_scores = []\n",
        "\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train_fold, X_test_fold = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train_fold, y_test_fold = y.iloc[train_index], y.iloc[test_index]\n",
        "    weights_train_fold, weights_test_fold = weights.iloc[train_index], weights.iloc[test_index]\n",
        "\n",
        "    # XGBoost\n",
        "    xgb_fold = XGBRegressor(objective='reg:squarederror', n_estimators=700, max_depth=2, learning_rate=0.1, random_state=42)\n",
        "    xgb_fold.fit(X_train_fold, y_train_fold, sample_weight=weights_train_fold)\n",
        "    y_pred_xgb_fold = xgb_fold.predict(X_test_fold)\n",
        "    cv_xgb_scores.append(r2_score(y_test_fold, y_pred_xgb_fold, sample_weight=weights_test_fold))\n",
        "\n",
        "    # RandomForest\n",
        "    rf_fold = RandomForestRegressor(n_estimators=300, max_depth=10, min_samples_split=80, random_state=42)\n",
        "    rf_fold.fit(X_train_fold, y_train_fold, sample_weight=weights_train_fold)\n",
        "    y_pred_rf_fold = rf_fold.predict(X_test_fold)\n",
        "    cv_rf_scores.append(r2_score(y_test_fold, y_pred_rf_fold, sample_weight=weights_test_fold))\n",
        "\n",
        "\n",
        "print(\"XGBoost 5-Fold CV R:\", np.mean(cv_xgb_scores), \"\", np.std(cv_xgb_scores))\n",
        "print(\"RandomForest 5-Fold CV R:\", np.mean(cv_rf_scores), \"\", np.std(cv_rf_scores))\n",
        "\n",
        "# Suburban and very low-price performance\n",
        "suburban_mask = df.loc[X_test.index, 'Mukim'].isin(['Mukim Setapak', 'Mukim Petaling'])\n",
        "low_price_mask = np.expm1(y_test) < 450000\n",
        "very_low_price_mask = np.expm1(y_test) < 300000\n",
        "print(\"Suburban XGBoost RMSE:\", np.sqrt(mean_squared_error(np.expm1(y_test[suburban_mask]), np.expm1(y_pred_xgb[suburban_mask]))))\n",
        "print(\"Suburban RandomForest RMSE:\", np.sqrt(mean_squared_error(np.expm1(y_test[suburban_mask]), np.expm1(y_pred_rf[suburban_mask]))))\n",
        "print(\"Suburban Ensemble RMSE:\", np.sqrt(mean_squared_error(np.expm1(y_test[suburban_mask]), np.expm1(y_pred_ensemble[suburban_mask]))))\n",
        "print(\"Low-Price (<450k RM) XGBoost RMSE:\", np.sqrt(mean_squared_error(np.expm1(y_test[low_price_mask]), np.expm1(y_pred_xgb[low_price_mask]))))\n",
        "print(\"Low-Price (<450k RM) RandomForest RMSE:\", np.sqrt(mean_squared_error(np.expm1(y_test[low_price_mask]), np.expm1(y_pred_rf[low_price_mask]))))\n",
        "print(\"Low-Price (<450k RM) Ensemble RMSE:\", np.sqrt(mean_squared_error(np.expm1(y_test[low_price_mask]), np.expm1(y_pred_ensemble[low_price_mask]))))\n",
        "print(\"Very Low-Price (<300k RM) XGBoost RMSE:\", np.sqrt(mean_squared_error(np.expm1(y_test[very_low_price_mask]), np.expm1(y_pred_xgb[very_low_price_mask]))))\n",
        "print(\"Very Low-Price (<300k RM) RandomForest RMSE:\", np.sqrt(mean_squared_error(np.expm1(y_test[very_low_price_mask]), np.expm1(y_pred_rf[very_low_price_mask]))))\n",
        "print(\"Very Low-Price (<300k RM) Ensemble RMSE:\", np.sqrt(mean_squared_error(np.expm1(y_test[very_low_price_mask]), np.expm1(y_pred_ensemble[very_low_price_mask]))))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KgqIU4sFtSRv",
        "outputId": "4c23d680-879b-45cc-9120-7daba1bb576c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<>:13: SyntaxWarning: invalid escape sequence '\\d'\n",
            "<>:13: SyntaxWarning: invalid escape sequence '\\d'\n",
            "/tmp/ipython-input-2442990773.py:13: SyntaxWarning: invalid escape sequence '\\d'\n",
            "  df['Parcel_sq_m'] = df['ParcelArea'].astype(str).str.extract('(\\d+\\.?\\d*)').astype(float)\n",
            "/tmp/ipython-input-2442990773.py:46: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['UnitLevel'].fillna(df['UnitLevel'].mean(), inplace=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XGBoost R: 0.9413363603964094\n",
            "XGBoost RMSE: 128915.06732878683\n",
            "RandomForest R: 0.9454136035011819\n",
            "RandomForest RMSE: 119597.22409090864\n",
            "Ensemble R: 0.9462451428078283\n",
            "Ensemble RMSE: 122161.60828223606\n",
            "XGBoost Feature Importance:\n",
            " Scheme_Name_encoded                0.693825\n",
            "Parcel_sq_m                        0.192427\n",
            "Year                               0.049983\n",
            "Mukim_Mukim Setapak_Parcel_sq_m    0.029599\n",
            "UnitLevel_High                     0.026890\n",
            "Mukim_Mukim Setapak_Tenure         0.007275\n",
            "Mukim_Mukim Setapak                0.000000\n",
            "dtype: float32\n",
            "RandomForest Feature Importance:\n",
            " Scheme_Name_encoded                0.921365\n",
            "Parcel_sq_m                        0.069172\n",
            "Mukim_Mukim Setapak_Parcel_sq_m    0.007457\n",
            "Mukim_Mukim Setapak_Tenure         0.000632\n",
            "Year                               0.000632\n",
            "UnitLevel_High                     0.000561\n",
            "Mukim_Mukim Setapak                0.000181\n",
            "dtype: float64\n",
            "XGBoost 5-Fold CV R: 0.9254555331364287  0.00626166830116085\n",
            "RandomForest 5-Fold CV R: 0.9212240619136536  0.006420805339200746\n",
            "Suburban XGBoost RMSE: 88612.17921166231\n",
            "Suburban RandomForest RMSE: 82843.29247465858\n",
            "Suburban Ensemble RMSE: 84204.12148442713\n",
            "Low-Price (<450k RM) XGBoost RMSE: 47681.32626594507\n",
            "Low-Price (<450k RM) RandomForest RMSE: 47125.0196362041\n",
            "Low-Price (<450k RM) Ensemble RMSE: 46674.57584425742\n",
            "Very Low-Price (<300k RM) XGBoost RMSE: 45474.75131111412\n",
            "Very Low-Price (<300k RM) RandomForest RMSE: 47148.28931610935\n",
            "Very Low-Price (<300k RM) Ensemble RMSE: 45264.36293028172\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# This code finalizes the ensemble model, tests stricter capping, and prepares for deployment\n",
        "\n",
        "Uses 91st percentile capping (~650k RM, ~95 sq.m) for very low-price focus.\n",
        "\n",
        "*  Maintains weights (5.0) for Setapak/Petaling.\n",
        "*  Prunes Mukim_Mukim Setapak (importance ~0).\n",
        "*  Saves models and scaler for deployment.\n",
        "*  Validates across suburban, low-price, and very low-price subsets."
      ],
      "metadata": {
        "id": "IhgMoIuZToQF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from sklearn.metrics import r2_score, mean_squared_error\n",
        "import joblib\n",
        "\n",
        "# Load and preprocess\n",
        "url = \"https://raw.githubusercontent.com/englian1123/KL-High-Rise-Data/refs/heads/main/KLHighRise.csv\"\n",
        "df = pd.read_csv(url)\n",
        "df.rename(columns={'TransactionPrice  ': 'TransactionPrice'}, inplace=True)\n",
        "df['Parcel_sq_m'] = df['ParcelArea'].astype(str).str.extract('(\\d+\\.?\\d*)').astype(float)\n",
        "df['Tenure'] = df['Tenure'].map({'Freehold': 1, 'Leasehold': 0})\n",
        "\n",
        "# Drop low-count Mukims\n",
        "low_count_mukims = ['Mukim Cheras', 'Mukim Ampang', 'Mukim Ulu Kelang']\n",
        "df = df[~df['Mukim'].isin(low_count_mukims)]\n",
        "\n",
        "# Outlier capping (91st percentile)\n",
        "price_cap = df['TransactionPrice'].quantile(0.91)\n",
        "df['TransactionPrice'] = np.clip(df['TransactionPrice'], 0, price_cap)\n",
        "area_cap = df['Parcel_sq_m'].quantile(0.91)\n",
        "df['Parcel_sq_m'] = np.clip(df['Parcel_sq_m'], 0, area_cap)\n",
        "\n",
        "# Log-transform\n",
        "df['TransactionPrice'] = np.log1p(df['TransactionPrice'])\n",
        "df['Parcel_sq_m'] = np.log1p(df['Parcel_sq_m'])\n",
        "\n",
        "# Target encode Scheme Name/Area\n",
        "scheme_encoding = df.groupby('SchemeName')['TransactionPrice'].mean()\n",
        "df['Scheme_Name_encoded'] = df['SchemeName'].map(scheme_encoding)\n",
        "\n",
        "# Add Year\n",
        "df['Year'] = pd.to_datetime(df['TransactionDate'], format='%b-%y').dt.year\n",
        "df['Year'] = pd.to_numeric(df['Year'], errors='coerce').fillna(df['Year'].median())\n",
        "\n",
        "# Clean UnitLevel\n",
        "#unit_level_map = {'Ground': 0, 'Basement': -1, 'Penthouse': 50, 'Mezzanine': 1}\n",
        "#df['UnitLevel_clean'] = df['UnitLevel'].replace(unit_level_map)\n",
        "#df['UnitLevel_clean'] = pd.to_numeric(df['UnitLevel_clean'], errors='coerce').fillna(df['UnitLevel_clean'].median())\n",
        "#df['UnitLevel_binned'] = pd.cut(df['UnitLevel_clean'], bins=[-float('inf'), 7, 15, float('inf')], labels=['Low', 'Mid', 'High'])\n",
        "#level_dummies = pd.get_dummies(df['UnitLevel_binned'], prefix='UnitLevel')\n",
        "\n",
        "df['UnitLevel'] = pd.to_numeric(df['UnitLevel'], errors='coerce')\n",
        "df['UnitLevel'].fillna(df['UnitLevel'].mean(), inplace=True)\n",
        "df['UnitLevel_binned'] = pd.cut(df['UnitLevel'], bins=[-float('inf'), 10, 20, float('inf')], labels=['Low', 'Mid', 'High'])\n",
        "level_dummies = pd.get_dummies(df['UnitLevel_binned'], prefix='UnitLevel')\n",
        "\n",
        "# Mukim * Tenure and Mukim * Parcel_sq_m (Setapak only)\n",
        "mukim_dummies = pd.get_dummies(df['Mukim'], prefix='Mukim')\n",
        "df['Mukim_Mukim Setapak_Tenure'] = mukim_dummies['Mukim_Mukim Setapak'] * df['Tenure']\n",
        "df['Mukim_Mukim Setapak_Parcel_sq_m'] = mukim_dummies['Mukim_Mukim Setapak'] * df['Parcel_sq_m']\n",
        "\n",
        "# Features\n",
        "features = ['Scheme_Name_encoded', 'Parcel_sq_m', 'Year', 'Mukim_Mukim Setapak_Tenure',\n",
        "            'Mukim_Mukim Setapak_Parcel_sq_m', 'UnitLevel_High']\n",
        "X = pd.concat([df[['Scheme_Name_encoded', 'Parcel_sq_m', 'Year']],\n",
        "               df[['Mukim_Mukim Setapak_Tenure', 'Mukim_Mukim Setapak_Parcel_sq_m']],\n",
        "               level_dummies[['UnitLevel_High']]], axis=1)\n",
        "y = df['TransactionPrice']\n",
        "\n",
        "# Robust scaling\n",
        "scaler = RobustScaler()\n",
        "X[['Scheme_Name_encoded', 'Parcel_sq_m', 'Year']] = scaler.fit_transform(X[['Scheme_Name_encoded', 'Parcel_sq_m', 'Year']])\n",
        "\n",
        "# Save scaler\n",
        "joblib.dump(scaler, 'scaler.joblib')\n",
        "joblib.dump(scheme_encoding, 'scheme_encoding.joblib')\n",
        "\n",
        "# Sample weights\n",
        "weights = df['Mukim'].apply(lambda x: 5.0 if x in ['Mukim Setapak', 'Mukim Petaling'] else 1.0)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test, w_train, w_test = train_test_split(X, y, weights, test_size=0.2, random_state=42)\n",
        "\n",
        "# Ensemble: Average RandomForest and XGBoost\n",
        "xgb = XGBRegressor(objective='reg:squarederror', n_estimators=700, max_depth=3, learning_rate=0.1, random_state=42)\n",
        "rf = RandomForestRegressor(n_estimators=300, max_depth=10, min_samples_split=80, random_state=42)\n",
        "xgb.fit(X_train, y_train, sample_weight=w_train)\n",
        "rf.fit(X_train, y_train, sample_weight=w_train)\n",
        "y_pred_xgb = xgb.predict(X_test)\n",
        "y_pred_rf = rf.predict(X_test)\n",
        "y_pred_ensemble = (y_pred_xgb + y_pred_rf) / 2\n",
        "\n",
        "# Save models\n",
        "joblib.dump(xgb, 'xgb_model.joblib')\n",
        "joblib.dump(rf, 'rf_model.joblib')\n",
        "\n",
        "# Evaluate\n",
        "print(\"XGBoost R:\", r2_score(y_test, y_pred_xgb))\n",
        "print(\"XGBoost RMSE:\", np.sqrt(mean_squared_error(np.expm1(y_test), np.expm1(y_pred_xgb))))\n",
        "print(\"RandomForest R:\", r2_score(y_test, y_pred_rf))\n",
        "print(\"RandomForest RMSE:\", np.sqrt(mean_squared_error(np.expm1(y_test), np.expm1(y_pred_rf))))\n",
        "print(\"Ensemble R:\", r2_score(y_test, y_pred_ensemble))\n",
        "print(\"Ensemble RMSE:\", np.sqrt(mean_squared_error(np.expm1(y_test), np.expm1(y_pred_ensemble))))\n",
        "\n",
        "# Feature importance\n",
        "importance_xgb = pd.Series(xgb.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
        "print(\"XGBoost Feature Importance:\\n\", importance_xgb)\n",
        "importance_rf = pd.Series(rf.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
        "print(\"RandomForest Feature Importance:\\n\", importance_rf)\n",
        "\n",
        "# Cross-validation\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "cv_xgb_scores = []\n",
        "cv_rf_scores = []\n",
        "\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train_fold, X_test_fold = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train_fold, y_test_fold = y.iloc[train_index], y.iloc[test_index]\n",
        "    weights_train_fold, weights_test_fold = weights.iloc[train_index], weights.iloc[test_index]\n",
        "\n",
        "    # XGBoost\n",
        "    xgb_fold = XGBRegressor(objective='reg:squarederror', n_estimators=700, max_depth=3, learning_rate=0.1, random_state=42)\n",
        "    xgb_fold.fit(X_train_fold, y_train_fold, sample_weight=weights_train_fold)\n",
        "    y_pred_xgb_fold = xgb_fold.predict(X_test_fold)\n",
        "    cv_xgb_scores.append(r2_score(y_test_fold, y_pred_xgb_fold, sample_weight=weights_test_fold))\n",
        "\n",
        "    # RandomForest\n",
        "    rf_fold = RandomForestRegressor(n_estimators=300, max_depth=10, min_samples_split=80, random_state=42)\n",
        "    rf_fold.fit(X_train_fold, y_train_fold, sample_weight=weights_train_fold)\n",
        "    y_pred_rf_fold = rf_fold.predict(X_test_fold)\n",
        "    cv_rf_scores.append(r2_score(y_test_fold, y_pred_rf_fold, sample_weight=weights_test_fold))\n",
        "\n",
        "\n",
        "print(\"XGBoost 5-Fold CV R:\", np.mean(cv_xgb_scores), \"\", np.std(cv_xgb_scores))\n",
        "print(\"RandomForest 5-Fold CV R:\", np.mean(cv_rf_scores), \"\", np.std(cv_rf_scores))\n",
        "\n",
        "# Suburban and price-tier performance\n",
        "suburban_mask = df.loc[X_test.index, 'Mukim'].isin(['Mukim Setapak', 'Mukim Petaling'])\n",
        "low_price_mask = np.expm1(y_test) < 450000\n",
        "very_low_price_mask = np.expm1(y_test) < 300000\n",
        "print(\"Suburban XGBoost RMSE:\", np.sqrt(mean_squared_error(np.expm1(y_test[suburban_mask]), np.expm1(y_pred_xgb[suburban_mask]))))\n",
        "print(\"Suburban RandomForest RMSE:\", np.sqrt(mean_squared_error(np.expm1(y_test[suburban_mask]), np.expm1(y_pred_rf[suburban_mask]))))\n",
        "print(\"Suburban Ensemble RMSE:\", np.sqrt(mean_squared_error(np.expm1(y_test[suburban_mask]), np.expm1(y_pred_ensemble[suburban_mask]))))\n",
        "print(\"Low-Price (<450k RM) XGBoost RMSE:\", np.sqrt(mean_squared_error(np.expm1(y_test[low_price_mask]), np.expm1(y_pred_xgb[low_price_mask]))))\n",
        "print(\"Low-Price (<450k RM) RandomForest RMSE:\", np.sqrt(mean_squared_error(np.expm1(y_test[low_price_mask]), np.expm1(y_pred_rf[low_price_mask]))))\n",
        "print(\"Low-Price (<450k RM) Ensemble RMSE:\", np.sqrt(mean_squared_error(np.expm1(y_test[low_price_mask]), np.expm1(y_pred_ensemble[low_price_mask]))))\n",
        "print(\"Very Low-Price (<300k RM) XGBoost RMSE:\", np.sqrt(mean_squared_error(np.expm1(y_test[very_low_price_mask]), np.expm1(y_pred_xgb[very_low_price_mask]))))\n",
        "print(\"Very Low-Price (<300k RM) RandomForest RMSE:\", np.sqrt(mean_squared_error(np.expm1(y_test[very_low_price_mask]), np.expm1(y_pred_rf[very_low_price_mask]))))\n",
        "print(\"Very Low-Price (<300k RM) Ensemble RMSE:\", np.sqrt(mean_squared_error(np.expm1(y_test[very_low_price_mask]), np.expm1(y_pred_ensemble[very_low_price_mask]))))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ProCStBTyW1",
        "outputId": "aa6b54a2-52d9-4122-f226-383db31e98e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<>:14: SyntaxWarning: invalid escape sequence '\\d'\n",
            "<>:14: SyntaxWarning: invalid escape sequence '\\d'\n",
            "/tmp/ipython-input-2303475956.py:14: SyntaxWarning: invalid escape sequence '\\d'\n",
            "  df['Parcel_sq_m'] = df['ParcelArea'].astype(str).str.extract('(\\d+\\.?\\d*)').astype(float)\n",
            "/tmp/ipython-input-2303475956.py:47: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['UnitLevel'].fillna(df['UnitLevel'].mean(), inplace=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XGBoost R: 0.9510497076379525\n",
            "XGBoost RMSE: 107865.81397864557\n",
            "RandomForest R: 0.944259501784373\n",
            "RandomForest RMSE: 115198.8511090917\n",
            "Ensemble R: 0.950614018796564\n",
            "Ensemble RMSE: 109667.53400911263\n",
            "XGBoost Feature Importance:\n",
            " Scheme_Name_encoded                0.734482\n",
            "Parcel_sq_m                        0.125278\n",
            "Year                               0.060852\n",
            "Mukim_Mukim Setapak_Parcel_sq_m    0.037680\n",
            "UnitLevel_High                     0.022743\n",
            "Mukim_Mukim Setapak_Tenure         0.018965\n",
            "dtype: float32\n",
            "RandomForest Feature Importance:\n",
            " Scheme_Name_encoded                0.925484\n",
            "Parcel_sq_m                        0.064825\n",
            "Mukim_Mukim Setapak_Parcel_sq_m    0.007887\n",
            "Year                               0.000624\n",
            "Mukim_Mukim Setapak_Tenure         0.000620\n",
            "UnitLevel_High                     0.000560\n",
            "dtype: float64\n",
            "XGBoost 5-Fold CV R: 0.9386201067209032  0.007961985472722944\n",
            "RandomForest 5-Fold CV R: 0.9203733823968863  0.006559427648889777\n",
            "Suburban XGBoost RMSE: 77094.64849305977\n",
            "Suburban RandomForest RMSE: 80586.05079440564\n",
            "Suburban Ensemble RMSE: 77629.46541540476\n",
            "Low-Price (<450k RM) XGBoost RMSE: 45784.587322504594\n",
            "Low-Price (<450k RM) RandomForest RMSE: 47253.31468167281\n",
            "Low-Price (<450k RM) Ensemble RMSE: 45669.53262635827\n",
            "Very Low-Price (<300k RM) XGBoost RMSE: 42907.208115173526\n",
            "Very Low-Price (<300k RM) RandomForest RMSE: 47193.93809443919\n",
            "Very Low-Price (<300k RM) Ensemble RMSE: 43528.74118593399\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Deployment-Ready Prediction Function\n",
        "\n",
        "*  Loads saved models (xgb_model.joblib, rf_model.joblib), scaler (scaler.joblib), and encoding (scheme_encoding.joblib).\n",
        "*  Processes input data (capping, log-transformation, scaling, encoding).\n",
        "*  Returns ensemble prediction in RM, rounded to 2 decimals.\n",
        "*  Handles unseen Scheme Name/Area by imputing mean encoding."
      ],
      "metadata": {
        "id": "xh75f1m_WiJ6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "\n",
        "def predict_transaction_price(scheme_name, parcel_area, year, unit_level, tenure, mukim):\n",
        "    # Load models and preprocessors\n",
        "    xgb = joblib.load('xgb_model.joblib')\n",
        "    rf = joblib.load('rf_model.joblib')\n",
        "    scaler = joblib.load('scaler.joblib')\n",
        "    scheme_encoding = joblib.load('scheme_encoding.joblib')\n",
        "\n",
        "    # Initialize data\n",
        "    data = {\n",
        "        'SchemeName': [scheme_name],\n",
        "        'ParcelArea': [parcel_area],\n",
        "        'Year': [year],\n",
        "        'UnitLevel': [unit_level],\n",
        "        'Tenure': [tenure],\n",
        "        'Mukim': [mukim]\n",
        "    }\n",
        "    df = pd.DataFrame(data)\n",
        "\n",
        "    # Preprocess\n",
        "    df['Parcel_sq_m'] = df['ParcelArea'].astype(str).str.extract('(\\d+\\.?\\d*)').astype(float)\n",
        "    df['Parcel_sq_m'] = np.clip(df['Parcel_sq_m'], 0, 95)  # 91st percentile\n",
        "    df['Parcel_sq_m'] = np.log1p(df['Parcel_sq_m'])\n",
        "    df['Tenure'] = df['Tenure'].map({'Freehold': 1, 'Leasehold': 0})\n",
        "    df['Year'] = pd.to_numeric(df['Year'], errors='coerce').fillna(2025)  # Median year\n",
        "    df['Scheme_Name_encoded'] = df['SchemeName'].map(scheme_encoding).fillna(scheme_encoding.mean())\n",
        "\n",
        "    # UnitLevel\n",
        "    unit_level_map = {'Ground': 0, 'Basement': -1, 'Penthouse': 50, 'Mezzanine': 1}\n",
        "    df['UnitLevel_clean'] = df['UnitLevel'].replace(unit_level_map)\n",
        "    df['UnitLevel_clean'] = pd.to_numeric(df['UnitLevel_clean'], errors='coerce').fillna(7)  # Median\n",
        "    df['UnitLevel_High'] = (df['UnitLevel_clean'] > 15).astype(int)\n",
        "\n",
        "    # Setapak interactions\n",
        "    df['Mukim_Mukim Setapak'] = (df['Mukim'] == 'Mukim Setapak').astype(int)\n",
        "    df['Mukim_Mukim Setapak_Tenure'] = df['Mukim_Mukim Setapak'] * df['Tenure']\n",
        "    df['Mukim_Mukim Setapak_Parcel_sq_m'] = df['Mukim_Mukim Setapak'] * df['Parcel_sq_m']\n",
        "\n",
        "    # Features\n",
        "    features = ['Scheme_Name_encoded', 'Parcel_sq_m', 'Year', 'Mukim_Mukim Setapak_Tenure',\n",
        "                'Mukim_Mukim Setapak_Parcel_sq_m', 'UnitLevel_High']\n",
        "    X = df[features]\n",
        "    X[['Scheme_Name_encoded', 'Parcel_sq_m', 'Year']] = scaler.transform(X[['Scheme_Name_encoded', 'Parcel_sq_m', 'Year']])\n",
        "\n",
        "    # Predict\n",
        "    y_pred_xgb = xgb.predict(X)\n",
        "    y_pred_rf = rf.predict(X)\n",
        "    y_pred_ensemble = (y_pred_xgb + y_pred_rf) / 2\n",
        "    price = np.expm1(y_pred_ensemble)[0]  # Exponentiate from log\n",
        "    return round(price, 2)\n",
        "\n",
        "# Example usage\n",
        "price = predict_transaction_price(\n",
        "    scheme_name='RESIDENSI PV9',\n",
        "    parcel_area=100,\n",
        "    year=2025,\n",
        "    unit_level='20',\n",
        "    tenure='Leasehold',\n",
        "    mukim='Mukim Setapak'\n",
        ")\n",
        "print(f\"Predicted TransactionPrice: {price} RM\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xUfby3gZYAiV",
        "outputId": "d7561e02-9d13-4d31-be33-6f367077d2bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<>:24: SyntaxWarning: invalid escape sequence '\\d'\n",
            "<>:24: SyntaxWarning: invalid escape sequence '\\d'\n",
            "/tmp/ipython-input-3223953797.py:24: SyntaxWarning: invalid escape sequence '\\d'\n",
            "  df['Parcel_sq_m'] = df['ParcelArea'].astype(str).str.extract('(\\d+\\.?\\d*)').astype(float)\n",
            "/tmp/ipython-input-3223953797.py:46: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X[['Scheme_Name_encoded', 'Parcel_sq_m', 'Year']] = scaler.transform(X[['Scheme_Name_encoded', 'Parcel_sq_m', 'Year']])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted TransactionPrice: 494309.37 RM\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Flask API Example"
      ],
      "metadata": {
        "id": "vGaAMFq2dfV_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from flask import Flask, request, jsonify\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "def predict_transaction_price(scheme_name, parcel_area, year, unit_level, tenure, mukim):\n",
        "    xgb = joblib.load('xgb_model.joblib')\n",
        "    rf = joblib.load('rf_model.joblib')\n",
        "    scaler = joblib.load('scaler.joblib')\n",
        "    scheme_encoding = joblib.load('scheme_encoding.joblib')\n",
        "\n",
        "    data = {\n",
        "        'SchemeName': [scheme_name],\n",
        "        'ParcelArea': [parcel_area],\n",
        "        'Year': [year],\n",
        "        'UnitLevel': [unit_level],\n",
        "        'Tenure': [tenure],\n",
        "        'Mukim': [mukim]\n",
        "    }\n",
        "    df = pd.DataFrame(data)\n",
        "\n",
        "    df['Parcel_sq_m'] = df['ParcelArea'].astype(str).str.extract('(\\d+\\.?\\d*)').astype(float)\n",
        "    df['Parcel_sq_m'] = np.clip(df['Parcel_sq_m'], 0, 95)\n",
        "    df['Parcel_sq_m'] = np.log1p(df['Parcel_sq_m'])\n",
        "    df['Tenure'] = df['Tenure'].map({'Freehold': 1, 'Leasehold': 0})\n",
        "    df['Year'] = pd.to_numeric(df['Year'], errors='coerce').fillna(2025)\n",
        "    df['Scheme_Name_encoded'] = df['Scheme Name/Area'].map(scheme_encoding).fillna(scheme_encoding.mean())\n",
        "\n",
        "    unit_level_map = {'Ground': 0, 'Basement': -1, 'Penthouse': 50, 'Mezzanine': 1}\n",
        "    df['UnitLevel_clean'] = df['UnitLevel'].replace(unit_level_map)\n",
        "    df['UnitLevel_clean'] = pd.to_numeric(df['UnitLevel_clean'], errors='coerce').fillna(7)\n",
        "    df['UnitLevel_High'] = (df['UnitLevel_clean'] > 15).astype(int)\n",
        "\n",
        "    df['Mukim_Mukim Setapak'] = (df['Mukim'] == 'Mukim Setapak').astype(int)\n",
        "    df['Mukim_Mukim Setapak_Tenure'] = df['Mukim_Mukim Setapak'] * df['Tenure']\n",
        "    df['Mukim_Mukim Setapak_Parcel_sq_m'] = df['Mukim_Mukim Setapak'] * df['Parcel_sq_m']\n",
        "\n",
        "    features = ['Scheme_Name_encoded', 'Parcel_sq_m', 'Year', 'Mukim_Mukim Setapak_Tenure',\n",
        "                'Mukim_Mukim Setapak_Parcel_sq_m', 'UnitLevel_High']\n",
        "    X = df[features]\n",
        "    X[['Scheme_Name_encoded', 'Parcel_sq_m', 'Year']] = scaler.transform(X[['Scheme_Name_encoded', 'Parcel_sq_m', 'Year']])\n",
        "\n",
        "    y_pred_xgb = xgb.predict(X)\n",
        "    y_pred_rf = rf.predict(X)\n",
        "    y_pred_ensemble = (y_pred_xgb + y_pred_rf) / 2\n",
        "    return np.expm1(y_pred_ensemble)[0]\n",
        "\n",
        "@app.route('/predict', methods=['POST'])\n",
        "def predict():\n",
        "    data = request.get_json()\n",
        "    try:\n",
        "        price = predict_transaction_price(\n",
        "            scheme_name=data['scheme_name'],\n",
        "            parcel_area=float(data['parcel_area']),\n",
        "            year=int(data['year']),\n",
        "            unit_level=data['unit_level'],\n",
        "            tenure=data['tenure'],\n",
        "            mukim=data['mukim']\n",
        "        )\n",
        "        return jsonify({'predicted_price': round(price, 2)})\n",
        "    except Exception as e:\n",
        "        return jsonify({'error': str(e)}), 400\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    app.run(debug=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AGN6le9Ndgnj",
        "outputId": "34c86fa6-de86-494f-b8cc-a4473a8aeac0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Serving Flask app '__main__'\n",
            " * Debug mode: on\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<>:24: SyntaxWarning: invalid escape sequence '\\d'\n",
            "<>:24: SyntaxWarning: invalid escape sequence '\\d'\n",
            "/tmp/ipython-input-4075593160.py:24: SyntaxWarning: invalid escape sequence '\\d'\n",
            "  df['Parcel_sq_m'] = df['ParcelArea'].astype(str).str.extract('(\\d+\\.?\\d*)').astype(float)\n",
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
            "INFO:werkzeug: * Restarting with watchdog (inotify)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing the Flask API"
      ],
      "metadata": {
        "id": "STQE1KRogBjM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import json\n",
        "\n",
        "# Test the API with a sample input\n",
        "url = 'http://127.0.0.1:5000/predict'\n",
        "data = {\n",
        "    'scheme_name': 'The Edge',\n",
        "    'parcel_area': 100,\n",
        "    'year': 2025,\n",
        "    'unit_level': '15',\n",
        "    'tenure': 'Freehold',\n",
        "    'mukim': 'Mukim Setapak'\n",
        "}\n",
        "\n",
        "response = requests.post(url, json=data)\n",
        "if response.status_code == 200:\n",
        "    print(\"Predicted TransactionPrice:\", response.json()['predicted_price'], \"RM\")\n",
        "else:\n",
        "    print(\"Error:\", response.json()['error'])"
      ],
      "metadata": {
        "id": "wEVImCMnf_JB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Below is the code to train and evaluate the LightGBM model, replicating the ensembles setup:"
      ],
      "metadata": {
        "id": "j0f7eUq1kWXP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from sklearn.metrics import r2_score, mean_squared_error\n",
        "import lightgbm as lgb\n",
        "import joblib\n",
        "\n",
        "# Load and preprocess\n",
        "url = \"https://raw.githubusercontent.com/englian1123/KL-High-Rise-Data/refs/heads/main/KLHighRise.csv\"\n",
        "df = pd.read_csv(url)\n",
        "df.rename(columns={'TransactionPrice  ': 'TransactionPrice'}, inplace=True)\n",
        "df['Parcel_sq_m'] = df['ParcelArea'].astype(str).str.extract('(\\d+\\.?\\d*)').astype(float)\n",
        "df['Tenure'] = df['Tenure'].map({'Freehold': 1, 'Leasehold': 0})\n",
        "\n",
        "# Drop low-count Mukims\n",
        "low_count_mukims = ['Mukim Cheras', 'Mukim Ampang', 'Mukim Ulu Kelang']\n",
        "df = df[~df['Mukim'].isin(low_count_mukims)]\n",
        "\n",
        "# Outlier capping (91st percentile)\n",
        "price_cap = df['TransactionPrice'].quantile(0.91)\n",
        "df['TransactionPrice'] = np.clip(df['TransactionPrice'], 0, price_cap)\n",
        "area_cap = df['Parcel_sq_m'].quantile(0.91)\n",
        "df['Parcel_sq_m'] = np.clip(df['Parcel_sq_m'], 0, area_cap)\n",
        "\n",
        "# Log-transform\n",
        "df['TransactionPrice'] = np.log1p(df['TransactionPrice'])\n",
        "df['Parcel_sq_m'] = np.log1p(df['Parcel_sq_m'])\n",
        "\n",
        "# Target encode Scheme Name/Area\n",
        "scheme_encoding = df.groupby('SchemeName')['TransactionPrice'].mean()\n",
        "df['Scheme_Name_encoded'] = df['SchemeName'].map(scheme_encoding)\n",
        "joblib.dump(scheme_encoding, 'scheme_encoding.joblib')\n",
        "\n",
        "\n",
        "# Add Year\n",
        "df['Year'] = pd.to_datetime(df['TransactionDate'], format='%b-%y').dt.year\n",
        "df['Year'] = pd.to_numeric(df['Year'], errors='coerce').fillna(df['Year'].median())\n",
        "\n",
        "df['UnitLevel'] = pd.to_numeric(df['UnitLevel'], errors='coerce')\n",
        "df['UnitLevel'].fillna(df['UnitLevel'].mean(), inplace=True)\n",
        "df['UnitLevel_binned'] = pd.cut(df['UnitLevel'], bins=[-float('inf'), 10, 20, float('inf')], labels=['Low', 'Mid', 'High'])\n",
        "level_dummies = pd.get_dummies(df['UnitLevel_binned'], prefix='UnitLevel')\n",
        "\n",
        "# Setapak interactions\n",
        "mukim_dummies = pd.get_dummies(df['Mukim'], prefix='Mukim')\n",
        "df['Mukim_Mukim Setapak_Tenure'] = mukim_dummies['Mukim_Mukim Setapak'] * df['Tenure']\n",
        "df['Mukim_Mukim Setapak_Parcel_sq_m'] = mukim_dummies['Mukim_Mukim Setapak'] * df['Parcel_sq_m']\n",
        "\n",
        "# Features\n",
        "features = ['Scheme_Name_encoded', 'Parcel_sq_m', 'Year', 'Mukim_Mukim Setapak_Tenure',\n",
        "            'Mukim_Mukim Setapak_Parcel_sq_m', 'UnitLevel_High']\n",
        "X = pd.concat([df[['Scheme_Name_encoded', 'Parcel_sq_m', 'Year']],\n",
        "               df[['Mukim_Mukim Setapak_Tenure', 'Mukim_Mukim Setapak_Parcel_sq_m']],\n",
        "               level_dummies[['UnitLevel_High']]], axis=1)\n",
        "y = df['TransactionPrice']\n",
        "\n",
        "# Robust scaling\n",
        "scaler = RobustScaler()\n",
        "X[['Scheme_Name_encoded', 'Parcel_sq_m', 'Year']] = scaler.fit_transform(X[['Scheme_Name_encoded', 'Parcel_sq_m', 'Year']])\n",
        "joblib.dump(scaler, 'scaler.joblib')\n",
        "\n",
        "# Sample weights\n",
        "weights = df['Mukim'].apply(lambda x: 5.0 if x in ['Mukim Setapak', 'Mukim Petaling'] else 1.0)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test, w_train, w_test = train_test_split(X, y, weights, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train LightGBM\n",
        "lgb_model = lgb.LGBMRegressor(\n",
        "    objective='regression',\n",
        "    n_estimators=700,\n",
        "    max_depth=3,\n",
        "    learning_rate=0.1,\n",
        "    num_leaves=8,\n",
        "    random_state=42,\n",
        "    verbose=-1\n",
        ")\n",
        "lgb_model.fit(X_train, y_train, sample_weight=w_train)\n",
        "y_pred_lgb = lgb_model.predict(X_test)\n",
        "joblib.dump(lgb_model, 'lgb_model.joblib')\n",
        "\n",
        "# Evaluate LightGBM\n",
        "print(\"LightGBM R:\", r2_score(y_test, y_pred_lgb))\n",
        "print(\"LightGBM RMSE:\", np.sqrt(mean_squared_error(np.expm1(y_test), np.expm1(y_pred_lgb))))\n",
        "\n",
        "# Feature importance\n",
        "importance_lgb = pd.Series(lgb_model.feature_importances_ / sum(lgb_model.feature_importances_), index=X.columns).sort_values(ascending=False)\n",
        "print(\"LightGBM Feature Importance:\\n\", importance_lgb)\n",
        "\n",
        "# Cross-validation (using KFold with sample weights)\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "cv_lgb_scores = []\n",
        "\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train_fold, X_test_fold = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train_fold, y_test_fold = y.iloc[train_index], y.iloc[test_index]\n",
        "    weights_train_fold, weights_test_fold = weights.iloc[train_index], weights.iloc[test_index]\n",
        "\n",
        "    lgb_fold = lgb.LGBMRegressor(\n",
        "        objective='regression',\n",
        "        n_estimators=700,\n",
        "        max_depth=3,\n",
        "        learning_rate=0.1,\n",
        "        num_leaves=8,\n",
        "        random_state=42,\n",
        "        verbose=-1\n",
        "    )\n",
        "    lgb_fold.fit(X_train_fold, y_train_fold, sample_weight=weights_train_fold)\n",
        "    y_pred_lgb_fold = lgb_fold.predict(X_test_fold)\n",
        "    cv_lgb_scores.append(r2_score(y_test_fold, y_pred_lgb_fold, sample_weight=weights_test_fold))\n",
        "\n",
        "\n",
        "print(\"LightGBM 5-Fold CV R:\", np.mean(cv_lgb_scores), \"\", np.std(cv_lgb_scores))\n",
        "\n",
        "# Suburban and price-tier performance\n",
        "suburban_mask = df.loc[X_test.index, 'Mukim'].isin(['Mukim Setapak', 'Mukim Petaling'])\n",
        "low_price_mask = np.expm1(y_test) < 450000\n",
        "very_low_price_mask = np.expm1(y_test) < 300000\n",
        "print(\"Suburban LightGBM RMSE:\", np.sqrt(mean_squared_error(np.expm1(y_test[suburban_mask]), np.expm1(y_pred_lgb[suburban_mask]))))\n",
        "print(\"Low-Price (<450k RM) LightGBM RMSE:\", np.sqrt(mean_squared_error(np.expm1(y_test[low_price_mask]), np.expm1(y_pred_lgb[low_price_mask]))))\n",
        "print(\"Very Low-Price (<300k RM) LightGBM RMSE:\", np.sqrt(mean_squared_error(np.expm1(y_test[very_low_price_mask]), np.expm1(y_pred_lgb[very_low_price_mask]))))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L4sVxtSakeMn",
        "outputId": "efb4f5bd-2fbf-4da0-cd69-235681fa178c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<>:13: SyntaxWarning: invalid escape sequence '\\d'\n",
            "<>:13: SyntaxWarning: invalid escape sequence '\\d'\n",
            "/tmp/ipython-input-2753258180.py:13: SyntaxWarning: invalid escape sequence '\\d'\n",
            "  df['Parcel_sq_m'] = df['ParcelArea'].astype(str).str.extract('(\\d+\\.?\\d*)').astype(float)\n",
            "/tmp/ipython-input-2753258180.py:41: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['UnitLevel'].fillna(df['UnitLevel'].mean(), inplace=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LightGBM R: 0.9512703640815886\n",
            "LightGBM RMSE: 106605.11611068565\n",
            "LightGBM Feature Importance:\n",
            " Scheme_Name_encoded                0.413288\n",
            "Parcel_sq_m                        0.308133\n",
            "Mukim_Mukim Setapak_Parcel_sq_m    0.115464\n",
            "Year                               0.088431\n",
            "UnitLevel_High                     0.059565\n",
            "Mukim_Mukim Setapak_Tenure         0.015120\n",
            "dtype: float64\n",
            "LightGBM 5-Fold CV R: 0.9403160952180819  0.008086832117646898\n",
            "Suburban LightGBM RMSE: 78050.13576533116\n",
            "Low-Price (<450k RM) LightGBM RMSE: 46452.627532075654\n",
            "Very Low-Price (<300k RM) LightGBM RMSE: 43543.772986584074\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Deployment Integration - To incorporate LightGBM into the existing Flask API, modify the prediction function to include it as an option:"
      ],
      "metadata": {
        "id": "66ojkw40ly2A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from flask import Flask, request, jsonify\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "def predict_transaction_price(scheme_name, parcel_area, year, unit_level, tenure, mukim, model_type='ensemble'):\n",
        "    xgb = joblib.load('xgb_model.joblib') if model_type in ['ensemble', 'xgboost'] else None\n",
        "    rf = joblib.load('rf_model.joblib') if model_type in ['ensemble', 'randomforest'] else None\n",
        "    lgb = joblib.load('lgb_model.joblib') if model_type == 'lightgbm' else None\n",
        "    scaler = joblib.load('scaler.joblib')\n",
        "    scheme_encoding = joblib.load('scheme_encoding.joblib')\n",
        "\n",
        "    data = {\n",
        "        'SchemeName': [scheme_name],\n",
        "        'Parcel Area': [parcel_area],\n",
        "        'Year': [year],\n",
        "        'UnitLevel': [unit_level],\n",
        "        'Tenure': [tenure],\n",
        "        'Mukim': [mukim]\n",
        "    }\n",
        "    df = pd.DataFrame(data)\n",
        "\n",
        "    df['Parcel_sq_m'] = df['ParcelArea'].astype(str).str.extract('(\\d+\\.?\\d*)').astype(float)\n",
        "    df['Parcel_sq_m'] = np.clip(df['Parcel_sq_m'], 0, 95)\n",
        "    df['Parcel_sq_m'] = np.log1p(df['Parcel_sq_m'])\n",
        "    df['Tenure'] = df['Tenure'].map({'Freehold': 1, 'Leasehold': 0})\n",
        "    df['Year'] = pd.to_numeric(df['Year'], errors='coerce').fillna(2025)\n",
        "    df['Scheme_Name_encoded'] = df['Scheme Name/Area'].map(scheme_encoding).fillna(scheme_encoding.mean())\n",
        "\n",
        "    unit_level_map = {'Ground': 0, 'Basement': -1, 'Penthouse': 50, 'Mezzanine': 1}\n",
        "    df['UnitLevel_clean'] = df['UnitLevel'].replace(unit_level_map)\n",
        "    df['UnitLevel_clean'] = pd.to_numeric(df['UnitLevel_clean'], errors='coerce').fillna(7)\n",
        "    df['UnitLevel_High'] = (df['UnitLevel_clean'] > 15).astype(int)\n",
        "\n",
        "    df['Mukim_Mukim Setapak'] = (df['Mukim'] == 'Mukim Setapak').astype(int)\n",
        "    df['Mukim_Mukim Setapak_Tenure'] = df['Mukim_Mukim Setapak'] * df['Tenure']\n",
        "    df['Mukim_Mukim Setapak_Parcel_sq_m'] = df['Mukim_Mukim Setapak'] * df['Parcel_sq_m']\n",
        "\n",
        "    features = ['Scheme_Name_encoded', 'Parcel_sq_m', 'Year', 'Mukim_Mukim Setapak_Tenure',\n",
        "                'Mukim_Mukim Setapak_Parcel_sq_m', 'UnitLevel_High']\n",
        "    X = df[features]\n",
        "    X[['Scheme_Name_encoded', 'Parcel_sq_m', 'Year']] = scaler.transform(X[['Scheme_Name_encoded', 'Parcel_sq_m', 'Year']])\n",
        "\n",
        "    if model_type == 'ensemble':\n",
        "        y_pred_xgb = xgb.predict(X)\n",
        "        y_pred_rf = rf.predict(X)\n",
        "        y_pred = (y_pred_xgb + y_pred_rf) / 2\n",
        "    elif model_type == 'xgboost':\n",
        "        y_pred = xgb.predict(X)\n",
        "    elif model_type == 'randomforest':\n",
        "        y_pred = rf.predict(X)\n",
        "    else:  # lightgbm\n",
        "        y_pred = lgb.predict(X)\n",
        "\n",
        "    return np.expm1(y_pred)[0]\n",
        "\n",
        "@app.route('/predict', methods=['POST'])\n",
        "def predict():\n",
        "    data = request.get_json()\n",
        "    try:\n",
        "        model_type = data.get('model_type', 'ensemble')  # Default to ensemble\n",
        "        price = predict_transaction_price(\n",
        "            scheme_name=data['scheme_name'],\n",
        "            parcel_area=float(data['parcel_area']),\n",
        "            year=int(data['year']),\n",
        "            unit_level=data['unit_level'],\n",
        "            tenure=data['tenure'],\n",
        "            mukim=data['mukim'],\n",
        "            model_type=model_type\n",
        "        )\n",
        "        return jsonify({'predicted_price': round(price, 2), 'model_type': model_type})\n",
        "    except Exception as e:\n",
        "        return jsonify({'error': str(e)}), 400\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    app.run(debug=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Je7_0CBGlzQm",
        "outputId": "fab2ce07-e3b3-4dff-b288-18a8c00261d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Serving Flask app '__main__'\n",
            " * Debug mode: on\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<>:25: SyntaxWarning: invalid escape sequence '\\d'\n",
            "<>:25: SyntaxWarning: invalid escape sequence '\\d'\n",
            "/tmp/ipython-input-3706776350.py:25: SyntaxWarning: invalid escape sequence '\\d'\n",
            "  df['Parcel_sq_m'] = df['ParcelArea'].astype(str).str.extract('(\\d+\\.?\\d*)').astype(float)\n",
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
            "INFO:werkzeug: * Restarting with watchdog (inotify)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train and Evaluate ANN Model"
      ],
      "metadata": {
        "id": "6VybtxvmsfIX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from sklearn.metrics import r2_score, mean_squared_error\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import joblib\n",
        "\n",
        "# Load and preprocess\n",
        "url = \"https://raw.githubusercontent.com/englian1123/KL-High-Rise-Data/refs/heads/main/KLHighRise.csv\"\n",
        "df = pd.read_csv(url)\n",
        "df.rename(columns={'TransactionPrice  ': 'TransactionPrice'}, inplace=True)\n",
        "df['Parcel_sq_m'] = df['ParcelArea'].astype(str).str.extract('(\\d+\\.?\\d*)').astype(float)\n",
        "df['Tenure'] = df['Tenure'].map({'Freehold': 1, 'Leasehold': 0})\n",
        "\n",
        "# Drop low-count Mukims\n",
        "low_count_mukims = ['Mukim Cheras', 'Mukim Ampang', 'Mukim Ulu Kelang']\n",
        "df = df[~df['Mukim'].isin(low_count_mukims)]\n",
        "\n",
        "# Outlier capping (91st percentile)\n",
        "price_cap = df['TransactionPrice'].quantile(0.91)\n",
        "df['TransactionPrice'] = np.clip(df['TransactionPrice'], 0, price_cap)\n",
        "area_cap = df['Parcel_sq_m'].quantile(0.91)\n",
        "df['Parcel_sq_m'] = np.clip(df['Parcel_sq_m'], 0, area_cap)\n",
        "\n",
        "# Log-transform\n",
        "df['TransactionPrice'] = np.log1p(df['TransactionPrice'])\n",
        "df['Parcel_sq_m'] = np.log1p(df['Parcel_sq_m'])\n",
        "\n",
        "# Target encode Scheme Name/Area\n",
        "scheme_encoding = df.groupby('SchemeName')['TransactionPrice'].mean()\n",
        "df['Scheme_Name_encoded'] = df['SchemeName'].map(scheme_encoding)\n",
        "joblib.dump(scheme_encoding, 'scheme_encoding.joblib')\n",
        "\n",
        "# Add Year\n",
        "df['Year'] = pd.to_datetime(df['TransactionDate'], format='%b-%y').dt.year\n",
        "df['Year'] = pd.to_numeric(df['Year'], errors='coerce').fillna(df['Year'].median())\n",
        "\n",
        "# Clean UnitLevel\n",
        "df['UnitLevel'] = pd.to_numeric(df['UnitLevel'], errors='coerce')\n",
        "df['UnitLevel'].fillna(df['UnitLevel'].mean(), inplace=True)\n",
        "df['UnitLevel_binned'] = pd.cut(df['UnitLevel'], bins=[-float('inf'), 10, 20, float('inf')], labels=['Low', 'Mid', 'High'])\n",
        "level_dummies = pd.get_dummies(df['UnitLevel_binned'], prefix='UnitLevel')\n",
        "\n",
        "# Setapak interactions\n",
        "mukim_dummies = pd.get_dummies(df['Mukim'], prefix='Mukim')\n",
        "df['Mukim_Mukim Setapak_Tenure'] = mukim_dummies['Mukim_Mukim Setapak'] * df['Tenure']\n",
        "df['Mukim_Mukim Setapak_Parcel_sq_m'] = mukim_dummies['Mukim_Mukim Setapak'] * df['Parcel_sq_m']\n",
        "\n",
        "# Features\n",
        "features = ['Scheme_Name_encoded', 'Parcel_sq_m', 'Year', 'Mukim_Mukim Setapak_Tenure',\n",
        "            'Mukim_Mukim Setapak_Parcel_sq_m', 'UnitLevel_High']\n",
        "X = pd.concat([df[['Scheme_Name_encoded', 'Parcel_sq_m', 'Year']],\n",
        "               df[['Mukim_Mukim Setapak_Tenure', 'Mukim_Mukim Setapak_Parcel_sq_m']],\n",
        "               level_dummies[['UnitLevel_High']]], axis=1)\n",
        "y = df['TransactionPrice']\n",
        "\n",
        "# Robust scaling\n",
        "scaler = RobustScaler()\n",
        "X[['Scheme_Name_encoded', 'Parcel_sq_m', 'Year']] = scaler.fit_transform(X[['Scheme_Name_encoded', 'Parcel_sq_m', 'Year']])\n",
        "joblib.dump(scaler, 'scaler.joblib')\n",
        "\n",
        "# Sample weights\n",
        "weights = df['Mukim'].apply(lambda x: 5.0 if x in ['Mukim Setapak', 'Mukim Petaling'] else 1.0)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test, w_train, w_test = train_test_split(X, y, weights, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define ANN model\n",
        "def create_ann_model():\n",
        "    model = Sequential([\n",
        "        Dense(64, activation='relu', input_shape=(X.shape[1],)),\n",
        "        Dropout(0.2),\n",
        "        Dense(32, activation='relu'),\n",
        "        Dropout(0.2),\n",
        "        Dense(16, activation='relu'),\n",
        "        Dense(1)\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='mse')\n",
        "    return model\n",
        "\n",
        "# Train ANN\n",
        "ann_model = create_ann_model()\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "ann_model.fit(X_train, y_train, sample_weight=w_train, epochs=100, batch_size=32,\n",
        "              validation_split=0.2, callbacks=[early_stopping], verbose=0)\n",
        "y_pred_ann = ann_model.predict(X_test, verbose=0).flatten()\n",
        "ann_model.save('ann_model.h5')\n",
        "\n",
        "# Evaluate ANN\n",
        "print(\"ANN R:\", r2_score(y_test, y_pred_ann))\n",
        "print(\"ANN RMSE:\", np.sqrt(mean_squared_error(np.expm1(y_test), np.expm1(y_pred_ann))))\n",
        "\n",
        "# Cross-validation\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "cv_ann_scores = []\n",
        "\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train_fold, X_test_fold = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train_fold, y_test_fold = y.iloc[train_index], y.iloc[test_index]\n",
        "    weights_train_fold = weights.iloc[train_index]\n",
        "\n",
        "    fold_model = create_ann_model()\n",
        "    fold_model.fit(X_train_fold, y_train_fold, sample_weight=weights_train_fold, epochs=100,\n",
        "                   batch_size=32, validation_split=0.2, callbacks=[early_stopping], verbose=0)\n",
        "    y_pred_fold = fold_model.predict(X_test_fold, verbose=0).flatten()\n",
        "    cv_ann_scores.append(r2_score(y_test_fold, y_pred_fold))\n",
        "\n",
        "print(\"ANN 5-Fold CV R:\", np.mean(cv_ann_scores), \"\", np.std(cv_ann_scores))\n",
        "\n",
        "# Suburban and price-tier performance\n",
        "suburban_mask = df.loc[X_test.index, 'Mukim'].isin(['Mukim Setapak', 'Mukim Petaling'])\n",
        "low_price_mask = np.expm1(y_test) < 450000\n",
        "very_low_price_mask = np.expm1(y_test) < 300000\n",
        "print(\"Suburban ANN RMSE:\", np.sqrt(mean_squared_error(np.expm1(y_test[suburban_mask]), np.expm1(y_pred_ann[suburban_mask]))))\n",
        "print(\"Low-Price (<450k RM) ANN RMSE:\", np.sqrt(mean_squared_error(np.expm1(y_test[low_price_mask]), np.expm1(y_pred_ann[low_price_mask]))))\n",
        "print(\"Very Low-Price (<300k RM) ANN RMSE:\", np.sqrt(mean_squared_error(np.expm1(y_test[very_low_price_mask]), np.expm1(y_pred_ann[very_low_price_mask]))))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EWtMB8gqshgy",
        "outputId": "1aa00929-ad54-4a6a-fb39-258d13590597"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<>:15: SyntaxWarning: invalid escape sequence '\\d'\n",
            "<>:15: SyntaxWarning: invalid escape sequence '\\d'\n",
            "/tmp/ipython-input-1694526144.py:15: SyntaxWarning: invalid escape sequence '\\d'\n",
            "  df['Parcel_sq_m'] = df['ParcelArea'].astype(str).str.extract('(\\d+\\.?\\d*)').astype(float)\n",
            "/tmp/ipython-input-1694526144.py:43: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['UnitLevel'].fillna(df['UnitLevel'].mean(), inplace=True)\n",
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ANN R: 0.6256300007201949\n",
            "ANN RMSE: 325662.68232579227\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ANN 5-Fold CV R: 0.6418281738218367  0.41556845041837226\n",
            "Suburban ANN RMSE: 220283.88860021127\n",
            "Low-Price (<450k RM) ANN RMSE: 112794.00643367518\n",
            "Very Low-Price (<300k RM) ANN RMSE: 118201.62449592122\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Improve ANN Architecture"
      ],
      "metadata": {
        "id": "-Ih22r8B0Q3P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from sklearn.metrics import r2_score, mean_squared_error\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.optimizers import AdamW\n",
        "import joblib\n",
        "\n",
        "# Load and preprocess\n",
        "url = \"https://raw.githubusercontent.com/englian1123/KL-High-Rise-Data/refs/heads/main/KLHighRise.csv\"\n",
        "df = pd.read_csv(url)\n",
        "df.rename(columns={'TransactionPrice  ': 'TransactionPrice'}, inplace=True)\n",
        "df['Parcel_sq_m'] = df['ParcelArea'].astype(str).str.extract('(\\d+\\.?\\d*)').astype(float)\n",
        "df['Tenure'] = df['Tenure'].map({'Freehold': 1, 'Leasehold': 0})\n",
        "\n",
        "# Drop low-count Mukims\n",
        "low_count_mukims = ['Mukim Cheras', 'Mukim Ampang', 'Mukim Ulu Kelang']\n",
        "df = df[~df['Mukim'].isin(low_count_mukims)]\n",
        "\n",
        "# Outlier capping (91st percentile)\n",
        "price_cap = df['TransactionPrice'].quantile(0.91)\n",
        "df['TransactionPrice'] = np.clip(df['TransactionPrice'], 0, price_cap)\n",
        "area_cap = df['Parcel_sq_m'].quantile(0.91)\n",
        "df['Parcel_sq_m'] = np.clip(df['Parcel_sq_m'], 0, area_cap)\n",
        "\n",
        "# Log-transform\n",
        "df['TransactionPrice'] = np.log1p(df['TransactionPrice'])\n",
        "df['Parcel_sq_m'] = np.log1p(df['Parcel_sq_m'])\n",
        "\n",
        "# Target encode Scheme Name/Area\n",
        "scheme_encoding = df.groupby('SchemeName')['TransactionPrice'].mean()\n",
        "df['Scheme_Name_encoded'] = df['SchemeName'].map(scheme_encoding)\n",
        "joblib.dump(scheme_encoding, 'scheme_encoding.joblib')\n",
        "\n",
        "# Add Year\n",
        "df['Year'] = pd.to_datetime(df['TransactionDate'], format='%b-%y').dt.year\n",
        "df['Year'] = pd.to_numeric(df['Year'], errors='coerce').fillna(df['Year'].median())\n",
        "\n",
        "# Clean UnitLevel\n",
        "\n",
        "df['UnitLevel'] = pd.to_numeric(df['UnitLevel'], errors='coerce')\n",
        "df['UnitLevel'].fillna(df['UnitLevel'].mean(), inplace=True)\n",
        "df['UnitLevel_binned'] = pd.cut(df['UnitLevel'], bins=[-float('inf'), 10, 20, float('inf')], labels=['Low', 'Mid', 'High'])\n",
        "level_dummies = pd.get_dummies(df['UnitLevel_binned'], prefix='UnitLevel')\n",
        "\n",
        "#unit_level_map = {'Ground': 0, 'Basement': -1, 'Penthouse': 50, 'Mezzanine': 1}\n",
        "#df['UnitLevel_clean'] = df['UnitLevel'].replace(unit_level_map)\n",
        "#df['UnitLevel_clean'] = pd.to_numeric(df['UnitLevel_clean'], errors='coerce').fillna(df['UnitLevel_clean'].mean())\n",
        "#df['UnitLevel_binned'] = pd.cut(df['UnitLevel_clean'], bins=[-float('inf'), 10, 20, float('inf')], labels=['Low', 'Mid', 'High'])\n",
        "#level_dummies = pd.get_dummies(df['UnitLevel_binned'], prefix='UnitLevel')\n",
        "\n",
        "# Setapak interactions\n",
        "mukim_dummies = pd.get_dummies(df['Mukim'], prefix='Mukim')\n",
        "df['Mukim_Mukim Setapak_Tenure'] = mukim_dummies['Mukim_Mukim Setapak'] * df['Tenure']\n",
        "df['Mukim_Mukim Setapak_Parcel_sq_m'] = mukim_dummies['Mukim_Mukim Setapak'] * df['Parcel_sq_m']\n",
        "\n",
        "# Features\n",
        "features = ['Scheme_Name_encoded', 'Parcel_sq_m', 'Year', 'Mukim_Mukim Setapak_Tenure',\n",
        "            'Mukim_Mukim Setapak_Parcel_sq_m', 'UnitLevel_High']\n",
        "X = pd.concat([df[['Scheme_Name_encoded', 'Parcel_sq_m', 'Year']],\n",
        "               df[['Mukim_Mukim Setapak_Tenure', 'Mukim_Mukim Setapak_Parcel_sq_m']],\n",
        "               level_dummies[['UnitLevel_High']]], axis=1)\n",
        "y = df['TransactionPrice']\n",
        "\n",
        "# Robust scaling\n",
        "scaler = RobustScaler()\n",
        "X[['Scheme_Name_encoded', 'Parcel_sq_m', 'Year']] = scaler.fit_transform(X[['Scheme_Name_encoded', 'Parcel_sq_m', 'Year']])\n",
        "joblib.dump(scaler, 'scaler.joblib')\n",
        "\n",
        "# Sample weights\n",
        "weights = df['Mukim'].apply(lambda x: 5.0 if x in ['Mukim Setapak', 'Mukim Petaling'] else 1.0)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test, w_train, w_test = train_test_split(X, y, weights, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define improved ANN model\n",
        "def create_ann_model():\n",
        "    model = Sequential([\n",
        "        Dense(128, activation='relu', input_shape=(X.shape[1],)),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.3),\n",
        "        Dense(64, activation='relu'),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.3),\n",
        "        Dense(32, activation='relu'),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.3),\n",
        "        Dense(16, activation='relu'),\n",
        "        Dense(1)\n",
        "    ])\n",
        "    optimizer = AdamW(learning_rate=0.001)\n",
        "    model.compile(optimizer=optimizer, loss='mse')\n",
        "    return model\n",
        "\n",
        "# Train ANN\n",
        "ann_model = create_ann_model()\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10, min_lr=0.0001)\n",
        "ann_model.fit(X_train, y_train, sample_weight=w_train, epochs=200, batch_size=32,\n",
        "              validation_split=0.2, callbacks=[early_stopping, reduce_lr], verbose=0)\n",
        "ann_model.save('ann_model.h5')\n",
        "\n",
        "# Evaluate ANN\n",
        "y_pred_ann = ann_model.predict(X_test, verbose=0).flatten()\n",
        "print(\"ANN R:\", r2_score(y_test, y_pred_ann))\n",
        "print(\"ANN RMSE:\", np.sqrt(mean_squared_error(np.expm1(y_test), np.expm1(y_pred_ann))))\n",
        "\n",
        "# Cross-validation\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "cv_ann_scores = []\n",
        "\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train_fold, X_test_fold = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train_fold, y_test_fold = y.iloc[train_index], y.iloc[test_index]\n",
        "    weights_train_fold = weights.iloc[train_index]\n",
        "\n",
        "    fold_model = create_ann_model()\n",
        "    fold_model.fit(X_train_fold, y_train_fold, sample_weight=weights_train_fold, epochs=200,\n",
        "                   batch_size=32, validation_split=0.2, callbacks=[early_stopping, reduce_lr], verbose=0)\n",
        "    y_pred_fold = fold_model.predict(X_test_fold, verbose=0).flatten()\n",
        "    cv_ann_scores.append(r2_score(y_test_fold, y_pred_fold))\n",
        "\n",
        "print(\"ANN 5-Fold CV R:\", np.mean(cv_ann_scores), \"\", np.std(cv_ann_scores))\n",
        "\n",
        "# Suburban and price-tier performance\n",
        "suburban_mask = df.loc[X_test.index, 'Mukim'].isin(['Mukim Setapak', 'Mukim Petaling'])\n",
        "low_price_mask = np.expm1(y_test) < 450000\n",
        "very_low_price_mask = np.expm1(y_test) < 300000\n",
        "print(\"Suburban ANN RMSE:\", np.sqrt(mean_squared_error(np.expm1(y_test[suburban_mask]), np.expm1(y_pred_ann[suburban_mask]))))\n",
        "print(\"Low-Price (<450k RM) ANN RMSE:\", np.sqrt(mean_squared_error(np.expm1(y_test[low_price_mask]), np.expm1(y_pred_ann[low_price_mask]))))\n",
        "print(\"Very Low-Price (<300k RM) ANN RMSE:\", np.sqrt(mean_squared_error(np.expm1(y_test[very_low_price_mask]), np.expm1(y_pred_ann[very_low_price_mask]))))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ep2oO-uR0Tyw",
        "outputId": "450d3f51-ea7b-431b-cbd1-1270e63d5adc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<>:16: SyntaxWarning: invalid escape sequence '\\d'\n",
            "<>:16: SyntaxWarning: invalid escape sequence '\\d'\n",
            "/tmp/ipython-input-1350273844.py:16: SyntaxWarning: invalid escape sequence '\\d'\n",
            "  df['Parcel_sq_m'] = df['ParcelArea'].astype(str).str.extract('(\\d+\\.?\\d*)').astype(float)\n",
            "/tmp/ipython-input-1350273844.py:45: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['UnitLevel'].fillna(df['UnitLevel'].mean(), inplace=True)\n",
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ANN R: 0.8798420843017155\n",
            "ANN RMSE: 232991.83872702272\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ANN 5-Fold CV R: 0.8788527006397497  0.05278522920862867\n",
            "Suburban ANN RMSE: 106543.63598477551\n",
            "Low-Price (<450k RM) ANN RMSE: 52930.96609925005\n",
            "Very Low-Price (<300k RM) ANN RMSE: 47990.99856697518\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Further ANN Improvements"
      ],
      "metadata": {
        "id": "HddAe7nA7XYN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*  Deeper Architecture: Expand to 256-128-64-32 neurons with 4 hidden layers to capture more complex non-linear patterns (e.g., interactions between size and location).\n",
        "\n",
        "*  Interaction Terms: Add new features like Scheme_Name_encoded * Parcel_sq_m (premium-size effect) and Year * Parcel_sq_m (time-size trend), as suggested. These can help the ANN model non-linear relationships more effectively.\n",
        "\n",
        "*  Other Tweaks: Increase dropout to 0.30.4 for regularization, use RMSprop optimizer for faster convergence, and 300 epochs with patience=30 for better training. We'll keep the same preprocessing (91st percentile capping, log-transformation, RobustScaler, weights 5.0 for Setapak/Petaling) and features, adding the interactions."
      ],
      "metadata": {
        "id": "zVjJJQrd6-Xz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from sklearn.metrics import r2_score, mean_squared_error\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "import joblib\n",
        "\n",
        "# Load and preprocess\n",
        "url = \"https://raw.githubusercontent.com/englian1123/KL-High-Rise-Data/refs/heads/main/KLHighRise.csv\"\n",
        "df = pd.read_csv(url)\n",
        "df.rename(columns={'TransactionPrice  ': 'TransactionPrice'}, inplace=True)\n",
        "df['Parcel_sq_m'] = df['ParcelArea'].astype(str).str.extract('(\\d+\\.?\\d*)').astype(float)\n",
        "df['Tenure'] = df['Tenure'].map({'Freehold': 1, 'Leasehold': 0})\n",
        "\n",
        "# Drop low-count Mukims\n",
        "low_count_mukims = ['Mukim Cheras', 'Mukim Ampang', 'Mukim Ulu Kelang']\n",
        "df = df[~df['Mukim'].isin(low_count_mukims)]\n",
        "\n",
        "# Outlier capping (91st percentile)\n",
        "price_cap = df['TransactionPrice'].quantile(0.91)\n",
        "df['TransactionPrice'] = np.clip(df['TransactionPrice'], 0, price_cap)\n",
        "area_cap = df['Parcel_sq_m'].quantile(0.91)\n",
        "df['Parcel_sq_m'] = np.clip(df['Parcel_sq_m'], 0, area_cap)\n",
        "\n",
        "# Log-transform\n",
        "df['TransactionPrice'] = np.log1p(df['TransactionPrice'])\n",
        "df['Parcel_sq_m'] = np.log1p(df['Parcel_sq_m'])\n",
        "\n",
        "# Target encode Scheme Name/Area\n",
        "scheme_encoding = df.groupby('SchemeName')['TransactionPrice'].mean()\n",
        "df['Scheme_Name_encoded'] = df['SchemeName'].map(scheme_encoding)\n",
        "joblib.dump(scheme_encoding, 'scheme_encoding.joblib')\n",
        "\n",
        "# Add Year\n",
        "df['Year'] = pd.to_datetime(df['TransactionDate'], format='%b-%y').dt.year\n",
        "df['Year'] = pd.to_numeric(df['Year'], errors='coerce').fillna(df['Year'].median())\n",
        "\n",
        "# Clean UnitLevel\n",
        "# unit_level_map = {'Ground': 0, 'Basement': -1, 'Penthouse': 50, 'Mezzanine': 1}\n",
        "# df['UnitLevel_clean'] = df['UnitLevel'].replace(unit_level_map)\n",
        "# df['UnitLevel_clean'] = pd.to_numeric(df['UnitLevel_clean'], errors='coerce').fillna(df['UnitLevel_clean'].mean())\n",
        "# df['UnitLevel_binned'] = pd.cut(df['UnitLevel_clean'], bins=[-float('inf'), 10, 20, float('inf')], labels=['Low', 'Mid', 'High'])\n",
        "# level_dummies = pd.get_dummies(df['UnitLevel_binned'], prefix='UnitLevel')\n",
        "\n",
        "df['UnitLevel'] = pd.to_numeric(df['UnitLevel'], errors='coerce')\n",
        "df['UnitLevel'].fillna(df['UnitLevel'].mean(), inplace=True)\n",
        "df['UnitLevel_binned'] = pd.cut(df['UnitLevel'], bins=[-float('inf'), 10, 20, float('inf')], labels=['Low', 'Mid', 'High'])\n",
        "level_dummies = pd.get_dummies(df['UnitLevel_binned'], prefix='UnitLevel')\n",
        "\n",
        "\n",
        "# Setapak interactions\n",
        "mukim_dummies = pd.get_dummies(df['Mukim'], prefix='Mukim')\n",
        "df['Mukim_Mukim Setapak_Tenure'] = mukim_dummies['Mukim_Mukim Setapak'] * df['Tenure']\n",
        "df['Mukim_Mukim Setapak_Parcel_sq_m'] = mukim_dummies['Mukim_Mukim Setapak'] * df['Parcel_sq_m']\n",
        "\n",
        "# New interaction terms\n",
        "df['Scheme_Name_encoded_Parcel_sq_m'] = df['Scheme_Name_encoded'] * df['Parcel_sq_m']\n",
        "df['Year_Parcel_sq_m'] = df['Year'] * df['Parcel_sq_m']\n",
        "\n",
        "# Features (add interactions)\n",
        "features = ['Scheme_Name_encoded', 'Parcel_sq_m', 'Year', 'Mukim_Mukim Setapak_Tenure',\n",
        "            'Mukim_Mukim Setapak_Parcel_sq_m', 'UnitLevel_High', 'Scheme_Name_encoded_Parcel_sq_m', 'Year_Parcel_sq_m']\n",
        "X = pd.concat([df[['Scheme_Name_encoded', 'Parcel_sq_m', 'Year']],\n",
        "               df[['Mukim_Mukim Setapak_Tenure', 'Mukim_Mukim Setapak_Parcel_sq_m']],\n",
        "               level_dummies[['UnitLevel_High']],\n",
        "               df[['Scheme_Name_encoded_Parcel_sq_m', 'Year_Parcel_sq_m']]], axis=1)\n",
        "y = df['TransactionPrice']\n",
        "\n",
        "# Robust scaling\n",
        "scaler = RobustScaler()\n",
        "X[['Scheme_Name_encoded', 'Parcel_sq_m', 'Year', 'Scheme_Name_encoded_Parcel_sq_m', 'Year_Parcel_sq_m']] = scaler.fit_transform(X[['Scheme_Name_encoded', 'Parcel_sq_m', 'Year', 'Scheme_Name_encoded_Parcel_sq_m', 'Year_Parcel_sq_m']])\n",
        "joblib.dump(scaler, 'scaler.joblib')\n",
        "\n",
        "# Sample weights\n",
        "weights = df['Mukim'].apply(lambda x: 5.0 if x in ['Mukim Setapak', 'Mukim Petaling'] else 1.0)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test, w_train, w_test = train_test_split(X, y, weights, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define improved ANN model\n",
        "def create_ann_model():\n",
        "    model = Sequential([\n",
        "        Dense(256, activation='relu', input_shape=(X.shape[1],)),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.4),\n",
        "        Dense(128, activation='relu'),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.4),\n",
        "        Dense(64, activation='relu'),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.3),\n",
        "        Dense(32, activation='relu'),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.3),\n",
        "        Dense(1)\n",
        "    ])\n",
        "    optimizer = RMSprop(learning_rate=0.001)\n",
        "    model.compile(optimizer=optimizer, loss='mse')\n",
        "    return model\n",
        "\n",
        "# Train ANN\n",
        "ann_model = create_ann_model()\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=30, restore_best_weights=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10, min_lr=0.00001)\n",
        "ann_model.fit(X_train, y_train, sample_weight=w_train, epochs=300, batch_size=32,\n",
        "              validation_split=0.2, callbacks=[early_stopping, reduce_lr], verbose=0)\n",
        "ann_model.save('ann_model.h5')\n",
        "\n",
        "# Evaluate ANN\n",
        "y_pred_ann = ann_model.predict(X_test, verbose=0).flatten()\n",
        "print(\"ANN R:\", r2_score(y_test, y_pred_ann))\n",
        "print(\"ANN RMSE:\", np.sqrt(mean_squared_error(np.expm1(y_test), np.expm1(y_pred_ann))))\n",
        "\n",
        "# Cross-validation\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "cv_ann_scores = []\n",
        "\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train_fold, X_test_fold = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train_fold, y_test_fold = y.iloc[train_index], y.iloc[test_index]\n",
        "    weights_train_fold = weights.iloc[train_index]\n",
        "\n",
        "    fold_model = create_ann_model()\n",
        "    fold_model.fit(X_train_fold, y_train_fold, sample_weight=weights_train_fold, epochs=300,\n",
        "                   batch_size=32, validation_split=0.2, callbacks=[early_stopping, reduce_lr], verbose=0)\n",
        "    y_pred_fold = fold_model.predict(X_test_fold, verbose=0).flatten()\n",
        "    cv_ann_scores.append(r2_score(y_test_fold, y_pred_fold))\n",
        "\n",
        "print(\"ANN 5-Fold CV R:\", np.mean(cv_ann_scores), \"\", np.std(cv_ann_scores))\n",
        "\n",
        "# Suburban and price-tier performance\n",
        "suburban_mask = df.loc[X_test.index, 'Mukim'].isin(['Mukim Setapak', 'Mukim Petaling'])\n",
        "low_price_mask = np.expm1(y_test) < 450000\n",
        "very_low_price_mask = np.expm1(y_test) < 300000\n",
        "print(\"Suburban ANN RMSE:\", np.sqrt(mean_squared_error(np.expm1(y_test[suburban_mask]), np.expm1(y_pred_ann[suburban_mask]))))\n",
        "print(\"Low-Price (<450k RM) ANN RMSE:\", np.sqrt(mean_squared_error(np.expm1(y_test[low_price_mask]), np.expm1(y_pred_ann[low_price_mask]))))\n",
        "print(\"Very Low-Price (<300k RM) ANN RMSE:\", np.sqrt(mean_squared_error(np.expm1(y_test[very_low_price_mask]), np.expm1(y_pred_ann[very_low_price_mask]))))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9sQySVEW0UAt",
        "outputId": "b8a0fe74-36b2-4b4b-b2e8-667ca9104598"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<>:16: SyntaxWarning: invalid escape sequence '\\d'\n",
            "<>:16: SyntaxWarning: invalid escape sequence '\\d'\n",
            "/tmp/ipython-input-1202918701.py:16: SyntaxWarning: invalid escape sequence '\\d'\n",
            "  df['Parcel_sq_m'] = df['ParcelArea'].astype(str).str.extract('(\\d+\\.?\\d*)').astype(float)\n",
            "/tmp/ipython-input-1202918701.py:50: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['UnitLevel'].fillna(df['UnitLevel'].mean(), inplace=True)\n",
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ANN R: 0.9107820192052271\n",
            "ANN RMSE: 143953.0771907707\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ANN 5-Fold CV R: 0.9014827837417851  0.013909783490653341\n",
            "Suburban ANN RMSE: 107848.57247159022\n",
            "Low-Price (<450k RM) ANN RMSE: 45345.082982908556\n",
            "Very Low-Price (<300k RM) ANN RMSE: 49965.23659902202\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from sklearn.metrics import r2_score, mean_squared_error\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.optimizers import Nadam\n",
        "from tensorflow.keras.regularizers import l2\n",
        "import joblib\n",
        "\n",
        "# Load and preprocess\n",
        "url = \"https://raw.githubusercontent.com/englian1123/KL-High-Rise-Data/refs/heads/main/KLHighRise.csv\"\n",
        "df = pd.read_csv(url)\n",
        "df.rename(columns={'TransactionPrice  ': 'TransactionPrice'}, inplace=True)\n",
        "df['Parcel_sq_m'] = df['ParcelArea'].astype(str).str.extract('(\\d+\\.?\\d*)').astype(float)\n",
        "df['Tenure'] = df['Tenure'].map({'Freehold': 1, 'Leasehold': 0})\n",
        "\n",
        "# Drop low-count Mukims\n",
        "low_count_mukims = ['Mukim Cheras', 'Mukim Ampang', 'Mukim Ulu Kelang']\n",
        "df = df[~df['Mukim'].isin(low_count_mukims)]\n",
        "\n",
        "# Outlier capping (91st percentile)\n",
        "price_cap = df['TransactionPrice'].quantile(0.91)\n",
        "df['TransactionPrice'] = np.clip(df['TransactionPrice'], 0, price_cap)\n",
        "area_cap = df['Parcel_sq_m'].quantile(0.91)\n",
        "df['Parcel_sq_m'] = np.clip(df['Parcel_sq_m'], 0, area_cap)\n",
        "\n",
        "# Log-transform\n",
        "df['TransactionPrice'] = np.log1p(df['TransactionPrice'])\n",
        "df['Parcel_sq_m'] = np.log1p(df['Parcel_sq_m'])\n",
        "\n",
        "# Target encode Scheme Name/Area\n",
        "scheme_encoding = df.groupby('SchemeName')['TransactionPrice'].mean()\n",
        "df['Scheme_Name_encoded'] = df['SchemeName'].map(scheme_encoding)\n",
        "joblib.dump(scheme_encoding, 'scheme_encoding.joblib')\n",
        "\n",
        "# Add Year\n",
        "df['Year'] = pd.to_datetime(df['TransactionDate'], format='%b-%y').dt.year\n",
        "df['Year'] = pd.to_numeric(df['Year'], errors='coerce').fillna(df['Year'].median())\n",
        "\n",
        "# Clean UnitLevel\n",
        "# unit_level_map = {'Ground': 0, 'Basement': -1, 'Penthouse': 50, 'Mezzanine': 1}\n",
        "# df['UnitLevel_clean'] = df['UnitLevel'].replace(unit_level_map)\n",
        "# df['UnitLevel_clean'] = pd.to_numeric(df['UnitLevel_clean'], errors='coerce').fillna(df['UnitLevel_clean'].mean())\n",
        "# df['UnitLevel_binned'] = pd.cut(df['UnitLevel_clean'], bins=[-float('inf'), 10, 20, float('inf')], labels=['Low', 'Mid', 'High'])\n",
        "# level_dummies = pd.get_dummies(df['UnitLevel_binned'], prefix='UnitLevel')\n",
        "\n",
        "df['UnitLevel'] = pd.to_numeric(df['UnitLevel'], errors='coerce')\n",
        "df['UnitLevel'].fillna(df['UnitLevel'].mean(), inplace=True)\n",
        "df['UnitLevel_binned'] = pd.cut(df['UnitLevel'], bins=[-float('inf'), 10, 20, float('inf')], labels=['Low', 'Mid', 'High'])\n",
        "level_dummies = pd.get_dummies(df['UnitLevel_binned'], prefix='UnitLevel')\n",
        "\n",
        "# Setapak interactions\n",
        "mukim_dummies = pd.get_dummies(df['Mukim'], prefix='Mukim')\n",
        "df['Mukim_Mukim Setapak_Tenure'] = mukim_dummies['Mukim_Mukim Setapak'] * df['Tenure']\n",
        "df['Mukim_Mukim Setapak_Parcel_sq_m'] = mukim_dummies['Mukim_Mukim Setapak'] * df['Parcel_sq_m']\n",
        "\n",
        "# Additional interaction terms\n",
        "df['UnitLevel_High'] = level_dummies['UnitLevel_High']\n",
        "df['UnitLevel_High_Parcel_sq_m'] = df['UnitLevel_High'] * df['Parcel_sq_m']\n",
        "df['Mukim_Mukim Setapak_Tenure_Scheme_Name_encoded'] = df['Mukim_Mukim Setapak_Tenure'] * df['Scheme_Name_encoded']\n",
        "\n",
        "# Data augmentation with Gaussian noise\n",
        "numerical_cols = ['Scheme_Name_encoded', 'Parcel_sq_m', 'Year', 'UnitLevel_High_Parcel_sq_m', 'Mukim_Mukim Setapak_Tenure_Scheme_Name_encoded']\n",
        "X = pd.concat([df[['Scheme_Name_encoded', 'Parcel_sq_m', 'Year']],\n",
        "               df[['Mukim_Mukim Setapak_Tenure', 'Mukim_Mukim Setapak_Parcel_sq_m', 'UnitLevel_High', 'UnitLevel_High_Parcel_sq_m', 'Mukim_Mukim Setapak_Tenure_Scheme_Name_encoded']]], axis=1)\n",
        "y = df['TransactionPrice']\n",
        "\n",
        "# Sample weights\n",
        "weights = df['Mukim'].apply(lambda x: 5.0 if x in ['Mukim Setapak', 'Mukim Petaling'] else 1.0)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test, w_train, w_test = train_test_split(X, y, weights, test_size=0.2, random_state=42)\n",
        "\n",
        "# Augment training data with Gaussian noise\n",
        "noise_factor = 0.05  # 5% noise\n",
        "aug_X = X_train.copy()\n",
        "aug_y = y_train.copy()\n",
        "for col in numerical_cols:\n",
        "    noise = np.random.normal(0, noise_factor * X_train[col].std(), len(X_train))\n",
        "    aug_X[col] += noise\n",
        "aug_X = pd.concat([X_train, aug_X])\n",
        "aug_y = pd.concat([y_train, aug_y])\n",
        "aug_weights = np.concatenate([w_train, w_train])\n",
        "\n",
        "# Robust scaling\n",
        "scaler = RobustScaler()\n",
        "aug_X[numerical_cols] = scaler.fit_transform(aug_X[numerical_cols])\n",
        "X_test[numerical_cols] = scaler.transform(X_test[numerical_cols])\n",
        "joblib.dump(scaler, 'scaler.joblib')\n",
        "\n",
        "# Define improved ANN model\n",
        "def create_ann_model():\n",
        "    model = Sequential([\n",
        "        Dense(512, activation='relu', input_shape=(X.shape[1],), kernel_regularizer=l2(0.01)),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.4),\n",
        "        Dense(256, activation='relu', kernel_regularizer=l2(0.01)),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.4),\n",
        "        Dense(128, activation='relu', kernel_regularizer=l2(0.01)),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.3),\n",
        "        Dense(64, activation='relu', kernel_regularizer=l2(0.01)),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.3),\n",
        "        Dense(1)\n",
        "    ])\n",
        "    optimizer = Nadam(learning_rate=0.001)\n",
        "    model.compile(optimizer=optimizer, loss='mse')\n",
        "    return model\n",
        "\n",
        "# Train ANN\n",
        "ann_model = create_ann_model()\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=50, restore_best_weights=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10, min_lr=0.00001)\n",
        "ann_model.fit(aug_X, aug_y, sample_weight=aug_weights, epochs=600, batch_size=32,\n",
        "              validation_split=0.2, callbacks=[early_stopping, reduce_lr], verbose=0)\n",
        "ann_model.save('ann_model.h5')\n",
        "\n",
        "# Evaluate ANN\n",
        "y_pred_ann = ann_model.predict(X_test, verbose=0).flatten()\n",
        "print(\"ANN R:\", r2_score(y_test, y_pred_ann))\n",
        "print(\"ANN RMSE:\", np.sqrt(mean_squared_error(np.expm1(y_test), np.expm1(y_pred_ann))))\n",
        "\n",
        "# Cross-validation\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "cv_ann_scores = []\n",
        "\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train_fold, X_test_fold = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train_fold, y_test_fold = y.iloc[train_index], y.iloc[test_index]\n",
        "    weights_train_fold = weights.iloc[train_index]\n",
        "\n",
        "    # Augment fold training data with Gaussian noise\n",
        "    aug_X_fold = X_train_fold.copy()\n",
        "    aug_y_fold = y_train_fold.copy()\n",
        "    for col in numerical_cols:\n",
        "        noise = np.random.normal(0, noise_factor * X_train_fold[col].std(), len(X_train_fold))\n",
        "        aug_X_fold[col] += noise\n",
        "    aug_X_fold = pd.concat([X_train_fold, aug_X_fold])\n",
        "    aug_y_fold = pd.concat([y_train_fold, aug_y_fold])\n",
        "    aug_weights_fold = np.concatenate([weights_train_fold, weights_train_fold])\n",
        "\n",
        "    fold_model = create_ann_model()\n",
        "    fold_model.fit(aug_X_fold, aug_y_fold, sample_weight=aug_weights_fold, epochs=600,\n",
        "                   batch_size=32, validation_split=0.2, callbacks=[early_stopping, reduce_lr], verbose=0)\n",
        "    y_pred_fold = fold_model.predict(X_test_fold, verbose=0).flatten()\n",
        "    cv_ann_scores.append(r2_score(y_test_fold, y_pred_fold))\n",
        "\n",
        "print(\"ANN 5-Fold CV R:\", np.mean(cv_ann_scores), \"\", np.std(cv_ann_scores))\n",
        "\n",
        "# Suburban and price-tier performance\n",
        "suburban_mask = df.loc[X_test.index, 'Mukim'].isin(['Mukim Setapak', 'Mukim Petaling'])\n",
        "low_price_mask = np.expm1(y_test) < 450000\n",
        "very_low_price_mask = np.expm1(y_test) < 300000\n",
        "print(\"Suburban ANN RMSE:\", np.sqrt(mean_squared_error(np.expm1(y_test[suburban_mask]), np.expm1(y_pred_ann[suburban_mask]))))\n",
        "print(\"Low-Price (<450k RM) ANN RMSE:\", np.sqrt(mean_squared_error(np.expm1(y_test[low_price_mask]), np.expm1(y_pred_ann[low_price_mask]))))\n",
        "print(\"Very Low-Price (<300k RM) ANN RMSE:\", np.sqrt(mean_squared_error(np.expm1(y_test[very_low_price_mask]), np.expm1(y_pred_ann[very_low_price_mask]))))"
      ],
      "metadata": {
        "id": "6H-j01J6CHzC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RNN"
      ],
      "metadata": {
        "id": "n08sUwuTWxuY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from sklearn.metrics import r2_score, mean_squared_error\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Input, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "import joblib\n",
        "\n",
        "# Load and preprocess\n",
        "url = \"https://raw.githubusercontent.com/englian1123/KL-High-Rise-Data/refs/heads/main/KLHighRise.csv\"\n",
        "df = pd.read_csv(url)\n",
        "df.rename(columns={'TransactionPrice  ': 'TransactionPrice', 'Parcel Area': 'ParcelArea', 'Scheme Name/Area': 'SchemeName'}, inplace=True)\n",
        "df['Parcel_sq_m'] = df['ParcelArea'].astype(str).str.extract('(\\d+\\.?\\d*)').astype(np.float32)\n",
        "df['Tenure'] = df['Tenure'].map({'Freehold': 1, 'Leasehold': 0}).fillna(0).astype(np.float32)\n",
        "\n",
        "# Drop low-count Mukims\n",
        "low_count_mukims = ['Mukim Cheras', 'Mukim Ampang', 'Mukim Ulu Kelang']\n",
        "df = df[~df['Mukim'].isin(low_count_mukims)]\n",
        "\n",
        "# Stricter outlier capping (90th percentile)\n",
        "price_cap = df['TransactionPrice'].quantile(0.90)\n",
        "df['TransactionPrice'] = np.clip(df['TransactionPrice'], 0, price_cap).astype(np.float32)\n",
        "area_cap = df['Parcel_sq_m'].quantile(0.90)\n",
        "df['Parcel_sq_m'] = np.clip(df['Parcel_sq_m'], 0, area_cap).astype(np.float32)\n",
        "\n",
        "# Log-transform\n",
        "df['TransactionPrice'] = np.log1p(df['TransactionPrice']).astype(np.float32)\n",
        "df['Parcel_sq_m'] = np.log1p(df['Parcel_sq_m']).astype(np.float32)\n",
        "\n",
        "# Target encode SchemeName\n",
        "scheme_encoding = df.groupby('SchemeName')['TransactionPrice'].mean().astype(np.float32)\n",
        "df['Scheme_Name_encoded'] = df['SchemeName'].map(scheme_encoding).fillna(scheme_encoding.mean()).astype(np.float32)\n",
        "joblib.dump(scheme_encoding, 'scheme_encoding.joblib')\n",
        "\n",
        "# Add Month-Year\n",
        "df['TransactionDate'] = pd.to_datetime(df['TransactionDate'], format='%b-%y')\n",
        "df['Year'] = df['TransactionDate'].dt.year.astype(np.float32)\n",
        "df['Month-Year'] = df['TransactionDate'].dt.strftime('%Y-%m').astype(str)\n",
        "\n",
        "# Clean UnitLevel\n",
        "unit_level_map = {'03A': 4, '12B': 12, '13A': 14, '23A': 24, '33A': 34, '43A': 44, '53A': 54,\n",
        "                  'B': 0, 'D': 0, 'G': 0, 'LG': 0, 'MZ': 0, 'P': 0, 'UG': 0,\n",
        "                  '1/5/2025': 0, '2/3/2025': 0, '1/4/2025': 0}\n",
        "df['UnitLevel_clean'] = df['UnitLevel'].replace(unit_level_map)\n",
        "unit_level_mean = pd.to_numeric(df['UnitLevel_clean'], errors='coerce').mean()\n",
        "df['UnitLevel_clean'] = pd.to_numeric(df['UnitLevel_clean'], errors='coerce').fillna(unit_level_mean).astype(np.float32)\n",
        "df['UnitLevel_binned'] = pd.cut(df['UnitLevel_clean'], bins=[-float('inf'), 10, 20, float('inf')], labels=['Low', 'Mid', 'High'])\n",
        "level_dummies = pd.get_dummies(df['UnitLevel_binned'], prefix='UnitLevel', dtype=np.float32)\n",
        "\n",
        "# Setapak interactions\n",
        "mukim_dummies = pd.get_dummies(df['Mukim'], prefix='Mukim', dtype=np.float32)\n",
        "df['Mukim_Mukim Setapak_Tenure'] = (mukim_dummies.get('Mukim_Mukim Setapak', pd.Series(0, index=df.index)) * df['Tenure']).astype(np.float32)\n",
        "df['Mukim_Mukim Setapak_Parcel_sq_m'] = (mukim_dummies.get('Mukim_Mukim Setapak', pd.Series(0, index=df.index)) * df['Parcel_sq_m']).astype(np.float32)\n",
        "\n",
        "# Features\n",
        "features = ['Scheme_Name_encoded', 'Parcel_sq_m', 'Year', 'Mukim_Mukim Setapak_Tenure',\n",
        "            'Mukim_Mukim Setapak_Parcel_sq_m', 'UnitLevel_High']\n",
        "X = pd.concat([df[['Scheme_Name_encoded', 'Parcel_sq_m', 'Year']],\n",
        "               df[['Mukim_Mukim Setapak_Tenure', 'Mukim_Mukim Setapak_Parcel_sq_m']],\n",
        "               level_dummies[['UnitLevel_High']]], axis=1).astype(np.float32)\n",
        "y = df['TransactionPrice'].astype(np.float32)\n",
        "\n",
        "# Robust scaling\n",
        "scaler = RobustScaler()\n",
        "X[['Scheme_Name_encoded', 'Parcel_sq_m', 'Year']] = scaler.fit_transform(X[['Scheme_Name_encoded', 'Parcel_sq_m', 'Year']]).astype(np.float32)\n",
        "joblib.dump(scaler, 'scaler.joblib')\n",
        "\n",
        "# Sample weights\n",
        "weights = df['Mukim'].apply(lambda x: 5.0 if x in ['Mukim Setapak', 'Mukim Petaling'] else 1.0).astype(np.float32)\n",
        "\n",
        "# Debug: Check data shapes and dtypes\n",
        "print(\"X shape:\", X.shape, \"dtype:\", X.dtypes)\n",
        "print(\"y shape:\", y.shape, \"dtype:\", y.dtype)\n",
        "print(\"weights shape:\", weights.shape, \"dtype:\", weights.dtype)\n",
        "print(\"Unique Month-Year:\", sorted(df['Month-Year'].unique()))\n",
        "print(\"Sample X head:\\n\", X.head())\n",
        "print(\"Sample y head:\\n\", y.head())\n",
        "print(\"Sample weights head:\\n\", weights.head())\n",
        "print(\"TransactionPrice stats (log-scale):\", y.describe())\n",
        "print(\"TransactionPrice stats (RM):\", np.expm1(y).describe())\n",
        "print(\"Mukim counts:\", df['Mukim'].value_counts())\n",
        "print(\"Unique SchemeName count:\", df['SchemeName'].nunique())\n",
        "print(\"SchemeName-Month-Year combinations:\", len(df.groupby(['SchemeName', 'Month-Year'])))\n",
        "\n",
        "# Reshape data for RNN (sequences by SchemeName and Month-Year)\n",
        "timesteps = 3  # Fixed timesteps\n",
        "feature_count = X.shape[1]\n",
        "\n",
        "# Train-test split with validation\n",
        "X_temp, X_test, y_temp, y_test, w_temp, w_test = train_test_split(X, y, weights, test_size=0.2, random_state=42)\n",
        "X_train, X_val, y_train, y_val, w_train, w_val = train_test_split(X_temp, y_temp, w_temp, test_size=0.2, random_state=42)\n",
        "\n",
        "# Function to create per-SchemeName-Month-Year sequences\n",
        "def create_sequences(X, y, weights, timesteps, df_subset):\n",
        "    X_seq, y_seq, w_seq = [], [], []\n",
        "    # Group by SchemeName and Month-Year\n",
        "    groups = df_subset.groupby(['SchemeName', 'Month-Year'])\n",
        "    for (scheme, month_year), group_idx in groups.groups.items():\n",
        "        mask = X.index.isin(group_idx)\n",
        "        if mask.sum() > 0:  # Skip empty groups\n",
        "            X_group = X[mask][features].values\n",
        "            y_group = y[mask].values\n",
        "            w_group = weights[mask].values\n",
        "            # Aggregate up to timesteps samples (mean if multiple)\n",
        "            if len(X_group) > timesteps:\n",
        "                indices = np.random.choice(len(X_group), timesteps, replace=False)\n",
        "                X_group = X_group[indices]\n",
        "                y_group = y_group[indices]\n",
        "                w_group = w_group[indices]\n",
        "            elif len(X_group) < timesteps:\n",
        "                pad_len = timesteps - len(X_group)\n",
        "                X_group = np.pad(X_group, ((0, pad_len), (0, 0)), mode='constant', constant_values=0).astype(np.float32)\n",
        "                y_group = np.pad(y_group, (0, pad_len), mode='constant', constant_values=0).astype(np.float32)\n",
        "                w_group = np.pad(w_group, (0, pad_len), mode='constant', constant_values=0).astype(np.float32)\n",
        "            X_seq.append(X_group)\n",
        "            y_seq.append(y_group[-1])  # Predict last timestep's price\n",
        "            w_seq.append(w_group[-1])\n",
        "    X_seq = np.array(X_seq, dtype=np.float32)\n",
        "    y_seq = np.array(y_seq, dtype=np.float32)\n",
        "    w_seq = np.array(w_seq, dtype=np.float32)\n",
        "    if len(X_seq) == 0:\n",
        "        print(\"Warning: No sequences created. Using dummy sequence.\")\n",
        "        return np.zeros((1, timesteps, len(features)), dtype=np.float32), np.zeros(1, dtype=np.float32), np.zeros(1, dtype=np.float32)\n",
        "    print(f\"Created {len(X_seq)} sequences, X_seq shape: {X_seq.shape}, dtype: {X_seq.dtype}\")\n",
        "    print(f\"y_seq shape: {y_seq.shape}, dtype: {y_seq.dtype}\")\n",
        "    print(f\"w_seq shape: {w_seq.shape}, dtype: {w_seq.dtype}\")\n",
        "    print(\"Sample X_seq[0]:\\n\", X_seq[0])\n",
        "    print(\"Sample y_seq[0]:\", y_seq[0])\n",
        "    print(\"Sample w_seq[0]:\", w_seq[0])\n",
        "    return X_seq, y_seq, w_seq\n",
        "\n",
        "# Create sequences for train, validation, and test\n",
        "X_train_seq, y_train_seq, w_train_seq = create_sequences(X_train, y_train, w_train, timesteps, df.loc[X_train.index])\n",
        "X_val_seq, y_val_seq, w_val_seq = create_sequences(X_val, y_val, w_val, timesteps, df.loc[X_val.index])\n",
        "X_test_seq, y_test_seq, w_test_seq = create_sequences(X_test, y_test, w_test, timesteps, df.loc[X_test.index])\n",
        "\n",
        "# Define simplified RNN model\n",
        "def create_rnn_model(timesteps, feature_count):\n",
        "    model = Sequential([\n",
        "        Input(shape=(timesteps, feature_count)),  # Include Year\n",
        "        LSTM(8, return_sequences=False),  # Reduced units\n",
        "        Dense(32, activation='relu'),\n",
        "        Dropout(0.2),\n",
        "        Dense(16, activation='relu'),\n",
        "        Dropout(0.2),\n",
        "        Dense(1)\n",
        "    ])\n",
        "    optimizer = RMSprop(learning_rate=0.001)\n",
        "    model.compile(optimizer=optimizer, loss='mse')\n",
        "    return model\n",
        "\n",
        "# Train RNN\n",
        "rnn_model = create_rnn_model(timesteps, feature_count)\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=30, restore_best_weights=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10, min_lr=0.00001)\n",
        "rnn_model.fit(X_train_seq, y_train_seq, sample_weight=w_train_seq, epochs=200, batch_size=16,\n",
        "              validation_data=(X_val_seq, y_val_seq, w_val_seq), callbacks=[early_stopping, reduce_lr], verbose=0)\n",
        "rnn_model.save('rnn_model.keras')  # Native Keras format\n",
        "\n",
        "# Evaluate RNN\n",
        "y_pred_rnn = rnn_model.predict(X_test_seq, verbose=0).flatten()\n",
        "print(\"RNN R:\", r2_score(y_test_seq, y_pred_rnn))\n",
        "print(\"RNN RMSE (log-scale):\", np.sqrt(mean_squared_error(y_test_seq, y_pred_rnn)))\n",
        "print(\"RNN RMSE (RM):\", np.sqrt(mean_squared_error(np.expm1(y_test_seq), np.expm1(y_pred_rnn))))\n",
        "\n",
        "# Debug predictions\n",
        "print(\"Sample y_test_seq (log-scale):\", y_test_seq[:5])\n",
        "print(\"Sample y_pred_rnn (log-scale):\", y_pred_rnn[:5])\n",
        "print(\"Sample y_test_seq (RM):\", np.expm1(y_test_seq[:5]))\n",
        "print(\"Sample y_pred_rnn (RM):\", np.expm1(y_pred_rnn[:5]))\n",
        "print(\"Prediction stats (log-scale):\", pd.Series(y_pred_rnn).describe())\n",
        "print(\"Prediction stats (RM):\", pd.Series(np.expm1(y_pred_rnn)).describe())\n",
        "\n",
        "# Cross-validation\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "cv_rnn_scores = []\n",
        "\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train_fold, X_test_fold = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train_fold, y_test_fold = y.iloc[train_index], y.iloc[test_index]\n",
        "    weights_train_fold = weights.iloc[train_index].values.astype(np.float32)\n",
        "    weights_test_fold = weights.iloc[test_index].values.astype(np.float32)\n",
        "\n",
        "    X_train_seq_fold, y_train_seq_fold, w_train_seq_fold = create_sequences(X_train_fold, y_train_fold, weights_train_fold, timesteps, df.loc[train_index])\n",
        "    X_test_seq_fold, y_test_seq_fold, w_test_seq_fold = create_sequences(X_test_fold, y_test_fold, weights_test_fold, timesteps, df.loc[test_index])\n",
        "\n",
        "    fold_model = create_rnn_model(timesteps, feature_count)\n",
        "    fold_model.fit(X_train_seq_fold, y_train_seq_fold, sample_weight=w_train_seq_fold, epochs=200,\n",
        "                   batch_size=16, validation_data=(X_test_seq_fold, y_test_seq_fold, w_test_seq_fold),\n",
        "                   callbacks=[early_stopping, reduce_lr], verbose=0)\n",
        "    y_pred_fold = fold_model.predict(X_test_seq_fold, verbose=0).flatten()\n",
        "    cv_rnn_scores.append(r2_score(y_test_seq_fold, y_pred_fold))\n",
        "\n",
        "    # Suburban and price-tier performance for this fold\n",
        "    suburban_mask_fold = df.loc[test_index, 'Mukim'].isin(['Mukim Setapak', 'Mukim Petaling'])\n",
        "    low_price_mask_fold = np.expm1(y_test_fold) < 450000\n",
        "    very_low_price_mask_fold = np.expm1(y_test_fold) < 300000\n",
        "\n",
        "    if suburban_mask_fold.any():\n",
        "        print(f\"Fold Suburban RNN RMSE (RM):\", np.sqrt(mean_squared_error(np.expm1(y_test_fold[suburban_mask_fold]), np.expm1(y_pred_fold[suburban_mask_fold]))))\n",
        "    if low_price_mask_fold.any():\n",
        "        print(f\"Fold Low-Price (<450k RM) RNN RMSE (RM):\", np.sqrt(mean_squared_error(np.expm1(y_test_fold[low_price_mask_fold]), np.expm1(y_pred_fold[low_price_mask_fold]))))\n",
        "    if very_low_price_mask_fold.any():\n",
        "        print(f\"Fold Very Low-Price (<300k RM) RNN RMSE (RM):\", np.sqrt(mean_squared_error(np.expm1(y_test_fold[very_low_price_mask_fold]), np.expm1(y_pred_fold[very_low_price_mask_fold]))))\n",
        "\n",
        "print(\"RNN 5-Fold CV R:\", np.mean(cv_rnn_scores), \"\", np.std(cv_rnn_scores))\n",
        "\n",
        "# Overall suburban and price-tier performance\n",
        "suburban_mask = df.loc[X_test.index, 'Mukim'].isin(['Mukim Setapak', 'Mukim Petaling'])\n",
        "low_price_mask = np.expm1(y_test) < 450000\n",
        "very_low_price_mask = np.expm1(y_test) < 300000\n",
        "if suburban_mask.any():\n",
        "    print(\"Suburban RNN RMSE (RM):\", np.sqrt(mean_squared_error(np.expm1(y_test[suburban_mask]), np.expm1(y_pred_rnn[suburban_mask]))))\n",
        "if low_price_mask.any():\n",
        "    print(\"Low-Price (<450k RM) RNN RMSE (RM):\", np.sqrt(mean_squared_error(np.expm1(y_test[low_price_mask]), np.expm1(y_pred_rnn[low_price_mask]))))\n",
        "if very_low_price_mask.any():\n",
        "    print(\"Very Low-Price (<300k RM) RNN RMSE (RM):\", np.sqrt(mean_squared_error(np.expm1(y_test[very_low_price_mask]), np.expm1(y_pred_rnn[very_low_price_mask]))))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "51apHR_slEGW",
        "outputId": "54ecfa17-cfcc-455d-a488-7aba3a23809b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<>:16: SyntaxWarning: invalid escape sequence '\\d'\n",
            "<>:16: SyntaxWarning: invalid escape sequence '\\d'\n",
            "/tmp/ipython-input-1253832519.py:16: SyntaxWarning: invalid escape sequence '\\d'\n",
            "  df['Parcel_sq_m'] = df['ParcelArea'].astype(str).str.extract('(\\d+\\.?\\d*)').astype(np.float32)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X shape: (14136, 6) dtype: Scheme_Name_encoded                float32\n",
            "Parcel_sq_m                        float32\n",
            "Year                               float32\n",
            "Mukim_Mukim Setapak_Tenure         float32\n",
            "Mukim_Mukim Setapak_Parcel_sq_m    float32\n",
            "UnitLevel_High                     float32\n",
            "dtype: object\n",
            "y shape: (14136,) dtype: float32\n",
            "weights shape: (14136,) dtype: float32\n",
            "Unique Month-Year: ['2021-01', '2021-02', '2021-03', '2021-04', '2021-05', '2021-06', '2021-07', '2021-08', '2021-09', '2021-10', '2021-11', '2021-12', '2022-01', '2022-02', '2022-03', '2022-04', '2022-05', '2022-06', '2022-07', '2022-08', '2022-09', '2022-10', '2022-11', '2022-12', '2023-01', '2023-02', '2023-03', '2023-04', '2023-05', '2023-06', '2023-07', '2023-08', '2023-09', '2023-10', '2023-11', '2023-12', '2024-01', '2024-02', '2024-03', '2024-04', '2024-05', '2024-06', '2024-07', '2024-08', '2024-09', '2024-10', '2024-11', '2024-12', '2025-01', '2025-02', '2025-03', '2025-04', '2025-05', '2025-06']\n",
            "Sample X head:\n",
            "    Scheme_Name_encoded  Parcel_sq_m  Year  Mukim_Mukim Setapak_Tenure  \\\n",
            "0             0.686880     1.036049  -0.5                         0.0   \n",
            "1             0.843227     1.572720  -0.5                         0.0   \n",
            "2            -0.662822    -0.613629  -0.5                         0.0   \n",
            "3             1.167282     1.572720  -0.5                         0.0   \n",
            "4             0.207606    -0.613629  -0.5                         0.0   \n",
            "\n",
            "   Mukim_Mukim Setapak_Parcel_sq_m  UnitLevel_High  \n",
            "0                              0.0             0.0  \n",
            "1                              0.0             0.0  \n",
            "2                              0.0             0.0  \n",
            "3                              0.0             0.0  \n",
            "4                              0.0             0.0  \n",
            "Sample y head:\n",
            " 0    13.873780\n",
            "1    14.240779\n",
            "2    12.611541\n",
            "3    14.384228\n",
            "4    13.384729\n",
            "Name: TransactionPrice, dtype: float32\n",
            "Sample weights head:\n",
            " 0    1.0\n",
            "1    1.0\n",
            "2    1.0\n",
            "3    1.0\n",
            "4    1.0\n",
            "Name: Mukim, dtype: float32\n",
            "TransactionPrice stats (log-scale): count    14136.000000\n",
            "mean        13.344301\n",
            "std          0.611975\n",
            "min         10.308986\n",
            "25%         12.899222\n",
            "50%         13.235694\n",
            "75%         13.815512\n",
            "max         14.384228\n",
            "Name: TransactionPrice, dtype: float64\n",
            "TransactionPrice stats (RM): count    1.413600e+04\n",
            "mean     7.514681e+05\n",
            "std      4.744860e+05\n",
            "min      2.999999e+04\n",
            "25%      4.000000e+05\n",
            "50%      5.600001e+05\n",
            "75%      1.000000e+06\n",
            "max      1.765999e+06\n",
            "Name: TransactionPrice, dtype: float64\n",
            "Mukim counts: Mukim\n",
            "Mukim Batu                  3842\n",
            "Mukim Kuala Lumpur          2943\n",
            "Mukim Petaling              2856\n",
            "Mukim Setapak               2494\n",
            "Kuala Lumpur Town Centre    2001\n",
            "Name: count, dtype: int64\n",
            "Unique SchemeName count: 713\n",
            "SchemeName-Month-Year combinations: 8551\n",
            "Created 6247 sequences, X_seq shape: (6247, 3, 6), dtype: float32\n",
            "y_seq shape: (6247,), dtype: float32\n",
            "w_seq shape: (6247,), dtype: float32\n",
            "Sample X_seq[0]:\n",
            " [[ 0.9568454  1.5727204 -1.         0.         0.         0.       ]\n",
            " [ 0.         0.         0.         0.         0.         0.       ]\n",
            " [ 0.         0.         0.         0.         0.         0.       ]]\n",
            "Sample y_seq[0]: 0.0\n",
            "Sample w_seq[0]: 0.0\n",
            "Created 1997 sequences, X_seq shape: (1997, 3, 6), dtype: float32\n",
            "y_seq shape: (1997,), dtype: float32\n",
            "w_seq shape: (1997,), dtype: float32\n",
            "Sample X_seq[0]:\n",
            " [[0.9568454  0.90659165 0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.        ]]\n",
            "Sample y_seq[0]: 0.0\n",
            "Sample w_seq[0]: 0.0\n",
            "Created 2418 sequences, X_seq shape: (2418, 3, 6), dtype: float32\n",
            "y_seq shape: (2418,), dtype: float32\n",
            "w_seq shape: (2418,), dtype: float32\n",
            "Sample X_seq[0]:\n",
            " [[0.9568454 1.4228412 0.        0.        0.        0.       ]\n",
            " [0.        0.        0.        0.        0.        0.       ]\n",
            " [0.        0.        0.        0.        0.        0.       ]]\n",
            "Sample y_seq[0]: 0.0\n",
            "Sample w_seq[0]: 0.0\n",
            "RNN R: -33.142547607421875\n",
            "RNN RMSE (log-scale): 12.979743434445206\n",
            "RNN RMSE (RM): 539217.4069593822\n",
            "Sample y_test_seq (log-scale): [0. 0. 0. 0. 0.]\n",
            "Sample y_pred_rnn (log-scale): [13.337552 13.15416  12.965359 12.923217 12.949641]\n",
            "Sample y_test_seq (RM): [0. 0. 0. 0. 0.]\n",
            "Sample y_pred_rnn (RM): [620046.94 516152.53 427349.06 409713.88 420684.7 ]\n",
            "Prediction stats (log-scale): count    2418.000000\n",
            "mean       13.167365\n",
            "std         0.239118\n",
            "min        11.510109\n",
            "25%        12.996100\n",
            "50%        13.158945\n",
            "75%        13.326396\n",
            "max        14.411994\n",
            "dtype: float64\n",
            "Prediction stats (RM): count    2.418000e+03\n",
            "mean     5.385328e+05\n",
            "std      1.378435e+05\n",
            "min      9.971774e+04\n",
            "25%      4.406902e+05\n",
            "50%      5.186283e+05\n",
            "75%      6.131684e+05\n",
            "max      1.815722e+06\n",
            "dtype: float64\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'[72, 350, 441, 719, 774, 882, 951, 952, 953, 954, 1054, 1055, 1112, 1113, 1115, 1647, 1773, 1774, 1775, 1842, 2063, 2064, 2065, 2066, 2159, 2160, 2161, 2162, 2163, 2282, 2283, 2410, 2411, 2413, 2414, 2415, 3317, 3318, 3319, 3452, 3796, 3835, 3899, 4079, 4080, 4151, 4152, 4381, 4675, 4676, 4677, 4678, 4781, 4782, 4783, 4784, 4857, 4858, 4859, 5071, 5072, 5073, 5201, 5392, 5393, 5499, 5529, 5720, 6056, 6057, 6497, 6829, 7957, 7994, 8431, 8743, 8838, 8914, 9056, 9057, 9058, 9059, 9253, 9254, 9325, 9412, 9467, 9468, 9470, 9471, 9472, 9473, 9474, 9475, 9566, 9567, 9568, 10147, 10749, 10750, 10752, 10753, 10822, 10823, 10951, 11012, 11013, 11014, 11059, 11105, 11106, 11224, 11256, 11257, 11258, 11267, 11268, 11367, 11368, 11369, 11370, 11402, 11403, 11404, 11405, 11443, 11444, 11446, 11447, 11742, 11744, 11851, 11852, 11854, 11855, 11939, 11940, 11941, 11942, 11949, 12034, 12042, 12043, 12158, 12159, 12160, 12161, 12162, 12268, 12402, 12403, 12410, 12411, 12412, 12413, 12414, 12415, 12450, 12464, 12465, 12466, 12468, 12469, 12470, 12472, 12564, 12566, 12676, 12804, 12805, 12806, 12899, 12900, 12901, 12902, 12903, 12904, 12905, 13004, 13005, 13289, 13322, 13323, 13324, 13411, 13412, 13422, 13423, 13424, 13425, 13427, 13548, 13656, 13750, 13751, 13752, 13757, 13849, 13850, 13864, 13956, 13957, 13958, 14043, 14044, 14045] not in index'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1253832519.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0mweights_test_fold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m     \u001b[0mX_train_seq_fold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_seq_fold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_train_seq_fold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_fold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_fold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights_train_fold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimesteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m     \u001b[0mX_test_seq_fold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_seq_fold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_test_seq_fold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_fold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_fold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights_test_fold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimesteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1189\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_deprecated_callable_usage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaybe_callable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1191\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1418\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot index with multidimensional key\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1420\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_iterable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1422\u001b[0m             \u001b[0;31m# nested tuple slicing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_iterable\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1359\u001b[0m         \u001b[0;31m# A collection of keys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1360\u001b[0;31m         \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1361\u001b[0m         return self.obj._reindex_with_indexers(\n\u001b[1;32m   1362\u001b[0m             \u001b[0;34m{\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_dups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1556\u001b[0m         \u001b[0maxis_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1558\u001b[0;31m         \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_indexer_strict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1559\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1560\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6198\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6200\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_if_missing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6202\u001b[0m         \u001b[0mkeyarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6251\u001b[0m             \u001b[0mnot_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmissing_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6252\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{not_found} not in index\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6254\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0moverload\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: '[72, 350, 441, 719, 774, 882, 951, 952, 953, 954, 1054, 1055, 1112, 1113, 1115, 1647, 1773, 1774, 1775, 1842, 2063, 2064, 2065, 2066, 2159, 2160, 2161, 2162, 2163, 2282, 2283, 2410, 2411, 2413, 2414, 2415, 3317, 3318, 3319, 3452, 3796, 3835, 3899, 4079, 4080, 4151, 4152, 4381, 4675, 4676, 4677, 4678, 4781, 4782, 4783, 4784, 4857, 4858, 4859, 5071, 5072, 5073, 5201, 5392, 5393, 5499, 5529, 5720, 6056, 6057, 6497, 6829, 7957, 7994, 8431, 8743, 8838, 8914, 9056, 9057, 9058, 9059, 9253, 9254, 9325, 9412, 9467, 9468, 9470, 9471, 9472, 9473, 9474, 9475, 9566, 9567, 9568, 10147, 10749, 10750, 10752, 10753, 10822, 10823, 10951, 11012, 11013, 11014, 11059, 11105, 11106, 11224, 11256, 11257, 11258, 11267, 11268, 11367, 11368, 11369, 11370, 11402, 11403, 11404, 11405, 11443, 11444, 11446, 11447, 11742, 11744, 11851, 11852, 11854, 11855, 11939, 11940, 11941, 11942, 11949, 12034, 12042, 12043, 12158, 12159, 12160, 12161, 12162, 12268, 12402, 12403, 12410, 12411, 12412, 12413, 12414, 12415, 12450, 12464, 12465, 12466, 12468, 12469, 12470, 12472, 12564, 12566, 12676, 12804, 12805, 12806, 12899, 12900, 12901, 12902, 12903, 12904, 12905, 13004, 13005, 13289, 13322, 13323, 13324, 13411, 13412, 13422, 13423, 13424, 13425, 13427, 13548, 13656, 13750, 13751, 13752, 13757, 13849, 13850, 13864, 13956, 13957, 13958, 14043, 14044, 14045] not in index'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RNN (include Year)"
      ],
      "metadata": {
        "id": "k-oKOmcojnbR"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "625ebf27",
        "outputId": "5b6d1210-e505-42f4-d174-f35a4207a5cf"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from sklearn.metrics import r2_score, mean_squared_error\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Input, BatchNormalization, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "import joblib\n",
        "\n",
        "# Load and preprocess\n",
        "url = \"https://raw.githubusercontent.com/englian1123/KL-High-Rise-Data/refs/heads/main/KLHighRise.csv\"\n",
        "df = pd.read_csv(url)\n",
        "df.rename(columns={'TransactionPrice  ': 'TransactionPrice'}, inplace=True) # Corrected column name\n",
        "df['ParcelArea'] = df['ParcelArea'].astype(str).str.extract('(\\d+\\.?\\d*)').astype(np.float32)\n",
        "df['Tenure'] = df['Tenure'].map({'Freehold': 1, 'Leasehold': 0}).fillna(0).astype(np.float32)\n",
        "\n",
        "# Drop low-count Mukims\n",
        "low_count_mukims = ['Mukim Cheras', 'Mukim Ampang', 'Mukim Ulu Kelang']\n",
        "df = df[~df['Mukim'].isin(low_count_mukims)]\n",
        "df = df.reset_index(drop=True) # Reset index after dropping rows\n",
        "\n",
        "# Outlier capping (91st percentile)\n",
        "price_cap = df['TransactionPrice'].quantile(0.91)\n",
        "df['TransactionPrice'] = np.clip(df['TransactionPrice'], 0, price_cap).astype(np.float32)\n",
        "area_cap = df['ParcelArea'].quantile(0.91)\n",
        "df['ParcelArea'] = np.clip(df['ParcelArea'], 0, area_cap).astype(np.float32)\n",
        "\n",
        "# Log-transform\n",
        "df['TransactionPrice'] = np.log1p(df['TransactionPrice']).astype(np.float32)\n",
        "df['ParcelArea'] = np.log1p(df['ParcelArea']).astype(np.float32)\n",
        "\n",
        "# Target encode SchemeName\n",
        "scheme_encoding = df.groupby('SchemeName')['TransactionPrice'].mean().astype(np.float32)\n",
        "df['Scheme_Name_encoded'] = df['SchemeName'].map(scheme_encoding).fillna(scheme_encoding.mean()).astype(np.float32)\n",
        "joblib.dump(scheme_encoding, 'scheme_encoding.joblib')\n",
        "\n",
        "# Add Year\n",
        "df['Year'] = pd.to_datetime(df['TransactionDate'], format='%b-%y').dt.year\n",
        "df['Year'] = pd.to_numeric(df['Year'], errors='coerce').fillna(df['Year'].median()).astype(np.float32)\n",
        "\n",
        "# Clean UnitLevel\n",
        "unit_level_map = {'03A': 4, '12B': 12, '13A': 14, '23A': 24, '33A': 34, '43A': 44, '53A': 54,\n",
        "                  'B': 0, 'D': 0, 'G': 0, 'LG': 0, 'MZ': 0, 'P': 0, 'UG': 0,\n",
        "                  '1/5/2025': 0, '2/3/2025': 0, '1/4/2025': 0}\n",
        "df['UnitLevel_clean'] = df['UnitLevel'].replace(unit_level_map)\n",
        "unit_level_mean = pd.to_numeric(df['UnitLevel_clean'], errors='coerce').mean()\n",
        "df['UnitLevel_clean'] = pd.to_numeric(df['UnitLevel_clean'], errors='coerce').fillna(unit_level_mean).astype(np.float32)\n",
        "df['UnitLevel_binned'] = pd.cut(df['UnitLevel_clean'], bins=[-float('inf'), 10, 20, float('inf')], labels=['Low', 'Mid', 'High'])\n",
        "level_dummies = pd.get_dummies(df['UnitLevel_binned'], prefix='UnitLevel', dtype=np.float32)\n",
        "\n",
        "# Setapak interactions\n",
        "mukim_dummies = pd.get_dummies(df['Mukim'], prefix='Mukim', dtype=np.float32)\n",
        "df['Mukim_Mukim Setapak_Tenure'] = (mukim_dummies.get('Mukim_Mukim Setapak', pd.Series(0, index=df.index)) * df['Tenure']).astype(np.float32)\n",
        "df['Mukim_Mukim Setapak_ParcelArea'] = (mukim_dummies.get('Mukim_Mukim Setapak', pd.Series(0, index=df.index)) * df['ParcelArea']).astype(np.float32)\n",
        "\n",
        "# Features\n",
        "features = ['Scheme_Name_encoded', 'ParcelArea', 'Year', 'Mukim_Mukim Setapak_Tenure',\n",
        "            'Mukim_Mukim Setapak_ParcelArea', 'UnitLevel_High']\n",
        "X = pd.concat([df[['Scheme_Name_encoded', 'ParcelArea', 'Year']],\n",
        "               df[['Mukim_Mukim Setapak_Tenure', 'Mukim_Mukim Setapak_ParcelArea']],\n",
        "               level_dummies[['UnitLevel_High']]], axis=1).astype(np.float32)\n",
        "y = df['TransactionPrice'].astype(np.float32)\n",
        "\n",
        "# Robust scaling\n",
        "scaler = RobustScaler()\n",
        "X[['Scheme_Name_encoded', 'ParcelArea', 'Year']] = scaler.fit_transform(X[['Scheme_Name_encoded', 'ParcelArea', 'Year']]).astype(np.float32)\n",
        "joblib.dump(scaler, 'scaler.joblib')\n",
        "\n",
        "# Sample weights\n",
        "weights = df['Mukim'].apply(lambda x: 5.0 if x in ['Mukim Setapak', 'Mukim Petaling'] else 1.0).astype(np.float32)\n",
        "\n",
        "# Debug: Check data shapes and dtypes\n",
        "# print(\"X shape:\", X.shape, \"dtype:\", X.dtypes)\n",
        "# print(\"y shape:\", y.shape, \"dtype:\", y.dtype)\n",
        "# print(\"weights shape:\", weights.shape, \"dtype:\", weights.dtype)\n",
        "# print(\"Unique years:\", df['Year'].unique())\n",
        "# print(\"Sample X head:\\n\", X.head())\n",
        "# print(\"Sample y head:\\n\", y.head())\n",
        "# print(\"Sample weights head:\\n\", weights.head())\n",
        "# print(\"TransactionPrice stats (log-scale):\", y.describe())\n",
        "# print(\"Mukim counts:\", df['Mukim'].value_counts())\n",
        "\n",
        "# Reshape data for RNN (sequences per sample)\n",
        "timesteps = 5  # Fixed number of time steps\n",
        "feature_count = X.shape[1]\n",
        "\n",
        "# Train-test split with validation\n",
        "X_temp, X_test, y_temp, y_test, w_temp, w_test = train_test_split(X, y, weights, test_size=0.2, random_state=42)\n",
        "X_train, X_val, y_train, y_val, w_train, w_val = train_test_split(X_temp, y_temp, w_temp, test_size=0.2, random_state=42)\n",
        "\n",
        "# Function to create sequences per sample\n",
        "def create_sequences(X, y, weights, timesteps):\n",
        "    X_seq, y_seq, w_seq = [], [], []\n",
        "    # Ensure weights is a numpy array\n",
        "    weights = np.array(weights, dtype=np.float32)\n",
        "    for i in range(len(X)):\n",
        "        # Create a sequence with one real timestep and padding\n",
        "        X_sample = X.iloc[i].values.reshape(1, -1).astype(np.float32)\n",
        "        X_padded = np.pad(X_sample, ((0, timesteps-1), (0, 0)), mode='constant', constant_values=0).astype(np.float32)\n",
        "        X_seq.append(X_padded)\n",
        "        y_seq.append(y.iloc[i].astype(np.float32))\n",
        "        w_seq.append(weights[i].astype(np.float32))\n",
        "    X_seq = np.array(X_seq, dtype=np.float32)\n",
        "    y_seq = np.array(y_seq, dtype=np.float32)\n",
        "    w_seq = np.array(w_seq, dtype=np.float32)\n",
        "    # print(f\"Created {len(X_seq)} sequences, X_seq shape: {X_seq.shape}, dtype: {X_seq.dtype}\")\n",
        "    # print(f\"y_seq shape: {y_seq.shape}, dtype: {y_seq.dtype}\")\n",
        "    # print(f\"w_seq shape: {w_seq.shape}, dtype: {w_seq.dtype}\")\n",
        "    # print(\"Sample X_seq[0]:\\n\", X_seq[0])\n",
        "    # print(\"Sample y_seq[0]:\", y_seq[0])\n",
        "    # print(\"Sample w_seq[0]:\", w_seq[0])\n",
        "    return X_seq, y_seq, w_seq\n",
        "\n",
        "# Create sequences for train, validation, and test\n",
        "X_train_seq, y_train_seq, w_train_seq = create_sequences(X_train, y_train, w_train, timesteps)\n",
        "X_val_seq, y_val_seq, w_val_seq = create_sequences(X_val, y_val, w_val, timesteps)\n",
        "X_test_seq, y_test_seq, w_test_seq = create_sequences(X_test, y_test, w_test, timesteps)\n",
        "\n",
        "# Define RNN model\n",
        "def create_rnn_model(timesteps, feature_count):\n",
        "    model = Sequential([\n",
        "        Input(shape=(timesteps, feature_count)),\n",
        "        LSTM(32, return_sequences=False),\n",
        "        Dense(128, activation='relu'),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.3),\n",
        "        Dense(64, activation='relu'),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.3),\n",
        "        Dense(32, activation='relu'),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.3),\n",
        "        Dense(1)\n",
        "    ])\n",
        "    optimizer = RMSprop(learning_rate=0.001)\n",
        "    model.compile(optimizer=optimizer, loss='mse')\n",
        "    return model\n",
        "\n",
        "# Train RNN\n",
        "rnn_model = create_rnn_model(timesteps, feature_count)\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=30, restore_best_weights=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10, min_lr=0.00001)\n",
        "rnn_model.fit(X_train_seq, y_train_seq, sample_weight=w_train_seq, epochs=300, batch_size=32,\n",
        "              validation_data=(X_val_seq, y_val_seq, w_val_seq), callbacks=[early_stopping, reduce_lr], verbose=0)\n",
        "rnn_model.save('rnn_model.h5')\n",
        "\n",
        "# Evaluate RNN\n",
        "y_pred_rnn = rnn_model.predict(X_test_seq, verbose=0).flatten()\n",
        "print(\"RNN R:\", r2_score(y_test_seq, y_pred_rnn))\n",
        "print(\"RNN RMSE (log-scale):\", np.sqrt(mean_squared_error(y_test_seq, y_pred_rnn)))\n",
        "print(\"RNN RMSE (RM):\", np.sqrt(mean_squared_error(np.expm1(y_test_seq), np.expm1(y_pred_rnn))))\n",
        "\n",
        "# Debug predictions\n",
        "print(\"Sample y_test_seq (log-scale):\", y_test_seq[:5])\n",
        "print(\"Sample y_pred_rnn (log-scale):\", y_pred_rnn[:5])\n",
        "print(\"Sample y_test_seq (RM):\", np.expm1(y_test_seq[:5]))\n",
        "print(\"Sample y_pred_rnn (RM):\", np.expm1(y_pred_rnn[:5]))\n",
        "\n",
        "# Cross-validation\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "cv_rnn_scores = []\n",
        "\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train_fold, X_test_fold = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train_fold, y_test_fold = y.iloc[train_index], y.iloc[test_index]\n",
        "    weights_train_fold = weights.iloc[train_index].values.astype(np.float32)\n",
        "    weights_test_fold = weights.iloc[test_index].values.astype(np.float32)\n",
        "\n",
        "    X_train_seq_fold, y_train_seq_fold, w_train_seq_fold = create_sequences(X_train_fold, y_train_fold, weights_train_fold, timesteps)\n",
        "    X_test_seq_fold, y_test_seq_fold, w_test_seq_fold = create_sequences(X_test_fold, y_test_fold, weights_test_fold, timesteps)\n",
        "\n",
        "    fold_model = create_rnn_model(timesteps, feature_count)\n",
        "    fold_model.fit(X_train_seq_fold, y_train_seq_fold, sample_weight=w_train_seq_fold, epochs=300,\n",
        "                   batch_size=32, validation_data=(X_test_seq_fold, y_test_seq_fold, w_test_seq_fold),\n",
        "                   callbacks=[early_stopping, reduce_lr], verbose=0)\n",
        "    y_pred_fold = fold_model.predict(X_test_seq_fold, verbose=0).flatten()\n",
        "    cv_rnn_scores.append(r2_score(y_test_seq_fold, y_pred_fold))\n",
        "\n",
        "    # Suburban and price-tier performance for this fold\n",
        "    suburban_mask_fold = df.loc[test_index, 'Mukim'].isin(['Mukim Setapak', 'Mukim Petaling'])\n",
        "    low_price_mask_fold = np.expm1(y_test_fold) < 450000\n",
        "    very_low_price_mask_fold = np.expm1(y_test_fold) < 300000\n",
        "\n",
        "    if suburban_mask_fold.any():\n",
        "        print(f\"Fold Suburban RNN RMSE (RM):\", np.sqrt(mean_squared_error(np.expm1(y_test_fold[suburban_mask_fold]), np.expm1(y_pred_fold[suburban_mask_fold]))))\n",
        "    if low_price_mask_fold.any():\n",
        "        print(f\"Fold Low-Price (<450k RM) RNN RMSE (RM):\", np.sqrt(mean_squared_error(np.expm1(y_test_fold[low_price_mask_fold]), np.expm1(y_pred_fold[low_price_mask_fold]))))\n",
        "    if very_low_price_mask_fold.any(): # Corrected typo here\n",
        "        print(f\"Fold Very Low-Price (<300k RM) RNN RMSE (RM):\", np.sqrt(mean_squared_error(np.expm1(y_test_fold[very_low_price_mask_fold]), np.expm1(y_pred_fold[very_low_price_mask_fold]))))\n",
        "\n",
        "print(\"RNN 5-Fold CV R:\", np.mean(cv_rnn_scores), \"\", np.std(cv_rnn_scores))\n",
        "\n",
        "# Overall suburban and price-tier performance\n",
        "suburban_mask = df.loc[X_test.index, 'Mukim'].isin(['Mukim Setapak', 'Mukim Petaling'])\n",
        "low_price_mask = np.expm1(y_test) < 450000\n",
        "very_low_price_mask = np.expm1(y_test) < 300000\n",
        "if suburban_mask.any():\n",
        "    print(\"Suburban RNN RMSE (RM):\", np.sqrt(mean_squared_error(np.expm1(y_test[suburban_mask]), np.expm1(y_pred_rnn[suburban_mask]))))\n",
        "if low_price_mask.any():\n",
        "    print(\"Low-Price (<450k RM) RNN RMSE (RM):\", np.sqrt(mean_squared_error(np.expm1(y_test[low_price_mask]), np.expm1(y_pred_rnn[low_price_mask]))))\n",
        "if very_low_price_mask.any():\n",
        "    print(\"Very Low-Price (<300k RM) RNN RMSE (RM):\", np.sqrt(mean_squared_error(np.expm1(y_test[very_low_price_mask]), np.expm1(y_pred_rnn[very_low_price_mask]))))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<>:16: SyntaxWarning: invalid escape sequence '\\d'\n",
            "<>:16: SyntaxWarning: invalid escape sequence '\\d'\n",
            "/tmp/ipython-input-1318150330.py:16: SyntaxWarning: invalid escape sequence '\\d'\n",
            "  df['ParcelArea'] = df['ParcelArea'].astype(str).str.extract('(\\d+\\.?\\d*)').astype(np.float32)\n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RNN R: 0.899840235710144\n",
            "RNN RMSE (log-scale): 0.19553319859581617\n",
            "RNN RMSE (RM): 176543.9274968131\n",
            "Sample y_test_seq (log-scale): [13.997833 12.42922  13.334246 12.7159   12.834684]\n",
            "Sample y_pred_rnn (log-scale): [13.705787 12.19916  13.315365 12.661335 12.822603]\n",
            "Sample y_test_seq (RM): [1200000.4   250000.    618000.2   332999.88  375000.16]\n",
            "Sample y_pred_rnn (RM): [896080.56 198621.16 606441.25 315316.38 370496.97]\n",
            "Fold Suburban RNN RMSE (RM): 119594.68616957862\n",
            "Fold Low-Price (<450k RM) RNN RMSE (RM): 50534.80131552908\n",
            "Fold Very Low-Price (<300k RM) RNN RMSE (RM): 56287.3132419731\n",
            "Fold Suburban RNN RMSE (RM): 101065.24086945027\n",
            "Fold Low-Price (<450k RM) RNN RMSE (RM): 56096.40844118276\n",
            "Fold Very Low-Price (<300k RM) RNN RMSE (RM): 57502.528640052\n",
            "Fold Suburban RNN RMSE (RM): 103911.4552299216\n",
            "Fold Low-Price (<450k RM) RNN RMSE (RM): 56648.26606349042\n",
            "Fold Very Low-Price (<300k RM) RNN RMSE (RM): 72722.83206806512\n",
            "Fold Suburban RNN RMSE (RM): 116434.2019854991\n",
            "Fold Low-Price (<450k RM) RNN RMSE (RM): 58960.93133592786\n",
            "Fold Very Low-Price (<300k RM) RNN RMSE (RM): 61532.84443287178\n",
            "Fold Suburban RNN RMSE (RM): 120868.29963228572\n",
            "Fold Low-Price (<450k RM) RNN RMSE (RM): 50448.20805539083\n",
            "Fold Very Low-Price (<300k RM) RNN RMSE (RM): 59260.563615274536\n",
            "RNN 5-Fold CV R: 0.8985396265983582  0.013751057042463734\n",
            "Suburban RNN RMSE (RM): 105350.89163362596\n",
            "Low-Price (<450k RM) RNN RMSE (RM): 53612.66238492545\n",
            "Very Low-Price (<300k RM) RNN RMSE (RM): 45930.2566942533\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RNN (No Year)"
      ],
      "metadata": {
        "id": "NhaYKphoW7ix"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from sklearn.metrics import r2_score, mean_squared_error\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Input, BatchNormalization, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "import joblib\n",
        "\n",
        "# Load and preprocess\n",
        "url = \"https://raw.githubusercontent.com/englian1123/KL-High-Rise-Data/refs/heads/main/KLHighRise.csv\"\n",
        "df = pd.read_csv(url)\n",
        "df.rename(columns={'TransactionPrice  ': 'TransactionPrice'}, inplace=True) # Corrected column name\n",
        "df['ParcelArea'] = df['ParcelArea'].astype(str).str.extract('(\\d+\\.?\\d*)').astype(np.float32)\n",
        "df['Tenure'] = df['Tenure'].map({'Freehold': 1, 'Leasehold': 0}).fillna(0).astype(np.float32)\n",
        "\n",
        "# Drop low-count Mukims\n",
        "low_count_mukims = ['Mukim Cheras', 'Mukim Ampang', 'Mukim Ulu Kelang']\n",
        "df = df[~df['Mukim'].isin(low_count_mukims)]\n",
        "df = df.reset_index(drop=True) # Reset index after dropping rows\n",
        "\n",
        "# Outlier capping (91st percentile)\n",
        "price_cap = df['TransactionPrice'].quantile(0.91)\n",
        "df['TransactionPrice'] = np.clip(df['TransactionPrice'], 0, price_cap).astype(np.float32)\n",
        "area_cap = df['ParcelArea'].quantile(0.91)\n",
        "df['ParcelArea'] = np.clip(df['ParcelArea'], 0, area_cap).astype(np.float32)\n",
        "\n",
        "# Log-transform\n",
        "df['TransactionPrice'] = np.log1p(df['TransactionPrice']).astype(np.float32)\n",
        "df['ParcelArea'] = np.log1p(df['ParcelArea']).astype(np.float32)\n",
        "\n",
        "# Target encode SchemeName\n",
        "scheme_encoding = df.groupby('SchemeName')['TransactionPrice'].mean().astype(np.float32)\n",
        "df['Scheme_Name_encoded'] = df['SchemeName'].map(scheme_encoding).fillna(scheme_encoding.mean()).astype(np.float32)\n",
        "joblib.dump(scheme_encoding, 'scheme_encoding.joblib')\n",
        "\n",
        "# Add Year\n",
        "df['Year'] = pd.to_datetime(df['TransactionDate'], format='%b-%y').dt.year\n",
        "df['Year'] = pd.to_numeric(df['Year'], errors='coerce').fillna(df['Year'].median()).astype(np.float32)\n",
        "\n",
        "# Clean UnitLevel\n",
        "unit_level_map = {'03A': 4, '12B': 12, '13A': 14, '23A': 24, '33A': 34, '43A': 44, '53A': 54,\n",
        "                  'B': 0, 'D': 0, 'G': 0, 'LG': 0, 'MZ': 0, 'P': 0, 'UG': 0,\n",
        "                  '1/5/2025': 0, '2/3/2025': 0, '1/4/2025': 0}\n",
        "df['UnitLevel_clean'] = df['UnitLevel'].replace(unit_level_map)\n",
        "unit_level_mean = pd.to_numeric(df['UnitLevel_clean'], errors='coerce').mean()\n",
        "df['UnitLevel_clean'] = pd.to_numeric(df['UnitLevel_clean'], errors='coerce').fillna(unit_level_mean).astype(np.float32)\n",
        "df['UnitLevel_binned'] = pd.cut(df['UnitLevel_clean'], bins=[-float('inf'), 10, 20, float('inf')], labels=['Low', 'Mid', 'High'])\n",
        "level_dummies = pd.get_dummies(df['UnitLevel_binned'], prefix='UnitLevel', dtype=np.float32)\n",
        "\n",
        "# Setapak interactions\n",
        "mukim_dummies = pd.get_dummies(df['Mukim'], prefix='Mukim', dtype=np.float32)\n",
        "df['Mukim_Mukim Setapak_Tenure'] = (mukim_dummies.get('Mukim_Mukim Setapak', pd.Series(0, index=df.index)) * df['Tenure']).astype(np.float32)\n",
        "df['Mukim_Mukim Setapak_ParcelArea'] = (mukim_dummies.get('Mukim_Mukim Setapak', pd.Series(0, index=df.index)) * df['ParcelArea']).astype(np.float32)\n",
        "\n",
        "# Features\n",
        "features = ['Scheme_Name_encoded', 'ParcelArea', 'Year', 'Mukim_Mukim Setapak_Tenure',\n",
        "            'Mukim_Mukim Setapak_ParcelArea', 'UnitLevel_High']\n",
        "X = pd.concat([df[['Scheme_Name_encoded', 'ParcelArea', 'Year']],\n",
        "               df[['Mukim_Mukim Setapak_Tenure', 'Mukim_Mukim Setapak_ParcelArea']],\n",
        "               level_dummies[['UnitLevel_High']]], axis=1).astype(np.float32)\n",
        "y = df['TransactionPrice'].astype(np.float32)\n",
        "\n",
        "# Robust scaling\n",
        "scaler = RobustScaler()\n",
        "X[['Scheme_Name_encoded', 'ParcelArea', 'Year']] = scaler.fit_transform(X[['Scheme_Name_encoded', 'ParcelArea', 'Year']]).astype(np.float32)\n",
        "joblib.dump(scaler, 'scaler.joblib')\n",
        "\n",
        "# Sample weights\n",
        "weights = df['Mukim'].apply(lambda x: 5.0 if x in ['Mukim Setapak', 'Mukim Petaling'] else 1.0).astype(np.float32)\n",
        "\n",
        "# Debug: Check data shapes and dtypes\n",
        "# print(\"X shape:\", X.shape, \"dtype:\", X.dtypes)\n",
        "# print(\"y shape:\", y.shape, \"dtype:\", y.dtype)\n",
        "# print(\"weights shape:\", weights.shape, \"dtype:\", weights.dtype)\n",
        "# print(\"Unique years:\", df['Year'].unique())\n",
        "# print(\"Sample X head:\\n\", X.head())\n",
        "# print(\"Sample y head:\\n\", y.head())\n",
        "# print(\"Sample weights head:\\n\", weights.head())\n",
        "# print(\"TransactionPrice stats (log-scale):\", y.describe())\n",
        "# print(\"Mukim counts:\", df['Mukim'].value_counts())\n",
        "\n",
        "# Reshape data for RNN (sequences per sample)\n",
        "timesteps = 5  # Fixed number of time steps\n",
        "feature_count = X.shape[1] -1 # Exclude Year\n",
        "\n",
        "# Train-test split with validation\n",
        "X_temp, X_test, y_temp, y_test, w_temp, w_test = train_test_split(X, y, weights, test_size=0.2, random_state=42)\n",
        "X_train, X_val, y_train, y_val, w_train, w_val = train_test_split(X_temp, y_temp, w_temp, test_size=0.2, random_state=42)\n",
        "\n",
        "# Function to create sequences per sample\n",
        "def create_sequences(X, y, weights, timesteps):\n",
        "    X_seq, y_seq, w_seq = [], [], []\n",
        "    X_no_year = X.drop('Year', axis=1, errors='ignore') # Drop Year here\n",
        "    if len(X_no_year) == 0: # Check if DataFrame is empty\n",
        "        return np.array([], dtype=np.float32).reshape(0, timesteps, X_no_year.shape[-1]), np.array([], dtype=np.float32), np.array([], dtype=np.float32)\n",
        "    # Ensure weights is a numpy array\n",
        "    weights = np.array(weights, dtype=np.float32)\n",
        "    for i in range(len(X_no_year)):\n",
        "        # Create a sequence with one real timestep and padding\n",
        "        X_sample = X_no_year.iloc[i].values.reshape(1, -1).astype(np.float32)\n",
        "        X_padded = np.pad(X_sample, ((0, timesteps-1), (0, 0)), mode='constant', constant_values=0).astype(np.float32)\n",
        "        X_seq.append(X_padded)\n",
        "        y_seq.append(y.iloc[i].astype(np.float32))\n",
        "        w_seq.append(weights[i].astype(np.float32))\n",
        "    X_seq = np.array(X_seq, dtype=np.float32)\n",
        "    y_seq = np.array(y_seq, dtype=np.float32)\n",
        "    w_seq = np.array(w_seq, dtype=np.float32)\n",
        "    # print(f\"Created {len(X_seq)} sequences, X_seq shape: {X_seq.shape}, dtype: {X_seq.dtype}\")\n",
        "    # print(f\"y_seq shape: {y_seq.shape}, dtype: {y_seq.dtype}\")\n",
        "    # print(f\"w_seq shape: {w_seq.shape}, dtype: {w_seq.dtype}\")\n",
        "    # print(\"Sample X_seq[0]:\\n\", X_seq[0])\n",
        "    # print(\"Sample y_seq[0]:\", y_seq[0])\n",
        "    # print(\"Sample w_seq[0]:\", w_seq[0])\n",
        "    return X_seq, y_seq, w_seq\n",
        "\n",
        "# Create sequences for train, validation, and test\n",
        "X_train_seq, y_train_seq, w_train_seq = create_sequences(X_train, y_train, w_train, timesteps)\n",
        "X_val_seq, y_val_seq, w_val_seq = create_sequences(X_val, y_val, w_val, timesteps)\n",
        "X_test_seq, y_test_seq, w_test_seq = create_sequences(X_test, y_test, w_test, timesteps)\n",
        "\n",
        "# Define RNN model\n",
        "def create_rnn_model(timesteps, feature_count):\n",
        "    model = Sequential([\n",
        "        Input(shape=(timesteps, feature_count)),\n",
        "        LSTM(32, return_sequences=False),\n",
        "        Dense(128, activation='relu'),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.3),\n",
        "        Dense(64, activation='relu'),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.3),\n",
        "        Dense(32, activation='relu'),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.3),\n",
        "        Dense(1)\n",
        "    ])\n",
        "    optimizer = RMSprop(learning_rate=0.001)\n",
        "    model.compile(optimizer=optimizer, loss='mse')\n",
        "    return model\n",
        "\n",
        "# Train RNN\n",
        "rnn_model = create_rnn_model(timesteps, feature_count)\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=30, restore_best_weights=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10, min_lr=0.00001)\n",
        "rnn_model.fit(X_train_seq, y_train_seq, sample_weight=w_train_seq, epochs=300, batch_size=32,\n",
        "              validation_data=(X_val_seq, y_val_seq, w_val_seq), callbacks=[early_stopping, reduce_lr], verbose=0)\n",
        "rnn_model.save('rnn_model.h5')\n",
        "\n",
        "# Evaluate RNN\n",
        "y_pred_rnn = rnn_model.predict(X_test_seq, verbose=0).flatten()\n",
        "print(\"RNN R:\", r2_score(y_test_seq, y_pred_rnn))\n",
        "print(\"RNN RMSE (log-scale):\", np.sqrt(mean_squared_error(y_test_seq, y_pred_rnn)))\n",
        "print(\"RNN RMSE (RM):\", np.sqrt(mean_squared_error(np.expm1(y_test_seq), np.expm1(y_pred_rnn))))\n",
        "\n",
        "# Debug predictions\n",
        "print(\"Sample y_test_seq (log-scale):\", y_test_seq[:5])\n",
        "print(\"Sample y_pred_rnn (log-scale):\", y_pred_rnn[:5])\n",
        "print(\"Sample y_test_seq (RM):\", np.expm1(y_test_seq[:5]))\n",
        "print(\"Sample y_pred_rnn (RM):\", np.expm1(y_pred_rnn[:5]))\n",
        "\n",
        "# Cross-validation\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "cv_rnn_scores = []\n",
        "\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train_fold, X_test_fold = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train_fold, y_test_fold = y.iloc[train_index], y.iloc[test_index]\n",
        "    weights_train_fold = weights.iloc[train_index].values.astype(np.float32)\n",
        "    weights_test_fold = weights.iloc[test_index].values.astype(np.float32)\n",
        "\n",
        "    X_train_seq_fold, y_train_seq_fold, w_train_seq_fold = create_sequences(X_train_fold, y_train_fold, weights_train_fold, timesteps)\n",
        "    X_test_seq_fold, y_test_seq_fold, w_test_seq_fold = create_sequences(X_test_fold, y_test_fold, weights_test_fold, timesteps)\n",
        "\n",
        "    fold_model = create_rnn_model(timesteps, feature_count)\n",
        "    fold_model.fit(X_train_seq_fold, y_train_seq_fold, sample_weight=w_train_seq_fold, epochs=300,\n",
        "                   batch_size=32, validation_data=(X_test_seq_fold, y_test_seq_fold, w_test_seq_fold),\n",
        "                   callbacks=[early_stopping, reduce_lr], verbose=0)\n",
        "    y_pred_fold = fold_model.predict(X_test_seq_fold, verbose=0).flatten()\n",
        "    cv_rnn_scores.append(r2_score(y_test_seq_fold, y_pred_fold))\n",
        "\n",
        "    # Suburban and price-tier performance for this fold\n",
        "    suburban_mask_fold = df.loc[test_index, 'Mukim'].isin(['Mukim Setapak', 'Mukim Petaling'])\n",
        "    low_price_mask_fold = np.expm1(y_test_fold) < 450000\n",
        "    very_low_price_mask_fold = np.expm1(y_test_fold) < 300000\n",
        "\n",
        "    if suburban_mask_fold.any():\n",
        "        print(f\"Fold Suburban RNN RMSE (RM):\", np.sqrt(mean_squared_error(np.expm1(y_test_fold[suburban_mask_fold]), np.expm1(y_pred_fold[suburban_mask_fold]))))\n",
        "    if low_price_mask_fold.any():\n",
        "        print(f\"Fold Low-Price (<450k RM) RNN RMSE (RM):\", np.sqrt(mean_squared_error(np.expm1(y_test_fold[low_price_mask_fold]), np.expm1(y_pred_fold[low_price_mask_fold]))))\n",
        "    if very_low_price_mask_fold.any():\n",
        "        print(f\"Fold Very Low-Price (<300k RM) RNN RMSE (RM):\", np.sqrt(mean_squared_error(np.expm1(y_test_fold[very_low_price_mask_fold]), np.expm1(y_pred_fold[very_low_price_mask_fold]))))\n",
        "\n",
        "print(\"RNN 5-Fold CV R:\", np.mean(cv_rnn_scores), \"\", np.std(cv_rnn_scores))"
      ],
      "metadata": {
        "id": "bA1bABZ8WIJa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RNN with Month-Year"
      ],
      "metadata": {
        "id": "j7iMFbA8gq-p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from sklearn.metrics import r2_score, mean_squared_error\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Input, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "import joblib\n",
        "\n",
        "# Load and preprocess\n",
        "url = \"https://raw.githubusercontent.com/englian1123/KL-High-Rise-Data/refs/heads/main/KLHighRise.csv\"\n",
        "df = pd.read_csv(url)\n",
        "df.rename(columns={'TransactionPrice  ': 'TransactionPrice', 'Parcel Area': 'ParcelArea', 'Scheme Name/Area': 'SchemeName'}, inplace=True)\n",
        "df['ParcelArea'] = df['ParcelArea'].astype(str).str.extract('(\\d+\\.?\\d*)').astype(np.float32)\n",
        "df['Tenure'] = df['Tenure'].map({'Freehold': 1, 'Leasehold': 0}).fillna(0).astype(np.float32)\n",
        "\n",
        "# Drop low-count Mukims and reset index\n",
        "low_count_mukims = ['Mukim Cheras', 'Mukim Ampang', 'Mukim Ulu Kelang']\n",
        "df = df[~df['Mukim'].isin(low_count_mukims)].reset_index(drop=True)\n",
        "\n",
        "# Outlier capping (90th percentile)\n",
        "price_cap = df['TransactionPrice'].quantile(0.90)\n",
        "df['TransactionPrice'] = np.clip(df['TransactionPrice'], 0, price_cap).astype(np.float32)\n",
        "area_cap = df['ParcelArea'].quantile(0.90)\n",
        "df['ParcelArea'] = np.clip(df['ParcelArea'], 0, area_cap).astype(np.float32)\n",
        "\n",
        "# Log-transform\n",
        "df['TransactionPrice'] = np.log1p(df['TransactionPrice']).astype(np.float32)\n",
        "df['ParcelArea'] = np.log1p(df['ParcelArea']).astype(np.float32)\n",
        "\n",
        "# Target encode SchemeName\n",
        "scheme_encoding = df.groupby('SchemeName')['TransactionPrice'].mean().astype(np.float32)\n",
        "df['Scheme_Name_encoded'] = df['SchemeName'].map(scheme_encoding).fillna(scheme_encoding.mean()).astype(np.float32)\n",
        "joblib.dump(scheme_encoding, 'scheme_encoding.joblib')\n",
        "\n",
        "# Add Month-Year\n",
        "df['TransactionDate'] = pd.to_datetime(df['TransactionDate'], format='%b-%y')\n",
        "df['Year'] = df['TransactionDate'].dt.year.astype(np.float32)\n",
        "df['Month-Year'] = df['TransactionDate'].dt.strftime('%Y-%m').astype(str)\n",
        "\n",
        "# Clean UnitLevel\n",
        "unit_level_map = {'03A': 4, '12B': 12, '13A': 14, '23A': 24, '33A': 34, '43A': 44, '53A': 54,\n",
        "                  'B': 0, 'D': 0, 'G': 0, 'LG': 0, 'MZ': 0, 'P': 0, 'UG': 0,\n",
        "                  '1/5/2025': 0, '2/3/2025': 0, '1/4/2025': 0}\n",
        "df['UnitLevel_clean'] = df['UnitLevel'].replace(unit_level_map)\n",
        "unit_level_mean = pd.to_numeric(df['UnitLevel_clean'], errors='coerce').mean()\n",
        "df['UnitLevel_clean'] = pd.to_numeric(df['UnitLevel_clean'], errors='coerce').fillna(unit_level_mean).astype(np.float32)\n",
        "df['UnitLevel_binned'] = pd.cut(df['UnitLevel_clean'], bins=[-float('inf'), 10, 20, float('inf')], labels=['Low', 'Mid', 'High'])\n",
        "level_dummies = pd.get_dummies(df['UnitLevel_binned'], prefix='UnitLevel', dtype=np.float32)\n",
        "\n",
        "# Setapak interactions\n",
        "mukim_dummies = pd.get_dummies(df['Mukim'], prefix='Mukim', dtype=np.float32)\n",
        "df['Mukim_Mukim Setapak_Tenure'] = (mukim_dummies.get('Mukim_Mukim Setapak', pd.Series(0, index=df.index)) * df['Tenure']).astype(np.float32)\n",
        "df['Mukim_Mukim Setapak_ParcelArea'] = (mukim_dummies.get('Mukim_Mukim Setapak', pd.Series(0, index=df.index)) * df['ParcelArea']).astype(np.float32)\n",
        "\n",
        "# Features\n",
        "features = ['Scheme_Name_encoded', 'ParcelArea', 'Year', 'Mukim_Mukim Setapak_Tenure',\n",
        "            'Mukim_Mukim Setapak_ParcelArea', 'UnitLevel_High']\n",
        "X = pd.concat([df[['Scheme_Name_encoded', 'ParcelArea', 'Year']],\n",
        "               df[['Mukim_Mukim Setapak_Tenure', 'Mukim_Mukim Setapak_ParcelArea']],\n",
        "               level_dummies[['UnitLevel_High']]], axis=1).astype(np.float32)\n",
        "y = df['TransactionPrice'].astype(np.float32)\n",
        "\n",
        "# Robust scaling\n",
        "scaler = RobustScaler()\n",
        "X[['Scheme_Name_encoded', 'ParcelArea', 'Year']] = scaler.fit_transform(X[['Scheme_Name_encoded', 'ParcelArea', 'Year']]).astype(np.float32)\n",
        "joblib.dump(scaler, 'scaler.joblib')\n",
        "\n",
        "# Sample weights\n",
        "weights = df['Mukim'].apply(lambda x: 5.0 if x in ['Mukim Setapak', 'Mukim Petaling'] else 1.0).astype(np.float32)\n",
        "\n",
        "# Debug: Check data shapes and dtypes\n",
        "print(\"X shape:\", X.shape, \"dtype:\", X.dtypes)\n",
        "print(\"y shape:\", y.shape, \"dtype:\", y.dtype)\n",
        "print(\"weights shape:\", weights.shape, \"dtype:\", weights.dtype)\n",
        "print(\"df shape:\", df.shape)\n",
        "print(\"Unique Month-Year:\", sorted(df['Month-Year'].unique()))\n",
        "print(\"Sample X head:\\n\", X.head())\n",
        "print(\"Sample y head:\\n\", y.head())\n",
        "print(\"Sample weights head:\\n\", weights.head())\n",
        "print(\"TransactionPrice stats (log-scale):\", y.describe())\n",
        "print(\"TransactionPrice stats (RM):\", np.expm1(y).describe())\n",
        "print(\"Mukim counts:\", df['Mukim'].value_counts())\n",
        "print(\"Unique SchemeName count:\", df['SchemeName'].nunique())\n",
        "print(\"SchemeName-Month-Year combinations:\", len(df.groupby(['SchemeName', 'Month-Year'])))\n",
        "\n",
        "# Reshape data for RNN (sequences by SchemeName and Month-Year)\n",
        "timesteps = 3  # Fixed timesteps\n",
        "feature_count = X.shape[1]  # Include Year\n",
        "\n",
        "# Train-test split with validation\n",
        "X_temp, X_test, y_temp, y_test, w_temp, w_test = train_test_split(X, y, weights, test_size=0.2, random_state=42)\n",
        "X_train, X_val, y_train, y_val, w_train, w_val = train_test_split(X_temp, y_temp, w_temp, test_size=0.2, random_state=42)\n",
        "\n",
        "# Function to create per-SchemeName-Month-Year sequences\n",
        "def create_sequences(X, y, weights, timesteps, df_full):\n",
        "    X_seq, y_seq, w_seq, mukim_seq = [], [], [], []\n",
        "    # Group by SchemeName and Month-Year on the full DataFrame\n",
        "    groups = df_full.groupby(['SchemeName', 'Month-Year'])\n",
        "    for (scheme, month_year), group_idx in groups.groups.items():\n",
        "        # Filter group indices to only include those present in the current X subset\n",
        "        valid_group_idx = group_idx.intersection(X.index)\n",
        "        if len(valid_group_idx) > 0:\n",
        "            X_group = X.loc[valid_group_idx, features].values\n",
        "            y_group = y.loc[valid_group_idx].values\n",
        "            w_group = weights.loc[valid_group_idx].values\n",
        "            mukim_group = df_full.loc[valid_group_idx, 'Mukim'].values\n",
        "            # Aggregate up to timesteps samples (mean if multiple)\n",
        "            if len(X_group) > timesteps:\n",
        "                indices = np.random.choice(len(X_group), timesteps, replace=False)\n",
        "                X_group = X_group[indices]\n",
        "                y_group = y_group[indices]\n",
        "                w_group = w_group[indices]\n",
        "                mukim_group = mukim_group[indices]\n",
        "            elif len(X_group) < timesteps:\n",
        "                pad_len = timesteps - len(X_group)\n",
        "                X_group = np.pad(X_group, ((0, pad_len), (0, 0)), mode='constant', constant_values=0).astype(np.float32)\n",
        "                y_group = np.pad(y_group, (0, pad_len), mode='constant', constant_values=0).astype(np.float32)\n",
        "                w_group = np.pad(w_group, (0, pad_len), mode='constant', constant_values=0).astype(np.float32)\n",
        "                mukim_group = np.pad(mukim_group, (0, pad_len), mode='constant', constant_values='').astype(str) # Pad with empty string\n",
        "            X_seq.append(X_group)\n",
        "            y_seq.append(y_group[-1])  # Predict last timestep's price\n",
        "            w_seq.append(w_group[-1])\n",
        "            mukim_seq.append(mukim_group[-1]) # Get Mukim for the last timestep\n",
        "    X_seq = np.array(X_seq, dtype=np.float32)\n",
        "    y_seq = np.array(y_seq, dtype=np.float32)\n",
        "    w_seq = np.array(w_seq, dtype=np.float32)\n",
        "    mukim_seq = np.array(mukim_seq, dtype=object) # Keep Mukim as object/string array\n",
        "    if len(X_seq) == 0:\n",
        "        print(\"Warning: No sequences created. Using dummy sequence.\")\n",
        "        return np.zeros((1, timesteps, len(features)), dtype=np.float32), np.zeros(1, dtype=np.float32), np.zeros(1, dtype=np.float32), np.array([''], dtype=object)\n",
        "    print(f\"Created {len(X_seq)} sequences, X_seq shape: {X_seq.shape}, dtype: {X_seq.dtype}\")\n",
        "    print(f\"y_seq shape: {y_seq.shape}, dtype: {y_seq.dtype}\")\n",
        "    print(f\"w_seq shape: {w_seq.shape}, dtype: {w_seq.dtype}\")\n",
        "    print(f\"mukim_seq shape: {mukim_seq.shape}, dtype: {mukim_seq.dtype}\")\n",
        "    print(\"Sample X_seq[0]:\\n\", X_seq[0])\n",
        "    print(\"Sample y_seq[0]:\", y_seq[0])\n",
        "    print(\"Sample w_seq[0]:\", w_seq[0])\n",
        "    print(\"Sample mukim_seq[0]:\", mukim_seq[0])\n",
        "    return X_seq, y_seq, w_seq, mukim_seq\n",
        "\n",
        "# Create sequences for train, validation, and test\n",
        "X_train_seq, y_train_seq, w_train_seq, mukim_train_seq = create_sequences(X_train, y_train, w_train, timesteps, df)\n",
        "X_val_seq, y_val_seq, w_val_seq, mukim_val_seq = create_sequences(X_val, y_val, w_val, timesteps, df)\n",
        "X_test_seq, y_test_seq, w_test_seq, mukim_test_seq = create_sequences(X_test, y_test, w_test, timesteps, df)\n",
        "\n",
        "# Define simplified RNN model\n",
        "def create_rnn_model(timesteps, feature_count):\n",
        "    model = Sequential([\n",
        "        Input(shape=(timesteps, feature_count)),  # Include Year\n",
        "        LSTM(8, return_sequences=False),  # Reduced units\n",
        "        Dense(32, activation='relu'),\n",
        "        Dropout(0.2),\n",
        "        Dense(16, activation='relu'),\n",
        "        Dropout(0.2),\n",
        "        Dense(1)\n",
        "    ])\n",
        "    optimizer = RMSprop(learning_rate=0.001)\n",
        "    model.compile(optimizer=optimizer, loss='mse')\n",
        "    return model\n",
        "\n",
        "# Train RNN\n",
        "rnn_model = create_rnn_model(timesteps, feature_count)\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=30, restore_best_weights=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10, min_lr=0.00001)\n",
        "rnn_model.fit(X_train_seq, y_train_seq, sample_weight=w_train_seq, epochs=200, batch_size=16,\n",
        "              validation_data=(X_val_seq, y_val_seq, w_val_seq), callbacks=[early_stopping, reduce_lr], verbose=0)\n",
        "rnn_model.save('rnn_model.keras')  # Native Keras format\n",
        "\n",
        "# Evaluate RNN\n",
        "y_pred_rnn = rnn_model.predict(X_test_seq, verbose=0).flatten()\n",
        "print(\"RNN R:\", r2_score(y_test_seq, y_pred_rnn))\n",
        "print(\"RNN RMSE (log-scale):\", np.sqrt(mean_squared_error(y_test_seq, y_pred_rnn)))\n",
        "print(\"RNN RMSE (RM):\", np.sqrt(mean_squared_error(np.expm1(y_test_seq), np.expm1(y_pred_rnn))))\n",
        "\n",
        "# Debug predictions\n",
        "print(\"Sample y_test_seq (log-scale):\", y_test_seq[:5])\n",
        "print(\"Sample y_pred_rnn (log-scale):\", y_pred_rnn[:5])\n",
        "print(\"Sample y_test_seq (RM):\", np.expm1(y_test_seq[:5]))\n",
        "print(\"Sample y_pred_rnn (RM):\", np.expm1(y_pred_rnn[:5]))\n",
        "print(\"Prediction stats (log-scale):\", pd.Series(y_pred_rnn).describe())\n",
        "print(\"Prediction stats (RM):\", pd.Series(np.expm1(y_pred_rnn)).describe())\n",
        "\n",
        "# Cross-validation\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "cv_rnn_scores = []\n",
        "\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train_fold, X_test_fold = X.loc[train_index], X.loc[test_index]\n",
        "    y_train_fold, y_test_fold = y.loc[train_index], y.loc[test_index]\n",
        "    weights_train_fold = weights.loc[train_index]\n",
        "    weights_test_fold = weights.loc[test_index]\n",
        "\n",
        "    # Filter df for the current fold's indices - use df.loc for correct indexing\n",
        "    df_train_fold = df.loc[df.index.intersection(train_index)]\n",
        "    df_test_fold = df.loc[df.index.intersection(test_index)]\n",
        "\n",
        "\n",
        "    X_train_seq_fold, y_train_seq_fold, w_train_seq_fold, mukim_train_seq_fold = create_sequences(X_train_fold, y_train_fold, weights_train_fold, timesteps, df_train_fold)\n",
        "    X_test_seq_fold, y_test_seq_fold, w_test_seq_fold, mukim_test_seq_fold = create_sequences(X_test_fold, y_test_fold, weights_test_fold, timesteps, df_test_fold)\n",
        "\n",
        "    # Skip the fold if no sequences were created\n",
        "    if len(X_train_seq_fold) == 0 or len(X_test_seq_fold) == 0:\n",
        "        print(\"Skipping fold due to no sequences.\")\n",
        "        continue\n",
        "\n",
        "    fold_model = create_rnn_model(timesteps, feature_count)\n",
        "    fold_model.fit(X_train_seq_fold, y_train_seq_fold, sample_weight=w_train_seq_fold, epochs=200,\n",
        "                   batch_size=16, validation_data=(X_test_seq_fold, y_test_seq_fold, w_test_seq_fold),\n",
        "                   callbacks=[early_stopping, reduce_lr], verbose=0)\n",
        "    y_pred_fold = fold_model.predict(X_test_seq_fold, verbose=0).flatten()\n",
        "    cv_rnn_scores.append(r2_score(y_test_seq_fold, y_pred_fold))\n",
        "\n",
        "    # Suburban and price-tier performance for this fold - Use mukim_test_seq_fold\n",
        "    suburban_mask_fold = np.isin(mukim_test_seq_fold, ['Mukim Setapak', 'Mukim Petaling'])\n",
        "    low_price_mask_fold = np.expm1(y_test_seq_fold) < 450000\n",
        "    very_low_price_mask_fold = np.expm1(y_test_seq_fold) < 300000\n",
        "\n",
        "    if suburban_mask_fold.any():\n",
        "        print(f\"Fold Suburban RNN RMSE (RM):\", np.sqrt(mean_squared_error(np.expm1(y_test_seq_fold[suburban_mask_fold]), np.expm1(y_pred_fold[suburban_mask_fold]))))\n",
        "    if low_price_mask_fold.any():\n",
        "        print(f\"Fold Low-Price (<450k RM) RNN RMSE (RM):\", np.sqrt(mean_squared_error(np.expm1(y_test_seq_fold[low_price_mask_fold]), np.expm1(y_pred_fold[low_price_mask_fold]))))\n",
        "    if very_low_price_mask_fold.any():\n",
        "        print(f\"Fold Very Low-Price (<300k RM) RNN RMSE (RM):\", np.sqrt(mean_squared_error(np.expm1(y_test_seq_fold[very_low_price_mask_fold]), np.expm1(y_pred_fold[very_low_price_mask_fold]))))\n",
        "\n",
        "print(\"RNN 5-Fold CV R:\", np.mean(cv_rnn_scores), \"\", np.std(cv_rnn_scores))\n",
        "\n",
        "# Overall suburban and price-tier performance\n",
        "suburban_mask = np.isin(mukim_test_seq, ['Mukim Setapak', 'Mukim Petaling'])\n",
        "low_price_mask = np.expm1(y_test_seq) < 450000\n",
        "very_low_price_mask = np.expm1(y_test_seq) < 300000\n",
        "if suburban_mask.any():\n",
        "    print(\"Suburban RNN RMSE (RM):\", np.sqrt(mean_squared_error(np.expm1(y_test_seq[suburban_mask]), np.expm1(y_pred_rnn[suburban_mask]))))\n",
        "if low_price_mask.any():\n",
        "    print(\"Low-Price (<450k RM) RNN RMSE (RM):\", np.sqrt(mean_squared_error(np.expm1(y_test_seq[low_price_mask]), np.expm1(y_pred_rnn[low_price_mask]))))\n",
        "if very_low_price_mask.any():\n",
        "    print(\"Very Low-Price (<300k RM) RNN RMSE (RM):\", np.sqrt(mean_squared_error(np.expm1(y_test_seq[very_low_price_mask]), np.expm1(y_pred_rnn[very_low_price_mask]))))"
      ],
      "metadata": {
        "id": "gwxtWLHognbz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b5d9e9f-8771-4173-d00c-218a49afea72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<>:16: SyntaxWarning: invalid escape sequence '\\d'\n",
            "<>:16: SyntaxWarning: invalid escape sequence '\\d'\n",
            "/tmp/ipython-input-2761223512.py:16: SyntaxWarning: invalid escape sequence '\\d'\n",
            "  df['ParcelArea'] = df['ParcelArea'].astype(str).str.extract('(\\d+\\.?\\d*)').astype(np.float32)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X shape: (14136, 6) dtype: Scheme_Name_encoded               float32\n",
            "ParcelArea                        float32\n",
            "Year                              float32\n",
            "Mukim_Mukim Setapak_Tenure        float32\n",
            "Mukim_Mukim Setapak_ParcelArea    float32\n",
            "UnitLevel_High                    float32\n",
            "dtype: object\n",
            "y shape: (14136,) dtype: float32\n",
            "weights shape: (14136,) dtype: float32\n",
            "df shape: (14136, 20)\n",
            "Unique Month-Year: ['2021-01', '2021-02', '2021-03', '2021-04', '2021-05', '2021-06', '2021-07', '2021-08', '2021-09', '2021-10', '2021-11', '2021-12', '2022-01', '2022-02', '2022-03', '2022-04', '2022-05', '2022-06', '2022-07', '2022-08', '2022-09', '2022-10', '2022-11', '2022-12', '2023-01', '2023-02', '2023-03', '2023-04', '2023-05', '2023-06', '2023-07', '2023-08', '2023-09', '2023-10', '2023-11', '2023-12', '2024-01', '2024-02', '2024-03', '2024-04', '2024-05', '2024-06', '2024-07', '2024-08', '2024-09', '2024-10', '2024-11', '2024-12', '2025-01', '2025-02', '2025-03', '2025-04', '2025-05', '2025-06']\n",
            "Sample X head:\n",
            "    Scheme_Name_encoded  ParcelArea  Year  Mukim_Mukim Setapak_Tenure  \\\n",
            "0             0.686880    1.036049  -0.5                         0.0   \n",
            "1             0.843227    1.572720  -0.5                         0.0   \n",
            "2            -0.662822   -0.613629  -0.5                         0.0   \n",
            "3             1.167282    1.572720  -0.5                         0.0   \n",
            "4             0.207606   -0.613629  -0.5                         0.0   \n",
            "\n",
            "   Mukim_Mukim Setapak_ParcelArea  UnitLevel_High  \n",
            "0                             0.0             0.0  \n",
            "1                             0.0             0.0  \n",
            "2                             0.0             0.0  \n",
            "3                             0.0             0.0  \n",
            "4                             0.0             0.0  \n",
            "Sample y head:\n",
            " 0    13.873780\n",
            "1    14.240779\n",
            "2    12.611541\n",
            "3    14.384228\n",
            "4    13.384729\n",
            "Name: TransactionPrice, dtype: float32\n",
            "Sample weights head:\n",
            " 0    1.0\n",
            "1    1.0\n",
            "2    1.0\n",
            "3    1.0\n",
            "4    1.0\n",
            "Name: Mukim, dtype: float32\n",
            "TransactionPrice stats (log-scale): count    14136.000000\n",
            "mean        13.344301\n",
            "std          0.611975\n",
            "min         10.308986\n",
            "25%         12.899222\n",
            "50%         13.235694\n",
            "75%         13.815512\n",
            "max         14.384228\n",
            "Name: TransactionPrice, dtype: float64\n",
            "TransactionPrice stats (RM): count    1.413600e+04\n",
            "mean     7.514681e+05\n",
            "std      4.744860e+05\n",
            "min      2.999999e+04\n",
            "25%      4.000000e+05\n",
            "50%      5.600001e+05\n",
            "75%      1.000000e+06\n",
            "max      1.765999e+06\n",
            "Name: TransactionPrice, dtype: float64\n",
            "Mukim counts: Mukim\n",
            "Mukim Batu                  3842\n",
            "Mukim Kuala Lumpur          2943\n",
            "Mukim Petaling              2856\n",
            "Mukim Setapak               2494\n",
            "Kuala Lumpur Town Centre    2001\n",
            "Name: count, dtype: int64\n",
            "Unique SchemeName count: 713\n",
            "SchemeName-Month-Year combinations: 8551\n",
            "Created 6247 sequences, X_seq shape: (6247, 3, 6), dtype: float32\n",
            "y_seq shape: (6247,), dtype: float32\n",
            "w_seq shape: (6247,), dtype: float32\n",
            "mukim_seq shape: (6247,), dtype: object\n",
            "Sample X_seq[0]:\n",
            " [[ 0.9568454  1.5727204 -1.         0.         0.         0.       ]\n",
            " [ 0.         0.         0.         0.         0.         0.       ]\n",
            " [ 0.         0.         0.         0.         0.         0.       ]]\n",
            "Sample y_seq[0]: 0.0\n",
            "Sample w_seq[0]: 0.0\n",
            "Sample mukim_seq[0]: \n",
            "Created 1997 sequences, X_seq shape: (1997, 3, 6), dtype: float32\n",
            "y_seq shape: (1997,), dtype: float32\n",
            "w_seq shape: (1997,), dtype: float32\n",
            "mukim_seq shape: (1997,), dtype: object\n",
            "Sample X_seq[0]:\n",
            " [[0.9568454  0.90659165 0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.        ]]\n",
            "Sample y_seq[0]: 0.0\n",
            "Sample w_seq[0]: 0.0\n",
            "Sample mukim_seq[0]: \n",
            "Created 2418 sequences, X_seq shape: (2418, 3, 6), dtype: float32\n",
            "y_seq shape: (2418,), dtype: float32\n",
            "w_seq shape: (2418,), dtype: float32\n",
            "mukim_seq shape: (2418,), dtype: object\n",
            "Sample X_seq[0]:\n",
            " [[0.9568454 1.4228412 0.        0.        0.        0.       ]\n",
            " [0.        0.        0.        0.        0.        0.       ]\n",
            " [0.        0.        0.        0.        0.        0.       ]]\n",
            "Sample y_seq[0]: 0.0\n",
            "Sample w_seq[0]: 0.0\n",
            "Sample mukim_seq[0]: \n",
            "RNN R: -32.38432312011719\n",
            "RNN RMSE (log-scale): 12.86715844619519\n",
            "RNN RMSE (RM): 471286.7875253878\n",
            "Sample y_test_seq (log-scale): [0. 0. 0. 0. 0.]\n",
            "Sample y_pred_rnn (log-scale): [13.114151 13.086903 12.919855 12.909714 12.898058]\n",
            "Sample y_test_seq (RM): [0. 0. 0. 0. 0.]\n",
            "Sample y_pred_rnn (RM): [495909.62 482579.3  408338.88 404218.7  399534.5 ]\n",
            "Prediction stats (log-scale): count    2418.000000\n",
            "mean       13.051523\n",
            "std         0.125858\n",
            "min        11.281292\n",
            "25%        12.957461\n",
            "50%        13.066076\n",
            "75%        13.139683\n",
            "max        13.523270\n",
            "dtype: float64\n",
            "Prediction stats (RM): count      2418.000000\n",
            "mean     469366.468750\n",
            "std       57015.468750\n",
            "min       79322.679688\n",
            "25%      423987.093750\n",
            "50%      472632.640625\n",
            "75%      508733.992188\n",
            "max      746587.625000\n",
            "dtype: float64\n",
            "Created 7344 sequences, X_seq shape: (7344, 3, 6), dtype: float32\n",
            "y_seq shape: (7344,), dtype: float32\n",
            "w_seq shape: (7344,), dtype: float32\n",
            "mukim_seq shape: (7344,), dtype: object\n",
            "Sample X_seq[0]:\n",
            " [[ 0.9568454  1.5727204 -1.         0.         0.         0.       ]\n",
            " [ 0.         0.         0.         0.         0.         0.       ]\n",
            " [ 0.         0.         0.         0.         0.         0.       ]]\n",
            "Sample y_seq[0]: 0.0\n",
            "Sample w_seq[0]: 0.0\n",
            "Sample mukim_seq[0]: \n",
            "Created 2418 sequences, X_seq shape: (2418, 3, 6), dtype: float32\n",
            "y_seq shape: (2418,), dtype: float32\n",
            "w_seq shape: (2418,), dtype: float32\n",
            "mukim_seq shape: (2418,), dtype: object\n",
            "Sample X_seq[0]:\n",
            " [[0.9568454 1.4228412 0.        0.        0.        0.       ]\n",
            " [0.        0.        0.        0.        0.        0.       ]\n",
            " [0.        0.        0.        0.        0.        0.       ]]\n",
            "Sample y_seq[0]: 0.0\n",
            "Sample w_seq[0]: 0.0\n",
            "Sample mukim_seq[0]: \n",
            "Fold Suburban RNN RMSE (RM): 100933.38730073415\n",
            "Fold Low-Price (<450k RM) RNN RMSE (RM): 561950.9640671506\n",
            "Fold Very Low-Price (<300k RM) RNN RMSE (RM): 562899.9346100512\n",
            "Created 7359 sequences, X_seq shape: (7359, 3, 6), dtype: float32\n",
            "y_seq shape: (7359,), dtype: float32\n",
            "w_seq shape: (7359,), dtype: float32\n",
            "mukim_seq shape: (7359,), dtype: object\n",
            "Sample X_seq[0]:\n",
            " [[0.9568454 1.4228412 0.        0.        0.        0.       ]\n",
            " [0.        0.        0.        0.        0.        0.       ]\n",
            " [0.        0.        0.        0.        0.        0.       ]]\n",
            "Sample y_seq[0]: 0.0\n",
            "Sample w_seq[0]: 0.0\n",
            "Sample mukim_seq[0]: \n",
            "Created 2403 sequences, X_seq shape: (2403, 3, 6), dtype: float32\n",
            "y_seq shape: (2403,), dtype: float32\n",
            "w_seq shape: (2403,), dtype: float32\n",
            "mukim_seq shape: (2403,), dtype: object\n",
            "Sample X_seq[0]:\n",
            " [[ 0.9568454  1.5727204 -1.         0.         0.         0.       ]\n",
            " [ 0.         0.         0.         0.         0.         0.       ]\n",
            " [ 0.         0.         0.         0.         0.         0.       ]]\n",
            "Sample y_seq[0]: 0.0\n",
            "Sample w_seq[0]: 0.0\n",
            "Sample mukim_seq[0]: \n",
            "Fold Suburban RNN RMSE (RM): 188696.3132231258\n",
            "Fold Low-Price (<450k RM) RNN RMSE (RM): 647999.845135784\n",
            "Fold Very Low-Price (<300k RM) RNN RMSE (RM): 649195.3056638656\n",
            "Created 7372 sequences, X_seq shape: (7372, 3, 6), dtype: float32\n",
            "y_seq shape: (7372,), dtype: float32\n",
            "w_seq shape: (7372,), dtype: float32\n",
            "mukim_seq shape: (7372,), dtype: object\n",
            "Sample X_seq[0]:\n",
            " [[ 0.9568454  1.5727204 -1.         0.         0.         0.       ]\n",
            " [ 0.         0.         0.         0.         0.         0.       ]\n",
            " [ 0.         0.         0.         0.         0.         0.       ]]\n",
            "Sample y_seq[0]: 0.0\n",
            "Sample w_seq[0]: 0.0\n",
            "Sample mukim_seq[0]: \n",
            "Created 2424 sequences, X_seq shape: (2424, 3, 6), dtype: float32\n",
            "y_seq shape: (2424,), dtype: float32\n",
            "w_seq shape: (2424,), dtype: float32\n",
            "mukim_seq shape: (2424,), dtype: object\n",
            "Sample X_seq[0]:\n",
            " [[-0.49121663 -0.6136288  -0.5         0.          0.          0.        ]\n",
            " [ 0.          0.          0.          0.          0.          0.        ]\n",
            " [ 0.          0.          0.          0.          0.          0.        ]]\n",
            "Sample y_seq[0]: 0.0\n",
            "Sample w_seq[0]: 0.0\n",
            "Sample mukim_seq[0]: \n",
            "Fold Suburban RNN RMSE (RM): 265937.76691549475\n",
            "Fold Low-Price (<450k RM) RNN RMSE (RM): 603101.2553659626\n",
            "Fold Very Low-Price (<300k RM) RNN RMSE (RM): 604097.8951130355\n",
            "Created 7318 sequences, X_seq shape: (7318, 3, 6), dtype: float32\n",
            "y_seq shape: (7318,), dtype: float32\n",
            "w_seq shape: (7318,), dtype: float32\n",
            "mukim_seq shape: (7318,), dtype: object\n",
            "Sample X_seq[0]:\n",
            " [[ 0.9568454  1.5727204 -1.         0.         0.         0.       ]\n",
            " [ 0.         0.         0.         0.         0.         0.       ]\n",
            " [ 0.         0.         0.         0.         0.         0.       ]]\n",
            "Sample y_seq[0]: 0.0\n",
            "Sample w_seq[0]: 0.0\n",
            "Sample mukim_seq[0]: \n",
            "Created 2433 sequences, X_seq shape: (2433, 3, 6), dtype: float32\n",
            "y_seq shape: (2433,), dtype: float32\n",
            "w_seq shape: (2433,), dtype: float32\n",
            "mukim_seq shape: (2433,), dtype: object\n",
            "Sample X_seq[0]:\n",
            " [[0.9568454 1.4228412 0.        0.        0.        0.       ]\n",
            " [0.        0.        0.        0.        0.        0.       ]\n",
            " [0.        0.        0.        0.        0.        0.       ]]\n",
            "Sample y_seq[0]: 0.0\n",
            "Sample w_seq[0]: 0.0\n",
            "Sample mukim_seq[0]: \n",
            "Fold Suburban RNN RMSE (RM): 146921.12713970037\n",
            "Fold Low-Price (<450k RM) RNN RMSE (RM): 566198.6787974695\n",
            "Fold Very Low-Price (<300k RM) RNN RMSE (RM): 567239.419561088\n",
            "Created 7355 sequences, X_seq shape: (7355, 3, 6), dtype: float32\n",
            "y_seq shape: (7355,), dtype: float32\n",
            "w_seq shape: (7355,), dtype: float32\n",
            "mukim_seq shape: (7355,), dtype: object\n",
            "Sample X_seq[0]:\n",
            " [[ 0.9568454  1.5727204 -1.         0.         0.         0.       ]\n",
            " [ 0.         0.         0.         0.         0.         0.       ]\n",
            " [ 0.         0.         0.         0.         0.         0.       ]]\n",
            "Sample y_seq[0]: 0.0\n",
            "Sample w_seq[0]: 0.0\n",
            "Sample mukim_seq[0]: \n",
            "Created 2422 sequences, X_seq shape: (2422, 3, 6), dtype: float32\n",
            "y_seq shape: (2422,), dtype: float32\n",
            "w_seq shape: (2422,), dtype: float32\n",
            "mukim_seq shape: (2422,), dtype: object\n",
            "Sample X_seq[0]:\n",
            " [[-0.49121663 -0.6136288   0.          0.          0.          0.        ]\n",
            " [ 0.          0.          0.          0.          0.          0.        ]\n",
            " [ 0.          0.          0.          0.          0.          0.        ]]\n",
            "Sample y_seq[0]: 0.0\n",
            "Sample w_seq[0]: 0.0\n",
            "Sample mukim_seq[0]: \n",
            "Fold Suburban RNN RMSE (RM): 127410.73562302355\n",
            "Fold Low-Price (<450k RM) RNN RMSE (RM): 589291.342817795\n",
            "Fold Very Low-Price (<300k RM) RNN RMSE (RM): 589901.9948432113\n",
            "RNN 5-Fold CV R: -34.249843978881835  3.161765325875529\n",
            "Suburban RNN RMSE (RM): 303013.364827362\n",
            "Low-Price (<450k RM) RNN RMSE (RM): 468945.3077193544\n",
            "Very Low-Price (<300k RM) RNN RMSE (RM): 469636.1689648701\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RNN SchemeName-Month-Year"
      ],
      "metadata": {
        "id": "pqGS3ZAGzmSV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from sklearn.metrics import r2_score, mean_squared_error\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Input, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "import joblib\n",
        "\n",
        "# Load and preprocess\n",
        "url = \"https://raw.githubusercontent.com/englian1123/KL-High-Rise-Data/refs/heads/main/KLHighRise.csv\"\n",
        "df = pd.read_csv(url)\n",
        "df.rename(columns={'TransactionPrice  ': 'TransactionPrice', 'Parcel Area': 'ParcelArea', 'Scheme Name/Area': 'SchemeName'}, inplace=True)\n",
        "df['ParcelArea'] = df['ParcelArea'].astype(str).str.extract('(\\d+\\.?\\d*)').astype(np.float32)\n",
        "df['Tenure'] = df['Tenure'].map({'Freehold': 1, 'Leasehold': 0}).fillna(0).astype(np.float32)\n",
        "\n",
        "# Drop low-count Mukims and reset index\n",
        "low_count_mukims = ['Mukim Cheras', 'Mukim Ampang', 'Mukim Ulu Kelang']\n",
        "df = df[~df['Mukim'].isin(low_count_mukims)].reset_index(drop=True)\n",
        "\n",
        "# Outlier capping (90th percentile)\n",
        "price_cap = df['TransactionPrice'].quantile(0.90)\n",
        "df['TransactionPrice'] = np.clip(df['TransactionPrice'], 0, price_cap).astype(np.float32)\n",
        "area_cap = df['ParcelArea'].quantile(0.90)\n",
        "df['ParcelArea'] = np.clip(df['ParcelArea'], 0, area_cap).astype(np.float32)\n",
        "\n",
        "# Log-transform\n",
        "df['TransactionPrice'] = np.log1p(df['TransactionPrice']).astype(np.float32)\n",
        "df['ParcelArea'] = np.log1p(df['ParcelArea']).astype(np.float32)\n",
        "\n",
        "# Target encode SchemeName\n",
        "scheme_encoding = df.groupby('SchemeName')['TransactionPrice'].mean().astype(np.float32)\n",
        "df['Scheme_Name_encoded'] = df['SchemeName'].map(scheme_encoding).fillna(scheme_encoding.mean()).astype(np.float32)\n",
        "joblib.dump(scheme_encoding, 'scheme_encoding.joblib')\n",
        "\n",
        "# Add Month-Year\n",
        "df['TransactionDate'] = pd.to_datetime(df['TransactionDate'], format='%b-%y')\n",
        "df['Year'] = df['TransactionDate'].dt.year.astype(np.float32)\n",
        "df['Month-Year'] = df['TransactionDate'].dt.strftime('%Y-%m').astype(str)\n",
        "\n",
        "# Clean UnitLevel\n",
        "unit_level_map = {'03A': 4, '12B': 12, '13A': 14, '23A': 24, '33A': 34, '43A': 44, '53A': 54,\n",
        "                  'B': 0, 'D': 0, 'G': 0, 'LG': 0, 'MZ': 0, 'P': 0, 'UG': 0,\n",
        "                  '1/5/2025': 0, '2/3/2025': 0, '1/4/2025': 0}\n",
        "df['UnitLevel_clean'] = df['UnitLevel'].replace(unit_level_map)\n",
        "unit_level_mean = pd.to_numeric(df['UnitLevel_clean'], errors='coerce').mean()\n",
        "df['UnitLevel_clean'] = pd.to_numeric(df['UnitLevel_clean'], errors='coerce').fillna(unit_level_mean).astype(np.float32)\n",
        "df['UnitLevel_binned'] = pd.cut(df['UnitLevel_clean'], bins=[-float('inf'), 10, 20, float('inf')], labels=['Low', 'Mid', 'High'])\n",
        "level_dummies = pd.get_dummies(df['UnitLevel_binned'], prefix='UnitLevel', dtype=np.float32)\n",
        "\n",
        "# Setapak interactions\n",
        "mukim_dummies = pd.get_dummies(df['Mukim'], prefix='Mukim', dtype=np.float32)\n",
        "df['Mukim_Mukim Setapak_Tenure'] = (mukim_dummies.get('Mukim_Mukim Setapak', pd.Series(0, index=df.index)) * df['Tenure']).astype(np.float32)\n",
        "df['Mukim_Mukim Setapak_ParcelArea'] = (mukim_dummies.get('Mukim_Mukim Setapak', pd.Series(0, index=df.index)) * df['ParcelArea']).astype(np.float32)\n",
        "\n",
        "# Features\n",
        "features = ['Scheme_Name_encoded', 'ParcelArea', 'Year', 'Mukim_Mukim Setapak_Tenure',\n",
        "            'Mukim_Mukim Setapak_ParcelArea', 'UnitLevel_High']\n",
        "X = pd.concat([df[['Scheme_Name_encoded', 'ParcelArea', 'Year']],\n",
        "               df[['Mukim_Mukim Setapak_Tenure', 'Mukim_Mukim Setapak_ParcelArea']],\n",
        "               level_dummies[['UnitLevel_High']]], axis=1).astype(np.float32)\n",
        "y = df['TransactionPrice'].astype(np.float32)\n",
        "\n",
        "# Robust scaling\n",
        "scaler = RobustScaler()\n",
        "X[['Scheme_Name_encoded', 'ParcelArea', 'Year']] = scaler.fit_transform(X[['Scheme_Name_encoded', 'ParcelArea', 'Year']]).astype(np.float32)\n",
        "joblib.dump(scaler, 'scaler.joblib')\n",
        "\n",
        "# Sample weights\n",
        "weights = df['Mukim'].apply(lambda x: 5.0 if x in ['Mukim Setapak', 'Mukim Petaling'] else 1.0).astype(np.float32)\n",
        "\n",
        "# Debug: Check data shapes and dtypes\n",
        "print(\"X shape:\", X.shape, \"dtype:\", X.dtypes)\n",
        "print(\"y shape:\", y.shape, \"dtype:\", y.dtype)\n",
        "print(\"weights shape:\", weights.shape, \"dtype:\", weights.dtype)\n",
        "print(\"df shape:\", df.shape)\n",
        "print(\"Unique Month-Year:\", sorted(df['Month-Year'].unique()))\n",
        "print(\"Sample X head:\\n\", X.head())\n",
        "print(\"Sample y head:\\n\", y.head())\n",
        "print(\"Sample weights head:\\n\", weights.head())\n",
        "print(\"TransactionPrice stats (log-scale):\", y.describe())\n",
        "print(\"TransactionPrice stats (RM):\", np.expm1(y).describe())\n",
        "print(\"Mukim counts:\", df['Mukim'].value_counts())\n",
        "print(\"Unique SchemeName count:\", df['SchemeName'].nunique())\n",
        "print(\"SchemeName-Month-Year combinations:\", len(df.groupby(['SchemeName', 'Month-Year'])))\n",
        "\n",
        "# Reshape data for RNN (sequences by SchemeName and Month-Year)\n",
        "timesteps = 3  # Fixed timesteps\n",
        "feature_count = X.shape[1]  # Include Year\n",
        "\n",
        "# Train-test split with validation\n",
        "X_temp, X_test, y_temp, y_test, w_temp, w_test = train_test_split(X, y, weights, test_size=0.2, random_state=42)\n",
        "X_train, X_val, y_train, y_val, w_train, w_val = train_test_split(X_temp, y_temp, w_temp, test_size=0.2, random_state=42)\n",
        "\n",
        "# Function to create per-SchemeName-Month-Year sequences\n",
        "def create_sequences(X, y, weights, timesteps, df_full):\n",
        "    X_seq, y_seq, w_seq, mukim_seq = [], [], [], []\n",
        "    invalid_seq_count = 0\n",
        "    # Group by SchemeName and Month-Year on the full DataFrame\n",
        "    groups = df_full.groupby(['SchemeName', 'Month-Year'])\n",
        "    for (scheme, month_year), group_idx in groups.groups.items():\n",
        "        # Filter group indices to only include those present in the current X subset\n",
        "        valid_group_idx = group_idx.intersection(X.index)\n",
        "        if len(valid_group_idx) > 0:\n",
        "            X_group = X.loc[valid_group_idx, features].values\n",
        "            y_group = y.loc[valid_group_idx].values\n",
        "            w_group = weights.loc[valid_group_idx].values\n",
        "            mukim_group = df_full.loc[valid_group_idx, 'Mukim'].values\n",
        "            # Skip groups with all-zero y_group\n",
        "            if np.all(y_group == 0.0):\n",
        "                invalid_seq_count += 1\n",
        "                continue\n",
        "            # Aggregate up to timesteps samples (median if multiple)\n",
        "            if len(X_group) > timesteps:\n",
        "                # Compute median values for each feature\n",
        "                X_group = np.median(X_group, axis=0, keepdims=True).repeat(timesteps, axis=0)\n",
        "                y_group = np.array([np.median(y_group)] * timesteps)\n",
        "                w_group = np.array([np.median(w_group)] * timesteps)\n",
        "                mukim_group = np.array([mukim_group[0]] * timesteps)  # Use first Mukim\n",
        "            elif len(X_group) < timesteps:\n",
        "                pad_len = timesteps - len(X_group)\n",
        "                X_group = np.pad(X_group, ((0, pad_len), (0, 0)), mode='constant', constant_values=0).astype(np.float32)\n",
        "                y_group = np.pad(y_group, (0, pad_len), mode='constant', constant_values=0).astype(np.float32)\n",
        "                w_group = np.pad(w_group, (0, pad_len), mode='constant', constant_values=0).astype(np.float32)\n",
        "                mukim_group = np.pad(mukim_group, (0, pad_len), mode='constant', constant_values='').astype(str)\n",
        "            # Use mean of non-zero y_group values for y_seq\n",
        "            non_zero_y = y_group[y_group > 0]\n",
        "            if len(non_zero_y) > 0:\n",
        "                X_seq.append(X_group)\n",
        "                y_seq.append(np.mean(non_zero_y).astype(np.float32))  # Mean of non-zero prices\n",
        "                w_seq.append(np.mean(w_group[w_group > 0]).astype(np.float32) if np.any(w_group > 0) else 1.0)\n",
        "                mukim_seq.append(mukim_group[-1])  # Last Mukim\n",
        "    X_seq = np.array(X_seq, dtype=np.float32)\n",
        "    y_seq = np.array(y_seq, dtype=np.float32)\n",
        "    w_seq = np.array(w_seq, dtype=np.float32)\n",
        "    mukim_seq = np.array(mukim_seq, dtype=object)\n",
        "    if len(X_seq) == 0:\n",
        "        print(\"Warning: No valid sequences created. Using dummy sequence.\")\n",
        "        return np.zeros((1, timesteps, len(features)), dtype=np.float32), np.zeros(1, dtype=np.float32), np.zeros(1, dtype=np.float32), np.array([''], dtype=object)\n",
        "    print(f\"Created {len(X_seq)} sequences, X_seq shape: {X_seq.shape}, dtype: {X_seq.dtype}\")\n",
        "    print(f\"y_seq shape: {y_seq.shape}, dtype: {y_seq.dtype}\")\n",
        "    print(f\"w_seq shape: {w_seq.shape}, dtype: {w_seq.dtype}\")\n",
        "    print(f\"mukim_seq shape: {mukim_seq.shape}, dtype: {mukim_seq.dtype}\")\n",
        "    print(f\"Invalid sequences skipped: {invalid_seq_count} ({invalid_seq_count/len(groups.groups)*100:.2f}%)\")\n",
        "    print(\"Sample X_seq[0]:\\n\", X_seq[0])\n",
        "    print(\"Sample y_seq[0]:\", y_seq[0])\n",
        "    print(\"Sample w_seq[0]:\", w_seq[0])\n",
        "    print(\"Sample mukim_seq[0]:\", mukim_seq[0])\n",
        "    return X_seq, y_seq, w_seq, mukim_seq\n",
        "\n",
        "# Create sequences for train, validation, and test\n",
        "X_train_seq, y_train_seq, w_train_seq, mukim_train_seq = create_sequences(X_train, y_train, w_train, timesteps, df)\n",
        "X_val_seq, y_val_seq, w_val_seq, mukim_val_seq = create_sequences(X_val, y_val, w_val, timesteps, df)\n",
        "X_test_seq, y_test_seq, w_test_seq, mukim_test_seq = create_sequences(X_test, y_test, w_test, timesteps, df)\n",
        "\n",
        "# Define simplified RNN model\n",
        "def create_rnn_model(timesteps, feature_count):\n",
        "    model = Sequential([\n",
        "        Input(shape=(timesteps, feature_count)),  # Include Year\n",
        "        LSTM(8, return_sequences=False),  # Reduced units\n",
        "        Dense(32, activation='relu'),\n",
        "        Dropout(0.2),\n",
        "        Dense(16, activation='relu'),\n",
        "        Dropout(0.2),\n",
        "        Dense(1)\n",
        "    ])\n",
        "    optimizer = RMSprop(learning_rate=0.001)\n",
        "    model.compile(optimizer=optimizer, loss='mse')\n",
        "    return model\n",
        "\n",
        "# Train RNN\n",
        "rnn_model = create_rnn_model(timesteps, feature_count)\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=30, restore_best_weights=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10, min_lr=0.00001)\n",
        "rnn_model.fit(X_train_seq, y_train_seq, sample_weight=w_train_seq, epochs=200, batch_size=16,\n",
        "              validation_data=(X_val_seq, y_val_seq, w_val_seq), callbacks=[early_stopping, reduce_lr], verbose=0)\n",
        "rnn_model.save('rnn_model.keras')  # Native Keras format\n",
        "\n",
        "# Evaluate RNN\n",
        "y_pred_rnn = rnn_model.predict(X_test_seq, verbose=0).flatten()\n",
        "print(\"RNN R:\", r2_score(y_test_seq, y_pred_rnn))\n",
        "print(\"RNN RMSE (log-scale):\", np.sqrt(mean_squared_error(y_test_seq, y_pred_rnn)))\n",
        "print(\"RNN RMSE (RM):\", np.sqrt(mean_squared_error(np.expm1(y_test_seq), np.expm1(y_pred_rnn))))\n",
        "\n",
        "# Debug predictions\n",
        "print(\"Sample y_test_seq (log-scale):\", y_test_seq[:5])\n",
        "print(\"Sample y_pred_rnn (log-scale):\", y_pred_rnn[:5])\n",
        "print(\"Sample y_test_seq (RM):\", np.expm1(y_test_seq[:5]))\n",
        "print(\"Sample y_pred_rnn (RM):\", np.expm1(y_pred_rnn[:5]))\n",
        "print(\"Prediction stats (log-scale):\", pd.Series(y_pred_rnn).describe())\n",
        "print(\"Prediction stats (RM):\", pd.Series(np.expm1(y_pred_rnn)).describe())\n",
        "\n",
        "# Cross-validation\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "cv_rnn_scores = []\n",
        "\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train_fold, X_test_fold = X.loc[train_index], X.loc[test_index]\n",
        "    y_train_fold, y_test_fold = y.loc[train_index], y.loc[test_index]\n",
        "    weights_train_fold = weights.loc[train_index]\n",
        "    weights_test_fold = weights.loc[test_index]\n",
        "\n",
        "    # Filter df for the current fold's indices\n",
        "    df_train_fold = df.loc[df.index.intersection(train_index)]\n",
        "    df_test_fold = df.loc[df.index.intersection(test_index)]\n",
        "\n",
        "    X_train_seq_fold, y_train_seq_fold, w_train_seq_fold, mukim_train_seq_fold = create_sequences(X_train_fold, y_train_fold, weights_train_fold, timesteps, df_train_fold)\n",
        "    X_test_seq_fold, y_test_seq_fold, w_test_seq_fold, mukim_test_seq_fold = create_sequences(X_test_fold, y_test_fold, weights_test_fold, timesteps, df_test_fold)\n",
        "\n",
        "    # Skip the fold if no sequences were created\n",
        "    if len(X_train_seq_fold) == 0 or len(X_test_seq_fold) == 0:\n",
        "        print(\"Skipping fold due to no sequences.\")\n",
        "        continue\n",
        "\n",
        "    fold_model = create_rnn_model(timesteps, feature_count)\n",
        "    fold_model.fit(X_train_seq_fold, y_train_seq_fold, sample_weight=w_train_seq_fold, epochs=200,\n",
        "                   batch_size=16, validation_data=(X_test_seq_fold, y_test_seq_fold, w_test_seq_fold),\n",
        "                   callbacks=[early_stopping, reduce_lr], verbose=0)\n",
        "    y_pred_fold = fold_model.predict(X_test_seq_fold, verbose=0).flatten()\n",
        "    cv_rnn_scores.append(r2_score(y_test_seq_fold, y_pred_fold))\n",
        "\n",
        "    # Suburban and price-tier performance for this fold\n",
        "    suburban_mask_fold = np.isin(mukim_test_seq_fold, ['Mukim Setapak', 'Mukim Petaling'])\n",
        "    low_price_mask_fold = np.expm1(y_test_seq_fold) < 450000\n",
        "    very_low_price_mask_fold = np.expm1(y_test_seq_fold) < 300000\n",
        "\n",
        "    if suburban_mask_fold.any():\n",
        "        print(f\"Fold Suburban RNN RMSE (RM):\", np.sqrt(mean_squared_error(np.expm1(y_test_seq_fold[suburban_mask_fold]), np.expm1(y_pred_fold[suburban_mask_fold]))))\n",
        "    if low_price_mask_fold.any():\n",
        "        print(f\"Fold Low-Price (<450k RM) RNN RMSE (RM):\", np.sqrt(mean_squared_error(np.expm1(y_test_seq_fold[low_price_mask_fold]), np.expm1(y_pred_fold[low_price_mask_fold]))))\n",
        "    if very_low_price_mask_fold.any():\n",
        "        print(f\"Fold Very Low-Price (<300k RM) RNN RMSE (RM):\", np.sqrt(mean_squared_error(np.expm1(y_test_seq_fold[very_low_price_mask_fold]), np.expm1(y_pred_fold[very_low_price_mask_fold]))))\n",
        "\n",
        "print(\"RNN 5-Fold CV R:\", np.mean(cv_rnn_scores), \"\", np.std(cv_rnn_scores))\n",
        "\n",
        "# Overall suburban and price-tier performance\n",
        "suburban_mask = np.isin(mukim_test_seq, ['Mukim Setapak', 'Mukim Petaling'])\n",
        "low_price_mask = np.expm1(y_test_seq) < 450000\n",
        "very_low_price_mask = np.expm1(y_test_seq) < 300000\n",
        "if suburban_mask.any():\n",
        "    print(\"Suburban RNN RMSE (RM):\", np.sqrt(mean_squared_error(np.expm1(y_test_seq[suburban_mask]), np.expm1(y_pred_rnn[suburban_mask]))))\n",
        "if low_price_mask.any():\n",
        "    print(\"Low-Price (<450k RM) RNN RMSE (RM):\", np.sqrt(mean_squared_error(np.expm1(y_test_seq[low_price_mask]), np.expm1(y_pred_rnn[low_price_mask]))))\n",
        "if very_low_price_mask.any():\n",
        "    print(\"Very Low-Price (<300k RM) RNN RMSE (RM):\", np.sqrt(mean_squared_error(np.expm1(y_test_seq[very_low_price_mask]), np.expm1(y_pred_rnn[very_low_price_mask]))))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_abPkp9ZzpuI",
        "outputId": "40b53299-242e-45d5-bd2e-ed901136bae2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<>:16: SyntaxWarning: invalid escape sequence '\\d'\n",
            "<>:16: SyntaxWarning: invalid escape sequence '\\d'\n",
            "/tmp/ipython-input-1355112481.py:16: SyntaxWarning: invalid escape sequence '\\d'\n",
            "  df['ParcelArea'] = df['ParcelArea'].astype(str).str.extract('(\\d+\\.?\\d*)').astype(np.float32)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X shape: (14136, 6) dtype: Scheme_Name_encoded               float32\n",
            "ParcelArea                        float32\n",
            "Year                              float32\n",
            "Mukim_Mukim Setapak_Tenure        float32\n",
            "Mukim_Mukim Setapak_ParcelArea    float32\n",
            "UnitLevel_High                    float32\n",
            "dtype: object\n",
            "y shape: (14136,) dtype: float32\n",
            "weights shape: (14136,) dtype: float32\n",
            "df shape: (14136, 20)\n",
            "Unique Month-Year: ['2021-01', '2021-02', '2021-03', '2021-04', '2021-05', '2021-06', '2021-07', '2021-08', '2021-09', '2021-10', '2021-11', '2021-12', '2022-01', '2022-02', '2022-03', '2022-04', '2022-05', '2022-06', '2022-07', '2022-08', '2022-09', '2022-10', '2022-11', '2022-12', '2023-01', '2023-02', '2023-03', '2023-04', '2023-05', '2023-06', '2023-07', '2023-08', '2023-09', '2023-10', '2023-11', '2023-12', '2024-01', '2024-02', '2024-03', '2024-04', '2024-05', '2024-06', '2024-07', '2024-08', '2024-09', '2024-10', '2024-11', '2024-12', '2025-01', '2025-02', '2025-03', '2025-04', '2025-05', '2025-06']\n",
            "Sample X head:\n",
            "    Scheme_Name_encoded  ParcelArea  Year  Mukim_Mukim Setapak_Tenure  \\\n",
            "0             0.686880    1.036049  -0.5                         0.0   \n",
            "1             0.843227    1.572720  -0.5                         0.0   \n",
            "2            -0.662822   -0.613629  -0.5                         0.0   \n",
            "3             1.167282    1.572720  -0.5                         0.0   \n",
            "4             0.207606   -0.613629  -0.5                         0.0   \n",
            "\n",
            "   Mukim_Mukim Setapak_ParcelArea  UnitLevel_High  \n",
            "0                             0.0             0.0  \n",
            "1                             0.0             0.0  \n",
            "2                             0.0             0.0  \n",
            "3                             0.0             0.0  \n",
            "4                             0.0             0.0  \n",
            "Sample y head:\n",
            " 0    13.873780\n",
            "1    14.240779\n",
            "2    12.611541\n",
            "3    14.384228\n",
            "4    13.384729\n",
            "Name: TransactionPrice, dtype: float32\n",
            "Sample weights head:\n",
            " 0    1.0\n",
            "1    1.0\n",
            "2    1.0\n",
            "3    1.0\n",
            "4    1.0\n",
            "Name: Mukim, dtype: float32\n",
            "TransactionPrice stats (log-scale): count    14136.000000\n",
            "mean        13.344301\n",
            "std          0.611975\n",
            "min         10.308986\n",
            "25%         12.899222\n",
            "50%         13.235694\n",
            "75%         13.815512\n",
            "max         14.384228\n",
            "Name: TransactionPrice, dtype: float64\n",
            "TransactionPrice stats (RM): count    1.413600e+04\n",
            "mean     7.514681e+05\n",
            "std      4.744860e+05\n",
            "min      2.999999e+04\n",
            "25%      4.000000e+05\n",
            "50%      5.600001e+05\n",
            "75%      1.000000e+06\n",
            "max      1.765999e+06\n",
            "Name: TransactionPrice, dtype: float64\n",
            "Mukim counts: Mukim\n",
            "Mukim Batu                  3842\n",
            "Mukim Kuala Lumpur          2943\n",
            "Mukim Petaling              2856\n",
            "Mukim Setapak               2494\n",
            "Kuala Lumpur Town Centre    2001\n",
            "Name: count, dtype: int64\n",
            "Unique SchemeName count: 713\n",
            "SchemeName-Month-Year combinations: 8551\n",
            "Created 6247 sequences, X_seq shape: (6247, 3, 6), dtype: float32\n",
            "y_seq shape: (6247,), dtype: float32\n",
            "w_seq shape: (6247,), dtype: float32\n",
            "mukim_seq shape: (6247,), dtype: object\n",
            "Invalid sequences skipped: 0 (0.00%)\n",
            "Sample X_seq[0]:\n",
            " [[ 0.9568454  1.5727204 -1.         0.         0.         0.       ]\n",
            " [ 0.         0.         0.         0.         0.         0.       ]\n",
            " [ 0.         0.         0.         0.         0.         0.       ]]\n",
            "Sample y_seq[0]: 14.384228\n",
            "Sample w_seq[0]: 1.0\n",
            "Sample mukim_seq[0]: \n",
            "Created 1997 sequences, X_seq shape: (1997, 3, 6), dtype: float32\n",
            "y_seq shape: (1997,), dtype: float32\n",
            "w_seq shape: (1997,), dtype: float32\n",
            "mukim_seq shape: (1997,), dtype: object\n",
            "Invalid sequences skipped: 0 (0.00%)\n",
            "Sample X_seq[0]:\n",
            " [[0.9568454  0.90659165 0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.        ]]\n",
            "Sample y_seq[0]: 13.84507\n",
            "Sample w_seq[0]: 1.0\n",
            "Sample mukim_seq[0]: \n",
            "Created 2418 sequences, X_seq shape: (2418, 3, 6), dtype: float32\n",
            "y_seq shape: (2418,), dtype: float32\n",
            "w_seq shape: (2418,), dtype: float32\n",
            "mukim_seq shape: (2418,), dtype: object\n",
            "Invalid sequences skipped: 0 (0.00%)\n",
            "Sample X_seq[0]:\n",
            " [[0.9568454 1.4228412 0.        0.        0.        0.       ]\n",
            " [0.        0.        0.        0.        0.        0.       ]\n",
            " [0.        0.        0.        0.        0.        0.       ]]\n",
            "Sample y_seq[0]: 14.137595\n",
            "Sample w_seq[0]: 1.0\n",
            "Sample mukim_seq[0]: \n",
            "RNN R: 0.8341063857078552\n",
            "RNN RMSE (log-scale): 0.24518986874441864\n",
            "RNN RMSE (RM): 235881.01895659175\n",
            "Sample y_test_seq (log-scale): [14.137595 14.220976 12.67608  12.847929 12.669809]\n",
            "Sample y_pred_rnn (log-scale): [13.943983 13.923933 12.683908 12.68648  12.572485]\n",
            "Sample y_test_seq (RM): [1380000.5  1499999.2   320000.12  379999.94  317999.84]\n",
            "Sample y_pred_rnn (RM): [1137089.1  1114517.5   322515.12  323345.44  288509.  ]\n",
            "Prediction stats (log-scale): count    2418.000000\n",
            "mean       13.208068\n",
            "std         0.500336\n",
            "min        11.176464\n",
            "25%        12.808963\n",
            "50%        13.088676\n",
            "75%        13.605397\n",
            "max        14.382315\n",
            "dtype: float64\n",
            "Prediction stats (RM): count    2.418000e+03\n",
            "mean     6.201366e+05\n",
            "std      3.330465e+05\n",
            "min      7.142834e+04\n",
            "25%      3.654776e+05\n",
            "50%      4.834362e+05\n",
            "75%      8.104923e+05\n",
            "max      1.762624e+06\n",
            "dtype: float64\n",
            "Created 7344 sequences, X_seq shape: (7344, 3, 6), dtype: float32\n",
            "y_seq shape: (7344,), dtype: float32\n",
            "w_seq shape: (7344,), dtype: float32\n",
            "mukim_seq shape: (7344,), dtype: object\n",
            "Invalid sequences skipped: 0 (0.00%)\n",
            "Sample X_seq[0]:\n",
            " [[ 0.9568454  1.5727204 -1.         0.         0.         0.       ]\n",
            " [ 0.         0.         0.         0.         0.         0.       ]\n",
            " [ 0.         0.         0.         0.         0.         0.       ]]\n",
            "Sample y_seq[0]: 14.384228\n",
            "Sample w_seq[0]: 1.0\n",
            "Sample mukim_seq[0]: \n",
            "Created 2418 sequences, X_seq shape: (2418, 3, 6), dtype: float32\n",
            "y_seq shape: (2418,), dtype: float32\n",
            "w_seq shape: (2418,), dtype: float32\n",
            "mukim_seq shape: (2418,), dtype: object\n",
            "Invalid sequences skipped: 0 (0.00%)\n",
            "Sample X_seq[0]:\n",
            " [[0.9568454 1.4228412 0.        0.        0.        0.       ]\n",
            " [0.        0.        0.        0.        0.        0.       ]\n",
            " [0.        0.        0.        0.        0.        0.       ]]\n",
            "Sample y_seq[0]: 14.137595\n",
            "Sample w_seq[0]: 1.0\n",
            "Sample mukim_seq[0]: \n",
            "Fold Suburban RNN RMSE (RM): 129101.96453966144\n",
            "Fold Low-Price (<450k RM) RNN RMSE (RM): 54765.94796038867\n",
            "Fold Very Low-Price (<300k RM) RNN RMSE (RM): 57568.115619672666\n",
            "Created 7359 sequences, X_seq shape: (7359, 3, 6), dtype: float32\n",
            "y_seq shape: (7359,), dtype: float32\n",
            "w_seq shape: (7359,), dtype: float32\n",
            "mukim_seq shape: (7359,), dtype: object\n",
            "Invalid sequences skipped: 0 (0.00%)\n",
            "Sample X_seq[0]:\n",
            " [[0.9568454 1.4228412 0.        0.        0.        0.       ]\n",
            " [0.        0.        0.        0.        0.        0.       ]\n",
            " [0.        0.        0.        0.        0.        0.       ]]\n",
            "Sample y_seq[0]: 14.187075\n",
            "Sample w_seq[0]: 1.0\n",
            "Sample mukim_seq[0]: \n",
            "Created 2403 sequences, X_seq shape: (2403, 3, 6), dtype: float32\n",
            "y_seq shape: (2403,), dtype: float32\n",
            "w_seq shape: (2403,), dtype: float32\n",
            "mukim_seq shape: (2403,), dtype: object\n",
            "Invalid sequences skipped: 0 (0.00%)\n",
            "Sample X_seq[0]:\n",
            " [[ 0.9568454  1.5727204 -1.         0.         0.         0.       ]\n",
            " [ 0.         0.         0.         0.         0.         0.       ]\n",
            " [ 0.         0.         0.         0.         0.         0.       ]]\n",
            "Sample y_seq[0]: 14.384228\n",
            "Sample w_seq[0]: 1.0\n",
            "Sample mukim_seq[0]: \n",
            "Fold Suburban RNN RMSE (RM): 72127.69831347733\n",
            "Fold Low-Price (<450k RM) RNN RMSE (RM): 51576.475878058984\n",
            "Fold Very Low-Price (<300k RM) RNN RMSE (RM): 45891.253720071756\n",
            "Created 7372 sequences, X_seq shape: (7372, 3, 6), dtype: float32\n",
            "y_seq shape: (7372,), dtype: float32\n",
            "w_seq shape: (7372,), dtype: float32\n",
            "mukim_seq shape: (7372,), dtype: object\n",
            "Invalid sequences skipped: 0 (0.00%)\n",
            "Sample X_seq[0]:\n",
            " [[ 0.9568454  1.5727204 -1.         0.         0.         0.       ]\n",
            " [ 0.         0.         0.         0.         0.         0.       ]\n",
            " [ 0.         0.         0.         0.         0.         0.       ]]\n",
            "Sample y_seq[0]: 14.384228\n",
            "Sample w_seq[0]: 1.0\n",
            "Sample mukim_seq[0]: \n",
            "Created 2424 sequences, X_seq shape: (2424, 3, 6), dtype: float32\n",
            "y_seq shape: (2424,), dtype: float32\n",
            "w_seq shape: (2424,), dtype: float32\n",
            "mukim_seq shape: (2424,), dtype: object\n",
            "Invalid sequences skipped: 0 (0.00%)\n",
            "Sample X_seq[0]:\n",
            " [[-0.49121663 -0.6136288  -0.5         0.          0.          0.        ]\n",
            " [ 0.          0.          0.          0.          0.          0.        ]\n",
            " [ 0.          0.          0.          0.          0.          0.        ]]\n",
            "Sample y_seq[0]: 12.782689\n",
            "Sample w_seq[0]: 5.0\n",
            "Sample mukim_seq[0]: \n",
            "Fold Suburban RNN RMSE (RM): 128397.38315090381\n",
            "Fold Low-Price (<450k RM) RNN RMSE (RM): 52068.437426141376\n",
            "Fold Very Low-Price (<300k RM) RNN RMSE (RM): 52542.37512712953\n",
            "Created 7318 sequences, X_seq shape: (7318, 3, 6), dtype: float32\n",
            "y_seq shape: (7318,), dtype: float32\n",
            "w_seq shape: (7318,), dtype: float32\n",
            "mukim_seq shape: (7318,), dtype: object\n",
            "Invalid sequences skipped: 0 (0.00%)\n",
            "Sample X_seq[0]:\n",
            " [[ 0.9568454  1.5727204 -1.         0.         0.         0.       ]\n",
            " [ 0.         0.         0.         0.         0.         0.       ]\n",
            " [ 0.         0.         0.         0.         0.         0.       ]]\n",
            "Sample y_seq[0]: 14.384228\n",
            "Sample w_seq[0]: 1.0\n",
            "Sample mukim_seq[0]: \n",
            "Created 2433 sequences, X_seq shape: (2433, 3, 6), dtype: float32\n",
            "y_seq shape: (2433,), dtype: float32\n",
            "w_seq shape: (2433,), dtype: float32\n",
            "mukim_seq shape: (2433,), dtype: object\n",
            "Invalid sequences skipped: 0 (0.00%)\n",
            "Sample X_seq[0]:\n",
            " [[0.9568454 1.4228412 0.        0.        0.        0.       ]\n",
            " [0.        0.        0.        0.        0.        0.       ]\n",
            " [0.        0.        0.        0.        0.        0.       ]]\n",
            "Sample y_seq[0]: 14.187075\n",
            "Sample w_seq[0]: 1.0\n",
            "Sample mukim_seq[0]: \n",
            "Fold Suburban RNN RMSE (RM): 121141.2018431384\n",
            "Fold Low-Price (<450k RM) RNN RMSE (RM): 52014.40292841974\n",
            "Fold Very Low-Price (<300k RM) RNN RMSE (RM): 51389.65374469846\n",
            "Created 7355 sequences, X_seq shape: (7355, 3, 6), dtype: float32\n",
            "y_seq shape: (7355,), dtype: float32\n",
            "w_seq shape: (7355,), dtype: float32\n",
            "mukim_seq shape: (7355,), dtype: object\n",
            "Invalid sequences skipped: 0 (0.00%)\n",
            "Sample X_seq[0]:\n",
            " [[ 0.9568454  1.5727204 -1.         0.         0.         0.       ]\n",
            " [ 0.         0.         0.         0.         0.         0.       ]\n",
            " [ 0.         0.         0.         0.         0.         0.       ]]\n",
            "Sample y_seq[0]: 14.384228\n",
            "Sample w_seq[0]: 1.0\n",
            "Sample mukim_seq[0]: \n",
            "Created 2422 sequences, X_seq shape: (2422, 3, 6), dtype: float32\n",
            "y_seq shape: (2422,), dtype: float32\n",
            "w_seq shape: (2422,), dtype: float32\n",
            "mukim_seq shape: (2422,), dtype: object\n",
            "Invalid sequences skipped: 0 (0.00%)\n",
            "Sample X_seq[0]:\n",
            " [[-0.49121663 -0.6136288   0.          0.          0.          0.        ]\n",
            " [ 0.          0.          0.          0.          0.          0.        ]\n",
            " [ 0.          0.          0.          0.          0.          0.        ]]\n",
            "Sample y_seq[0]: 12.821261\n",
            "Sample w_seq[0]: 5.0\n",
            "Sample mukim_seq[0]: \n",
            "Fold Suburban RNN RMSE (RM): 92141.67039944523\n",
            "Fold Low-Price (<450k RM) RNN RMSE (RM): 50168.08355917136\n",
            "Fold Very Low-Price (<300k RM) RNN RMSE (RM): 52682.33434463587\n",
            "RNN 5-Fold CV R: 0.8917388200759888  0.022694083077795413\n",
            "Suburban RNN RMSE (RM): 85781.79126131606\n",
            "Low-Price (<450k RM) RNN RMSE (RM): 51447.86751654533\n",
            "Very Low-Price (<300k RM) RNN RMSE (RM): 53053.33407053698\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prediction using RNN Model"
      ],
      "metadata": {
        "id": "EqpRrHEk-RQ6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from tensorflow.keras.models import load_model\n",
        "import joblib\n",
        "\n",
        "# Load saved model and preprocessing objects\n",
        "model = load_model('rnn_model.keras')\n",
        "scaler = joblib.load('scaler.joblib')\n",
        "scheme_encoding = joblib.load('scheme_encoding.joblib')\n",
        "\n",
        "# Define sample input\n",
        "sample_input = {\n",
        "    'SchemeName': 'The Edge',\n",
        "    'ParcelArea': 80.0,  # sq.m\n",
        "    'Year': 2025.0,\n",
        "    'Mukim': 'Mukim Setapak',\n",
        "    'Tenure': 'Freehold',\n",
        "    'UnitLevel': 15\n",
        "}\n",
        "\n",
        "# Preprocessing function to match training pipeline\n",
        "def preprocess_sample(sample, scheme_encoding, scaler, features, price_cap, area_cap):\n",
        "    # Create DataFrame for sample\n",
        "    df_sample = pd.DataFrame([sample])\n",
        "\n",
        "    # Log-transform ParcelArea\n",
        "    df_sample['ParcelArea'] = np.log1p(np.clip(df_sample['ParcelArea'], 0, area_cap)).astype(np.float32)\n",
        "\n",
        "    # Encode SchemeName\n",
        "    df_sample['Scheme_Name_encoded'] = df_sample['SchemeName'].map(scheme_encoding).fillna(scheme_encoding.mean()).astype(np.float32)\n",
        "\n",
        "    # Tenure\n",
        "    df_sample['Tenure'] = df_sample['Tenure'].map({'Freehold': 1, 'Leasehold': 0}).fillna(0).astype(np.float32)\n",
        "\n",
        "    # UnitLevel binning\n",
        "    unit_level_map = {'03A': 4, '12B': 12, '13A': 14, '23A': 24, '33A': 34, '43A': 44, '53A': 54,\n",
        "                      'B': 0, 'D': 0, 'G': 0, 'LG': 0, 'MZ': 0, 'P': 0, 'UG': 0,\n",
        "                      '1/5/2025': 0, '2/3/2025': 0, '1/4/2025': 0}\n",
        "    df_sample['UnitLevel_clean'] = df_sample['UnitLevel'].replace(unit_level_map)\n",
        "    df_sample['UnitLevel_clean'] = pd.to_numeric(df_sample['UnitLevel_clean'], errors='coerce').fillna(10.0).astype(np.float32)\n",
        "    df_sample['UnitLevel_binned'] = pd.cut(df_sample['UnitLevel_clean'], bins=[-float('inf'), 10, 20, float('inf')], labels=['Low', 'Mid', 'High'])\n",
        "    level_dummies = pd.get_dummies(df_sample['UnitLevel_binned'], prefix='UnitLevel', dtype=np.float32)\n",
        "\n",
        "    # Setapak interactions\n",
        "    df_sample['Mukim_Mukim Setapak_Tenure'] = (df_sample['Mukim'].eq('Mukim Setapak').astype(np.float32) * df_sample['Tenure']).astype(np.float32)\n",
        "    df_sample['Mukim_Mukim Setapak_ParcelArea'] = (df_sample['Mukim'].eq('Mukim Setapak').astype(np.float32) * df_sample['ParcelArea']).astype(np.float32)\n",
        "\n",
        "    # Create feature array\n",
        "    X_sample = pd.concat([df_sample[['Scheme_Name_encoded', 'ParcelArea', 'Year']],\n",
        "                          df_sample[['Mukim_Mukim Setapak_Tenure', 'Mukim_Mukim Setapak_ParcelArea']],\n",
        "                          level_dummies[['UnitLevel_High']]], axis=1).astype(np.float32)\n",
        "\n",
        "    # Scale features\n",
        "    X_sample[['Scheme_Name_encoded', 'ParcelArea', 'Year']] = scaler.transform(X_sample[['Scheme_Name_encoded', 'ParcelArea', 'Year']]).astype(np.float32)\n",
        "\n",
        "    return X_sample\n",
        "\n",
        "# Create sequence for RNN (3 timesteps)\n",
        "def create_sample_sequence(X_sample, timesteps=3):\n",
        "    # For a single sample, repeat it to create a sequence (or pad if simulating fewer timesteps)\n",
        "    X_seq = np.repeat(X_sample.values, timesteps, axis=0).reshape(1, timesteps, -1).astype(np.float32)\n",
        "    return X_seq\n",
        "\n",
        "# Training data caps (from previous output)\n",
        "price_cap = 1765999.0  # 90th percentile\n",
        "area_cap = 90.0        # Approximate 90th percentile for ParcelArea\n",
        "\n",
        "# Preprocess sample\n",
        "features = ['Scheme_Name_encoded', 'ParcelArea', 'Year', 'Mukim_Mukim Setapak_Tenure', 'Mukim_Mukim Setapak_ParcelArea', 'UnitLevel_High']\n",
        "X_sample = preprocess_sample(sample_input, scheme_encoding, scaler, features, price_cap, area_cap)\n",
        "\n",
        "# Create sequence\n",
        "X_seq = create_sample_sequence(X_sample)\n",
        "\n",
        "# Predict\n",
        "y_pred_log = model.predict(X_seq, verbose=0).flatten()[0]\n",
        "y_pred_rm = np.expm1(y_pred_log)  # Convert from log-scale to RM\n",
        "\n",
        "# Debug prints\n",
        "print(\"Sample Input:\", sample_input)\n",
        "print(\"Preprocessed X_sample:\\n\", X_sample)\n",
        "print(\"X_seq shape:\", X_seq.shape)\n",
        "print(\"X_seq:\\n\", X_seq)\n",
        "print(\"Predicted TransactionPrice (log-scale):\", y_pred_log)\n",
        "print(\"Predicted TransactionPrice (RM):\", y_pred_rm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xv-JwF2L-VW9",
        "outputId": "70753abf-e9c3-4044-cb25-594342200a89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample Input: {'SchemeName': 'The Edge', 'ParcelArea': 80.0, 'Year': 2025.0, 'Mukim': 'Mukim Setapak', 'Tenure': 'Freehold', 'UnitLevel': 15}\n",
            "Preprocessed X_sample:\n",
            "    Scheme_Name_encoded  ParcelArea  Year  Mukim_Mukim Setapak_Tenure  \\\n",
            "0             0.044883   -0.728349   1.0                         1.0   \n",
            "\n",
            "   Mukim_Mukim Setapak_ParcelArea  UnitLevel_High  \n",
            "0                        4.394449             0.0  \n",
            "X_seq shape: (1, 3, 6)\n",
            "X_seq:\n",
            " [[[ 0.04488303 -0.7283488   1.          1.          4.394449\n",
            "    0.        ]\n",
            "  [ 0.04488303 -0.7283488   1.          1.          4.394449\n",
            "    0.        ]\n",
            "  [ 0.04488303 -0.7283488   1.          1.          4.394449\n",
            "    0.        ]]]\n",
            "Predicted TransactionPrice (log-scale): 12.998993\n",
            "Predicted TransactionPrice (RM): 441967.06\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Compare Basline MLR with LightGBM (BEST)"
      ],
      "metadata": {
        "id": "wgjcahsdKadc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from sklearn.metrics import r2_score, mean_squared_error\n",
        "import lightgbm as lgb\n",
        "import joblib\n",
        "\n",
        "# Load data\n",
        "url = \"https://raw.githubusercontent.com/englian1123/KL-High-Rise-Data/refs/heads/main/KLHighRise.csv\"\n",
        "df = pd.read_csv(url)\n",
        "df.rename(columns={'TransactionPrice  ': 'TransactionPrice', 'Parcel Area': 'ParcelArea', 'Scheme Name/Area': 'SchemeName'}, inplace=True)\n",
        "df['ParcelArea'] = df['ParcelArea'].astype(str).str.extract('(\\d+\\.?\\d*)').astype(np.float32)\n",
        "df['Tenure'] = df['Tenure'].map({'Freehold': 1, 'Leasehold': 0}).fillna(0).astype(np.float32)\n",
        "\n",
        "# Drop low-count Mukims\n",
        "low_count_mukims = ['Mukim Cheras', 'Mukim Ampang', 'Mukim Ulu Kelang']\n",
        "df = df[~df['Mukim'].isin(low_count_mukims)].reset_index(drop=True)\n",
        "\n",
        "# Outlier capping\n",
        "price_cap = df['TransactionPrice'].quantile(0.90)\n",
        "df['TransactionPrice'] = np.clip(df['TransactionPrice'], 0, price_cap).astype(np.float32)\n",
        "area_cap = df['ParcelArea'].quantile(0.90)\n",
        "df['ParcelArea'] = np.clip(df['ParcelArea'], 0, area_cap).astype(np.float32)\n",
        "\n",
        "# Log-transform\n",
        "df['TransactionPrice'] = np.log1p(df['TransactionPrice']).astype(np.float32)\n",
        "df['ParcelArea'] = np.log1p(df['ParcelArea']).astype(np.float32)\n",
        "\n",
        "# Target encode SchemeName\n",
        "scheme_encoding = df.groupby('SchemeName')['TransactionPrice'].mean().astype(np.float32)\n",
        "df['Scheme_Name_encoded'] = df['SchemeName'].map(scheme_encoding).fillna(scheme_encoding.mean()).astype(np.float32)\n",
        "joblib.dump(scheme_encoding, 'scheme_encoding_lightgbm.joblib')\n",
        "\n",
        "# Add Year\n",
        "df['TransactionDate'] = pd.to_datetime(df['TransactionDate'], format='%b-%y')\n",
        "df['Year'] = df['TransactionDate'].dt.year.astype(np.float32)\n",
        "\n",
        "# Clean UnitLevel\n",
        "unit_level_map = {'03A': 4, '12B': 12, '13A': 14, '23A': 24, '33A': 34, '43A': 44, '53A': 54,\n",
        "                  'B': 0, 'D': 0, 'G': 0, 'LG': 0, 'MZ': 0, 'P': 0, 'UG': 0,\n",
        "                  '1/5/2025': 0, '2/3/2025': 0, '1/4/2025': 0}\n",
        "df['UnitLevel_clean'] = df['UnitLevel'].replace(unit_level_map)\n",
        "unit_level_mean = pd.to_numeric(df['UnitLevel_clean'], errors='coerce').mean()\n",
        "df['UnitLevel_clean'] = pd.to_numeric(df['UnitLevel_clean'], errors='coerce').fillna(unit_level_mean).astype(np.float32)\n",
        "df['UnitLevel_binned'] = pd.cut(df['UnitLevel_clean'], bins=[-float('inf'), 10, 20, float('inf')], labels=['Low', 'Mid', 'High'])\n",
        "level_dummies = pd.get_dummies(df['UnitLevel_binned'], prefix='UnitLevel', dtype=np.float32)\n",
        "\n",
        "# Setapak interactions\n",
        "mukim_dummies = pd.get_dummies(df['Mukim'], prefix='Mukim', dtype=np.float32)\n",
        "df['Mukim_Mukim Setapak_Tenure'] = (mukim_dummies.get('Mukim_Mukim Setapak', pd.Series(0, index=df.index)) * df['Tenure']).astype(np.float32)\n",
        "df['Mukim_Mukim Setapak_ParcelArea'] = (mukim_dummies.get('Mukim_Mukim Setapak', pd.Series(0, index=df.index)) * df['ParcelArea']).astype(np.float32)\n",
        "\n",
        "# Features\n",
        "features = ['Scheme_Name_encoded', 'ParcelArea', 'Year', 'Mukim_Mukim Setapak_Tenure', 'Mukim_Mukim Setapak_ParcelArea', 'UnitLevel_High']\n",
        "X = pd.concat([df[['Scheme_Name_encoded', 'ParcelArea', 'Year']],\n",
        "               df[['Mukim_Mukim Setapak_Tenure', 'Mukim_Mukim Setapak_ParcelArea']],\n",
        "               level_dummies[['UnitLevel_High']]], axis=1).astype(np.float32)\n",
        "y = df['TransactionPrice'].astype(np.float32)\n",
        "\n",
        "# Split data\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Scale features\n",
        "scaler = RobustScaler()\n",
        "X_train[['Scheme_Name_encoded', 'ParcelArea', 'Year']] = scaler.fit_transform(X_train[['Scheme_Name_encoded', 'ParcelArea', 'Year']]).astype(np.float32)\n",
        "X_test[['Scheme_Name_encoded', 'ParcelArea', 'Year']] = scaler.transform(X_test[['Scheme_Name_encoded', 'ParcelArea', 'Year']]).astype(np.float32)\n",
        "joblib.dump(scaler, 'scaler_lightgbm.joblib')\n",
        "\n",
        "# Train MLR\n",
        "mlr_model = LinearRegression()\n",
        "mlr_model.fit(X_train, y_train)\n",
        "joblib.dump(mlr_model, 'mlr_model.joblib')\n",
        "\n",
        "# Train LightGBM\n",
        "lgb_train = lgb.Dataset(X_train, label=y_train)\n",
        "lgb_test = lgb.Dataset(X_test, label=y_test, reference=lgb_train)\n",
        "params = {\n",
        "    'objective': 'regression',\n",
        "    'metric': 'rmse',\n",
        "    'num_leaves': 31,\n",
        "    'learning_rate': 0.05,\n",
        "    'feature_fraction': 0.9,\n",
        "    'bagging_fraction': 0.8,\n",
        "    'bagging_freq': 5,\n",
        "    'verbose': -1\n",
        "}\n",
        "lgb_model = lgb.train(params, lgb_train, num_boost_round=100, valid_sets=[lgb_train, lgb_test], callbacks=[lgb.early_stopping(10)])\n",
        "joblib.dump(lgb_model, 'lightgbm_model.joblib')\n",
        "\n",
        "# Evaluate models\n",
        "y_pred_mlr = mlr_model.predict(X_test)\n",
        "mlr_r2 = r2_score(y_test, y_pred_mlr)\n",
        "mlr_rmse_log = np.sqrt(mean_squared_error(y_test, y_pred_mlr))\n",
        "mlr_rmse_rm = np.sqrt(mean_squared_error(np.expm1(y_test), np.expm1(y_pred_mlr)))\n",
        "\n",
        "y_pred_lgb = lgb_model.predict(X_test)\n",
        "lgb_r2 = r2_score(y_test, y_pred_lgb)\n",
        "lgb_rmse_log = np.sqrt(mean_squared_error(y_test, y_pred_lgb))\n",
        "lgb_rmse_rm = np.sqrt(mean_squared_error(np.expm1(y_test), np.expm1(y_pred_lgb)))\n",
        "\n",
        "print(\"MLR R:\", mlr_r2)\n",
        "print(\"MLR RMSE (log-scale):\", mlr_rmse_log)\n",
        "print(\"MLR RMSE (RM):\", mlr_rmse_rm)\n",
        "print(\"LightGBM R:\", lgb_r2)\n",
        "print(\"LightGBM RMSE (log-scale):\", lgb_rmse_log)\n",
        "print(\"LightGBM RMSE (RM):\", lgb_rmse_rm)\n",
        "\n",
        "# Define sample input\n",
        "sample_input = {\n",
        "    'SchemeName': 'The Edge',\n",
        "    'ParcelArea': 80.0,  # sq.m\n",
        "    'Year': 2025.0,\n",
        "    'Mukim': 'Mukim Setapak',\n",
        "    'Tenure': 'Freehold',\n",
        "    'UnitLevel': 15\n",
        "}\n",
        "\n",
        "# Preprocessing function\n",
        "def preprocess_sample(sample, scheme_encoding, scaler, features, price_cap, area_cap, year_max=2025.0):\n",
        "    df_sample = pd.DataFrame([sample])\n",
        "    df_sample['Year'] = np.clip(df_sample['Year'], 2021.0, year_max).astype(np.float32)\n",
        "    print(f\"Year capped to {df_sample['Year'].iloc[0]} (training range: 20212025)\")\n",
        "    df_sample['ParcelArea'] = np.log1p(np.clip(df_sample['ParcelArea'], 0, area_cap)).astype(np.float32)\n",
        "    raw_scheme_encoding = df_sample['SchemeName'].map(scheme_encoding).fillna(scheme_encoding.mean()).astype(np.float32)\n",
        "    print(f\"Raw Scheme_Name_encoded: {raw_scheme_encoding.iloc[0]} (log-scale, mean={scheme_encoding.mean():.4f})\")\n",
        "    df_sample['Scheme_Name_encoded'] = raw_scheme_encoding\n",
        "    df_sample['Tenure'] = df_sample['Tenure'].map({'Freehold': 1, 'Leasehold': 0}).fillna(0).astype(np.float32)\n",
        "    unit_level_map = {'03A': 4, '12B': 12, '13A': 14, '23A': 24, '33A': 34, '43A': 44, '53A': 54,\n",
        "                      'B': 0, 'D': 0, 'G': 0, 'LG': 0, 'MZ': 0, 'P': 0, 'UG': 0,\n",
        "                      '1/5/2025': 0, '2/3/2025': 0, '1/4/2025': 0}\n",
        "    df_sample['UnitLevel_clean'] = df_sample['UnitLevel'].replace(unit_level_map)\n",
        "    df_sample['UnitLevel_clean'] = pd.to_numeric(df_sample['UnitLevel_clean'], errors='coerce').fillna(10.0).astype(np.float32)\n",
        "    df_sample['UnitLevel_binned'] = pd.cut(df_sample['UnitLevel_clean'], bins=[-float('inf'), 10, 20, float('inf')], labels=['Low', 'Mid', 'High'])\n",
        "    print(f\"UnitLevel_clean: {df_sample['UnitLevel_clean'].iloc[0]}, UnitLevel_binned: {df_sample['UnitLevel_binned'].iloc[0]}\")\n",
        "    level_dummies = pd.get_dummies(df_sample['UnitLevel_binned'], prefix='UnitLevel', dtype=np.float32)\n",
        "    if 'UnitLevel_High' not in level_dummies:\n",
        "        level_dummies['UnitLevel_High'] = 0.0\n",
        "    level_dummies = level_dummies[['UnitLevel_High']].astype(np.float32)\n",
        "    df_sample['Mukim_Mukim Setapak_Tenure'] = (df_sample['Mukim'].eq('Mukim Setapak').astype(np.float32) * df_sample['Tenure']).astype(np.float32)\n",
        "    df_sample['Mukim_Mukim Setapak_ParcelArea'] = (df_sample['Mukim'].eq('Mukim Setapak').astype(np.float32) * df_sample['ParcelArea']).astype(np.float32)\n",
        "    X_sample = pd.concat([df_sample[['Scheme_Name_encoded', 'ParcelArea', 'Year']],\n",
        "                          df_sample[['Mukim_Mukim Setapak_Tenure', 'Mukim_Mukim Setapak_ParcelArea']],\n",
        "                          level_dummies[['UnitLevel_High']]], axis=1).astype(np.float32)\n",
        "    X_sample[['Scheme_Name_encoded', 'ParcelArea', 'Year']] = scaler.transform(X_sample[['Scheme_Name_encoded', 'ParcelArea', 'Year']]).astype(np.float32)\n",
        "    return X_sample\n",
        "\n",
        "# Preprocess sample\n",
        "price_cap = 1765999.0\n",
        "area_cap = 90.0\n",
        "features = ['Scheme_Name_encoded', 'ParcelArea', 'Year', 'Mukim_Mukim Setapak_Tenure', 'Mukim_Mukim Setapak_ParcelArea', 'UnitLevel_High']\n",
        "X_sample = preprocess_sample(sample_input, scheme_encoding, scaler, features, price_cap, area_cap)\n",
        "\n",
        "# Predict with MLR and LightGBM\n",
        "y_pred_mlr_log = mlr_model.predict(X_sample).flatten()[0]\n",
        "y_pred_mlr_rm = np.expm1(y_pred_mlr_log)\n",
        "y_pred_lgb_log = lgb_model.predict(X_sample).flatten()[0]\n",
        "y_pred_lgb_rm = np.expm1(y_pred_lgb_log)\n",
        "\n",
        "# Print comparison\n",
        "print(\"\\nSample Input:\", sample_input)\n",
        "print(\"Preprocessed X_sample:\\n\", X_sample)\n",
        "print(\"MLR Predicted TransactionPrice (log-scale):\", y_pred_mlr_log)\n",
        "print(\"MLR Predicted TransactionPrice (RM):\", y_pred_mlr_rm)\n",
        "print(\"LightGBM Predicted TransactionPrice (log-scale):\", y_pred_lgb_log)\n",
        "print(\"LightGBM Predicted TransactionPrice (RM):\", y_pred_lgb_rm)\n",
        "print(\"Difference (MLR - LightGBM, RM):\", y_pred_mlr_rm - y_pred_lgb_rm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KPsFT4D5Kezm",
        "outputId": "8b100bb5-746b-49be-e9a5-0f8e9ae8ac91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<>:13: SyntaxWarning: invalid escape sequence '\\d'\n",
            "<>:13: SyntaxWarning: invalid escape sequence '\\d'\n",
            "/tmp/ipython-input-1945332030.py:13: SyntaxWarning: invalid escape sequence '\\d'\n",
            "  df['ParcelArea'] = df['ParcelArea'].astype(str).str.extract('(\\d+\\.?\\d*)').astype(np.float32)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training until validation scores don't improve for 10 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\ttraining's rmse: 0.127597\tvalid_1's rmse: 0.136025\n",
            "MLR R: 0.921079158782959\n",
            "MLR RMSE (log-scale): 0.17053568897268526\n",
            "MLR RMSE (RM): 138014.02270783935\n",
            "LightGBM R: 0.9497888620314612\n",
            "LightGBM RMSE (log-scale): 0.1360252233001447\n",
            "LightGBM RMSE (RM): 104946.88341715561\n",
            "Year capped to 2025.0 (training range: 20212025)\n",
            "Raw Scheme_Name_encoded: 13.267335891723633 (log-scale, mean=13.2673)\n",
            "UnitLevel_clean: 15.0, UnitLevel_binned: Mid\n",
            "\n",
            "Sample Input: {'SchemeName': 'The Edge', 'ParcelArea': 80.0, 'Year': 2025.0, 'Mukim': 'Mukim Setapak', 'Tenure': 'Freehold', 'UnitLevel': 15}\n",
            "Preprocessed X_sample:\n",
            "    Scheme_Name_encoded  ParcelArea  Year  Mukim_Mukim Setapak_Tenure  \\\n",
            "0             0.077558   -0.728349   1.0                         1.0   \n",
            "\n",
            "   Mukim_Mukim Setapak_ParcelArea  UnitLevel_High  \n",
            "0                        4.394449             0.0  \n",
            "MLR Predicted TransactionPrice (log-scale): 13.13234\n",
            "MLR Predicted TransactionPrice (RM): 505012.5\n",
            "LightGBM Predicted TransactionPrice (log-scale): 13.102156824081552\n",
            "LightGBM Predicted TransactionPrice (RM): 489997.115461048\n",
            "Difference (MLR - LightGBM, RM): 15015.384538952028\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Compare SVR with LightGBM (BEST)"
      ],
      "metadata": {
        "id": "eTCtJl7lN8Lt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from sklearn.metrics import r2_score, mean_squared_error\n",
        "import lightgbm as lgb\n",
        "import joblib\n",
        "\n",
        "# Load data\n",
        "url = \"https://raw.githubusercontent.com/englian1123/KL-High-Rise-Data/refs/heads/main/KLHighRise.csv\"\n",
        "df = pd.read_csv(url)\n",
        "df.rename(columns={'TransactionPrice  ': 'TransactionPrice', 'Parcel Area': 'ParcelArea', 'Scheme Name/Area': 'SchemeName'}, inplace=True)\n",
        "df['ParcelArea'] = df['ParcelArea'].astype(str).str.extract('(\\d+\\.?\\d*)').astype(np.float32)\n",
        "df['Tenure'] = df['Tenure'].map({'Freehold': 1, 'Leasehold': 0}).fillna(0).astype(np.float32)\n",
        "\n",
        "# Outlier capping\n",
        "price_cap = df['TransactionPrice'].quantile(0.90)\n",
        "df['TransactionPrice'] = np.clip(df['TransactionPrice'], 0, price_cap).astype(np.float32)\n",
        "area_cap = df['ParcelArea'].quantile(0.90)\n",
        "df['ParcelArea'] = np.clip(df['ParcelArea'], 0, area_cap).astype(np.float32)\n",
        "\n",
        "# Log-transform\n",
        "df['TransactionPrice'] = np.log1p(df['TransactionPrice']).astype(np.float32)\n",
        "df['ParcelArea'] = np.log1p(df['ParcelArea']).astype(np.float32)\n",
        "\n",
        "# Target encode SchemeName\n",
        "scheme_encoding = df.groupby('SchemeName')['TransactionPrice'].mean().astype(np.float32)\n",
        "df['Scheme_Name_encoded'] = df['SchemeName'].map(scheme_encoding).fillna(scheme_encoding.mean()).astype(np.float32)\n",
        "joblib.dump(scheme_encoding, 'scheme_encoding_compare_v1.joblib')\n",
        "\n",
        "# Add Year\n",
        "df['TransactionDate'] = pd.to_datetime(df['TransactionDate'], format='%b-%y')\n",
        "df['Year'] = df['TransactionDate'].dt.year.astype(np.float32)\n",
        "\n",
        "# Clean UnitLevel\n",
        "unit_level_map = {'03A': 4, '12B': 12, '13A': 14, '23A': 24, '33A': 34, '43A': 44, '53A': 54,\n",
        "                  'B': 0, 'D': 0, 'G': 0, 'LG': 0, 'MZ': 0, 'P': 0, 'UG': 0,\n",
        "                  '1/5/2025': 0, '2/3/2025': 0, '1/4/2025': 0}\n",
        "df['UnitLevel_clean'] = df['UnitLevel'].replace(unit_level_map)\n",
        "unit_level_mean = pd.to_numeric(df['UnitLevel_clean'], errors='coerce').mean()\n",
        "df['UnitLevel_clean'] = pd.to_numeric(df['UnitLevel_clean'], errors='coerce').fillna(unit_level_mean).astype(np.float32)\n",
        "df['UnitLevel_binned'] = pd.cut(df['UnitLevel_clean'], bins=[-float('inf'), 10, 20, float('inf')], labels=['Low', 'Mid', 'High'])\n",
        "level_dummies = pd.get_dummies(df['UnitLevel_binned'], prefix='UnitLevel', dtype=np.float32)\n",
        "\n",
        "# Setapak interactions\n",
        "mukim_dummies = pd.get_dummies(df['Mukim'], prefix='Mukim', dtype=np.float32)\n",
        "df['Mukim_Mukim Setapak_Tenure'] = (mukim_dummies.get('Mukim_Mukim Setapak', pd.Series(0, index=df.index)) * df['Tenure']).astype(np.float32)\n",
        "df['Mukim_Mukim Setapak_ParcelArea'] = (mukim_dummies.get('Mukim_Mukim Setapak', pd.Series(0, index=df.index)) * df['ParcelArea']).astype(np.float32)\n",
        "\n",
        "# Features\n",
        "features = ['Scheme_Name_encoded', 'ParcelArea', 'Year', 'Mukim_Mukim Setapak_Tenure', 'Mukim_Mukim Setapak_ParcelArea', 'UnitLevel_High']\n",
        "X = pd.concat([df[['Scheme_Name_encoded', 'ParcelArea', 'Year']],\n",
        "               df[['Mukim_Mukim Setapak_Tenure', 'Mukim_Mukim Setapak_ParcelArea']],\n",
        "               level_dummies[['UnitLevel_High']]], axis=1).astype(np.float32)\n",
        "y = df['TransactionPrice'].astype(np.float32)\n",
        "\n",
        "# Split data\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Scale features\n",
        "scaler = RobustScaler()\n",
        "X_train[['Scheme_Name_encoded', 'ParcelArea', 'Year']] = scaler.fit_transform(X_train[['Scheme_Name_encoded', 'ParcelArea', 'Year']]).astype(np.float32)\n",
        "X_test[['Scheme_Name_encoded', 'ParcelArea', 'Year']] = scaler.transform(X_test[['Scheme_Name_encoded', 'ParcelArea', 'Year']]).astype(np.float32)\n",
        "joblib.dump(scaler, 'scaler_compare_v1.joblib')\n",
        "\n",
        "# Train MLR\n",
        "mlr_model = LinearRegression()\n",
        "mlr_model.fit(X_train, y_train)\n",
        "joblib.dump(mlr_model, 'mlr_model_v1.joblib')\n",
        "\n",
        "# Train LightGBM\n",
        "lgb_train = lgb.Dataset(X_train, label=y_train)\n",
        "lgb_test = lgb.Dataset(X_test, label=y_test, reference=lgb_train)\n",
        "params = {\n",
        "    'objective': 'regression',\n",
        "    'metric': 'rmse',\n",
        "    'num_leaves': 50,\n",
        "    'learning_rate': 0.01,\n",
        "    'feature_fraction': 0.9,\n",
        "    'bagging_fraction': 0.8,\n",
        "    'bagging_freq': 5,\n",
        "    'min_data_in_leaf': 20,\n",
        "    'verbose': -1\n",
        "}\n",
        "lgb_model = lgb.train(params, lgb_train, num_boost_round=500, valid_sets=[lgb_train, lgb_test], callbacks=[lgb.early_stopping(10)])\n",
        "joblib.dump(lgb_model, 'lightgbm_model_v1.joblib')\n",
        "\n",
        "# Train SVR\n",
        "svr_model = SVR(kernel='rbf', C=1.0, epsilon=0.1, gamma='scale')\n",
        "svr_model.fit(X_train, y_train)\n",
        "joblib.dump(svr_model, 'svr_model_v1.joblib')\n",
        "\n",
        "# Evaluate models\n",
        "y_pred_mlr = mlr_model.predict(X_test)\n",
        "mlr_r2 = r2_score(y_test, y_pred_mlr)\n",
        "mlr_rmse_log = np.sqrt(mean_squared_error(y_test, y_pred_mlr))\n",
        "mlr_rmse_rm = np.sqrt(mean_squared_error(np.expm1(y_test), np.expm1(y_pred_mlr)))\n",
        "\n",
        "y_pred_lgb = lgb_model.predict(X_test)\n",
        "lgb_r2 = r2_score(y_test, y_pred_lgb)\n",
        "lgb_rmse_log = np.sqrt(mean_squared_error(y_test, y_pred_lgb))\n",
        "lgb_rmse_rm = np.sqrt(mean_squared_error(np.expm1(y_test), np.expm1(y_pred_lgb)))\n",
        "\n",
        "y_pred_svr = svr_model.predict(X_test)\n",
        "svr_r2 = r2_score(y_test, y_pred_svr)\n",
        "svr_rmse_log = np.sqrt(mean_squared_error(y_test, y_pred_svr))\n",
        "svr_rmse_rm = np.sqrt(mean_squared_error(np.expm1(y_test), np.expm1(y_pred_svr)))\n",
        "\n",
        "print(\"MLR R:\", mlr_r2)\n",
        "print(\"MLR RMSE (log-scale):\", mlr_rmse_log)\n",
        "print(\"MLR RMSE (RM):\", mlr_rmse_rm)\n",
        "print(\"LightGBM R:\", lgb_r2)\n",
        "print(\"LightGBM RMSE (log-scale):\", lgb_rmse_log)\n",
        "print(\"LightGBM RMSE (RM):\", lgb_rmse_rm)\n",
        "print(\"SVR R:\", svr_r2)\n",
        "print(\"SVR RMSE (log-scale):\", svr_rmse_log)\n",
        "print(\"SVR RMSE (RM):\", svr_rmse_rm)\n",
        "\n",
        "# Define sample inputs\n",
        "sample_inputs = [\n",
        "    {'SchemeName': 'The Edge', 'ParcelArea': 80.0, 'Year': 2025.0, 'Mukim': 'Mukim Setapak', 'Tenure': 'Freehold', 'UnitLevel': 15},\n",
        "    {'SchemeName': 'The Edge', 'ParcelArea': 80.0, 'Year': 2025.0, 'Mukim': 'Mukim Setapak', 'Tenure': 'Freehold', 'UnitLevel': 25}\n",
        "]\n",
        "\n",
        "# Preprocessing function\n",
        "def preprocess_sample(sample, scheme_encoding, scaler, features, price_cap, area_cap, year_max=2025.0):\n",
        "    df_sample = pd.DataFrame([sample])\n",
        "    df_sample['Year'] = np.clip(df_sample['Year'], 2021.0, year_max).astype(np.float32)\n",
        "    print(f\"\\nSample: {sample}\")\n",
        "    print(f\"Year capped to {df_sample['Year'].iloc[0]} (training range: 20212025)\")\n",
        "    df_sample['ParcelArea'] = np.log1p(np.clip(df_sample['ParcelArea'], 0, area_cap)).astype(np.float32)\n",
        "    raw_scheme_encoding = df_sample['SchemeName'].map(scheme_encoding).fillna(scheme_encoding.mean()).astype(np.float32)\n",
        "    print(f\"Raw Scheme_Name_encoded: {raw_scheme_encoding.iloc[0]} (log-scale, mean={scheme_encoding.mean():.4f})\")\n",
        "    df_sample['Scheme_Name_encoded'] = raw_scheme_encoding\n",
        "    df_sample['Tenure'] = df_sample['Tenure'].map({'Freehold': 1, 'Leasehold': 0}).fillna(0).astype(np.float32)\n",
        "    unit_level_map = {'03A': 4, '12B': 12, '13A': 14, '23A': 24, '33A': 34, '43A': 44, '53A': 54,\n",
        "                      'B': 0, 'D': 0, 'G': 0, 'LG': 0, 'MZ': 0, 'P': 0, 'UG': 0,\n",
        "                      '1/5/2025': 0, '2/3/2025': 0, '1/4/2025': 0}\n",
        "    df_sample['UnitLevel_clean'] = df_sample['UnitLevel'].replace(unit_level_map)\n",
        "    df_sample['UnitLevel_clean'] = pd.to_numeric(df_sample['UnitLevel_clean'], errors='coerce').fillna(10.0).astype(np.float32)\n",
        "    df_sample['UnitLevel_binned'] = pd.cut(df_sample['UnitLevel_clean'], bins=[-float('inf'), 10, 20, float('inf')], labels=['Low', 'Mid', 'High'])\n",
        "    print(f\"UnitLevel_clean: {df_sample['UnitLevel_clean'].iloc[0]}, UnitLevel_binned: {df_sample['UnitLevel_binned'].iloc[0]}\")\n",
        "    level_dummies = pd.get_dummies(df_sample['UnitLevel_binned'], prefix='UnitLevel', dtype=np.float32)\n",
        "    if 'UnitLevel_High' not in level_dummies:\n",
        "        level_dummies['UnitLevel_High'] = 0.0\n",
        "    level_dummies = level_dummies[['UnitLevel_High']].astype(np.float32)\n",
        "    df_sample['Mukim_Mukim Setapak_Tenure'] = (df_sample['Mukim'].eq('Mukim Setapak').astype(np.float32) * df_sample['Tenure']).astype(np.float32)\n",
        "    df_sample['Mukim_Mukim Setapak_ParcelArea'] = (df_sample['Mukim'].eq('Mukim Setapak').astype(np.float32) * df_sample['ParcelArea']).astype(np.float32)\n",
        "    X_sample = pd.concat([df_sample[['Scheme_Name_encoded', 'ParcelArea', 'Year']],\n",
        "                          df_sample[['Mukim_Mukim Setapak_Tenure', 'Mukim_Mukim Setapak_ParcelArea']],\n",
        "                          level_dummies[['UnitLevel_High']]], axis=1).astype(np.float32)\n",
        "    X_sample[['Scheme_Name_encoded', 'ParcelArea', 'Year']] = scaler.transform(X_sample[['Scheme_Name_encoded', 'ParcelArea', 'Year']]).astype(np.float32)\n",
        "    return X_sample\n",
        "\n",
        "# Predict for both inputs\n",
        "price_cap = 1765999.0\n",
        "area_cap = 90.0\n",
        "features = ['Scheme_Name_encoded', 'ParcelArea', 'Year', 'Mukim_Mukim Setapak_Tenure', 'Mukim_Mukim Setapak_ParcelArea', 'UnitLevel_High']\n",
        "for sample in sample_inputs:\n",
        "    X_sample = preprocess_sample(sample, scheme_encoding, scaler, features, price_cap, area_cap)\n",
        "    y_pred_mlr_log = mlr_model.predict(X_sample).flatten()[0]\n",
        "    y_pred_mlr_rm = np.expm1(y_pred_mlr_log)\n",
        "    y_pred_lgb_log = lgb_model.predict(X_sample).flatten()[0]\n",
        "    y_pred_lgb_rm = np.expm1(y_pred_lgb_log)\n",
        "    y_pred_svr_log = svr_model.predict(X_sample).flatten()[0]\n",
        "    y_pred_svr_rm = np.expm1(y_pred_svr_log)\n",
        "    print(\"Preprocessed X_sample:\\n\", X_sample)\n",
        "    print(\"MLR Predicted TransactionPrice (log-scale):\", y_pred_mlr_log)\n",
        "    print(\"MLR Predicted TransactionPrice (RM):\", y_pred_mlr_rm)\n",
        "    print(\"LightGBM Predicted TransactionPrice (log-scale):\", y_pred_lgb_log)\n",
        "    print(\"LightGBM Predicted TransactionPrice (RM):\", y_pred_lgb_rm)\n",
        "    print(\"SVR Predicted TransactionPrice (log-scale):\", y_pred_svr_log)\n",
        "    print(\"SVR Predicted TransactionPrice (RM):\", y_pred_svr_rm)\n",
        "    print(\"Difference (MLR - LightGBM, RM):\", y_pred_mlr_rm - y_pred_lgb_rm)\n",
        "    print(\"Difference (MLR - SVR, RM):\", y_pred_mlr_rm - y_pred_svr_rm)\n",
        "    print(\"Difference (LightGBM - SVR, RM):\", y_pred_lgb_rm - y_pred_svr_rm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AXyfI_tXOH7q",
        "outputId": "394df4f3-0d73-4990-8862-222f8a459059"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<>:14: SyntaxWarning: invalid escape sequence '\\d'\n",
            "<>:14: SyntaxWarning: invalid escape sequence '\\d'\n",
            "/tmp/ipython-input-637501855.py:14: SyntaxWarning: invalid escape sequence '\\d'\n",
            "  df['ParcelArea'] = df['ParcelArea'].astype(str).str.extract('(\\d+\\.?\\d*)').astype(np.float32)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training until validation scores don't improve for 10 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[500]\ttraining's rmse: 0.124202\tvalid_1's rmse: 0.128833\n",
            "MLR R: 0.9245739579200745\n",
            "MLR RMSE (log-scale): 0.17010225390331987\n",
            "MLR RMSE (RM): 132923.9171255497\n",
            "LightGBM R: 0.956733055218318\n",
            "LightGBM RMSE (log-scale): 0.1288331175606285\n",
            "LightGBM RMSE (RM): 97149.46362172888\n",
            "SVR R: 0.9362402669698674\n",
            "SVR RMSE (log-scale): 0.15639492151723566\n",
            "SVR RMSE (RM): 118371.04526433026\n",
            "\n",
            "Sample: {'SchemeName': 'The Edge', 'ParcelArea': 80.0, 'Year': 2025.0, 'Mukim': 'Mukim Setapak', 'Tenure': 'Freehold', 'UnitLevel': 15}\n",
            "Year capped to 2025.0 (training range: 20212025)\n",
            "Raw Scheme_Name_encoded: 13.261866569519043 (log-scale, mean=13.2619)\n",
            "UnitLevel_clean: 15.0, UnitLevel_binned: Mid\n",
            "Preprocessed X_sample:\n",
            "    Scheme_Name_encoded  ParcelArea  Year  Mukim_Mukim Setapak_Tenure  \\\n",
            "0             0.080807   -0.728349   1.0                         1.0   \n",
            "\n",
            "   Mukim_Mukim Setapak_ParcelArea  UnitLevel_High  \n",
            "0                        4.394449             0.0  \n",
            "MLR Predicted TransactionPrice (log-scale): 13.139416\n",
            "MLR Predicted TransactionPrice (RM): 508598.28\n",
            "LightGBM Predicted TransactionPrice (log-scale): 13.118692561749686\n",
            "LightGBM Predicted TransactionPrice (RM): 498166.9567763656\n",
            "SVR Predicted TransactionPrice (log-scale): 13.09595906062074\n",
            "SVR Predicted TransactionPrice (RM): 486969.6146033656\n",
            "Difference (MLR - LightGBM, RM): 10431.32447363442\n",
            "Difference (MLR - SVR, RM): 21628.666646634403\n",
            "Difference (LightGBM - SVR, RM): 11197.342172999983\n",
            "\n",
            "Sample: {'SchemeName': 'The Edge', 'ParcelArea': 80.0, 'Year': 2025.0, 'Mukim': 'Mukim Setapak', 'Tenure': 'Freehold', 'UnitLevel': 25}\n",
            "Year capped to 2025.0 (training range: 20212025)\n",
            "Raw Scheme_Name_encoded: 13.261866569519043 (log-scale, mean=13.2619)\n",
            "UnitLevel_clean: 25.0, UnitLevel_binned: High\n",
            "Preprocessed X_sample:\n",
            "    Scheme_Name_encoded  ParcelArea  Year  Mukim_Mukim Setapak_Tenure  \\\n",
            "0             0.080807   -0.728349   1.0                         1.0   \n",
            "\n",
            "   Mukim_Mukim Setapak_ParcelArea  UnitLevel_High  \n",
            "0                        4.394449             1.0  \n",
            "MLR Predicted TransactionPrice (log-scale): 13.189443\n",
            "MLR Predicted TransactionPrice (RM): 534689.1\n",
            "LightGBM Predicted TransactionPrice (log-scale): 13.172391017346682\n",
            "LightGBM Predicted TransactionPrice (RM): 525649.0769250484\n",
            "SVR Predicted TransactionPrice (log-scale): 13.16281511730386\n",
            "SVR Predicted TransactionPrice (RM): 520639.5280807597\n",
            "Difference (MLR - LightGBM, RM): 9040.048074951628\n",
            "Difference (MLR - SVR, RM): 14049.596919240314\n",
            "Difference (LightGBM - SVR, RM): 5009.548844288685\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RNN Vs GRU Vs TRANSFORMER"
      ],
      "metadata": {
        "id": "IgAXLRdjSYiS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from sklearn.metrics import r2_score, mean_squared_error\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, SimpleRNN, GRU, Dense, Layer, MultiHeadAttention, LayerNormalization, Dropout\n",
        "import joblib\n",
        "\n",
        "# Load data\n",
        "url = \"https://raw.githubusercontent.com/englian1123/KL-High-Rise-Data/refs/heads/main/KLHighRise.csv\"\n",
        "df = pd.read_csv(url)\n",
        "df.rename(columns={'TransactionPrice  ': 'TransactionPrice', 'Parcel Area': 'ParcelArea', 'Scheme Name/Area': 'SchemeName'}, inplace=True)\n",
        "df['ParcelArea'] = df['ParcelArea'].astype(str).str.extract('(\\d+\\.?\\d*)').astype(np.float32)\n",
        "df['Tenure'] = df['Tenure'].map({'Freehold': 1, 'Leasehold': 0}).fillna(0).astype(np.float32)\n",
        "\n",
        "# Outlier capping (only ParcelArea)\n",
        "area_cap = df['ParcelArea'].quantile(0.90)\n",
        "df['ParcelArea'] = np.clip(df['ParcelArea'], 0, area_cap).astype(np.float32)\n",
        "\n",
        "# Log-transform\n",
        "df['TransactionPrice'] = np.log1p(df['TransactionPrice']).astype(np.float32)\n",
        "df['ParcelArea'] = np.log1p(df['ParcelArea']).astype(np.float32)\n",
        "\n",
        "# Target encode SchemeName\n",
        "scheme_encoding = df.groupby('SchemeName')['TransactionPrice'].mean().astype(np.float32)\n",
        "df['Scheme_Name_encoded'] = df['SchemeName'].map(scheme_encoding).fillna(scheme_encoding.mean()).astype(np.float32)\n",
        "joblib.dump(scheme_encoding, 'scheme_encoding_rnn_gru_transformer_v1.joblib')\n",
        "\n",
        "# Add Year\n",
        "df['TransactionDate'] = pd.to_datetime(df['TransactionDate'], format='%b-%y')\n",
        "df['Year'] = df['TransactionDate'].dt.year.astype(np.float32)\n",
        "\n",
        "# Clean UnitLevel\n",
        "unit_level_map = {'03A': 4, '12B': 12, '13A': 14, '23A': 24, '33A': 34, '43A': 44, '53A': 54,\n",
        "                  'B': 0, 'D': 0, 'G': 0, 'LG': 0, 'MZ': 0, 'P': 0, 'UG': 0,\n",
        "                  '1/5/2025': 0, '2/3/2025': 0, '1/4/2025': 0}\n",
        "df['UnitLevel_clean'] = df['UnitLevel'].replace(unit_level_map)\n",
        "unit_level_mean = pd.to_numeric(df['UnitLevel_clean'], errors='coerce').mean()\n",
        "df['UnitLevel_clean'] = pd.to_numeric(df['UnitLevel_clean'], errors='coerce').fillna(unit_level_mean).astype(np.float32)\n",
        "df['UnitLevel_binned'] = pd.cut(df['UnitLevel_clean'], bins=[-float('inf'), 5, 15, 25, float('inf')], labels=['Low', 'Mid-Low', 'Mid-High', 'High'])\n",
        "level_dummies = pd.get_dummies(df['UnitLevel_binned'], prefix='UnitLevel', dtype=np.float32)\n",
        "\n",
        "# Setapak interactions\n",
        "mukim_dummies = pd.get_dummies(df['Mukim'], prefix='Mukim', dtype=np.float32)\n",
        "df['Mukim_Mukim Setapak_Tenure'] = (mukim_dummies.get('Mukim_Mukim Setapak', pd.Series(0, index=df.index)) * df['Tenure']).astype(np.float32)\n",
        "df['Mukim_Mukim Setapak_ParcelArea'] = (mukim_dummies.get('Mukim_Mukim Setapak', pd.Series(0, index=df.index)) * df['ParcelArea']).astype(np.float32)\n",
        "df['ParcelArea_UnitLevel'] = (df['ParcelArea'] * df['UnitLevel_clean']).astype(np.float32)\n",
        "\n",
        "# Features\n",
        "features = ['Scheme_Name_encoded', 'ParcelArea', 'Year', 'Mukim_Mukim Setapak_Tenure', 'Mukim_Mukim Setapak_ParcelArea', 'UnitLevel_Mid-High', 'UnitLevel_High', 'ParcelArea_UnitLevel']\n",
        "X = pd.concat([df[['Scheme_Name_encoded', 'ParcelArea', 'Year', 'ParcelArea_UnitLevel']],\n",
        "               df[['Mukim_Mukim Setapak_Tenure', 'Mukim_Mukim Setapak_ParcelArea']],\n",
        "               level_dummies[['UnitLevel_Mid-High', 'UnitLevel_High']]], axis=1).astype(np.float32)\n",
        "y = df['TransactionPrice'].astype(np.float32)\n",
        "\n",
        "# Create sequences (3 timesteps)\n",
        "sequence_length = 3\n",
        "X_seq = []\n",
        "y_seq = []\n",
        "# Keep track of the original index for each sequence\n",
        "original_indices = []\n",
        "for idx in range(len(X)):\n",
        "    year = int(X.iloc[idx]['Year'])\n",
        "    sample = X.iloc[idx][features].values\n",
        "    seq = np.zeros((sequence_length, len(features)), dtype=np.float32)\n",
        "    seq[-1] = sample  # Current year\n",
        "    for t in range(1, sequence_length):\n",
        "        if year - t >= 2021:\n",
        "            seq[sequence_length - t - 1] = sample.copy()\n",
        "            seq[sequence_length - t - 1][2] = (year - t - 2023) / 2.0  # Scale Year\n",
        "    X_seq.append(seq)\n",
        "    y_seq.append(y.iloc[idx])\n",
        "    original_indices.append(X.index[idx])  # Store the original index\n",
        "\n",
        "X_seq = np.array(X_seq)\n",
        "y_seq = np.array(y_seq)\n",
        "original_indices = np.array(original_indices) # Convert to numpy array\n",
        "\n",
        "# Split data - use original_indices to split df correctly\n",
        "from sklearn.model_selection import train_test_split\n",
        "train_indices, test_indices, y_train, y_test = train_test_split(original_indices, y_seq, test_size=0.2, random_state=42)\n",
        "\n",
        "# Use the indices to get the corresponding sequences from X_seq\n",
        "X_train = X_seq[np.isin(original_indices, train_indices)]\n",
        "X_test = X_seq[np.isin(original_indices, test_indices)]\n",
        "\n",
        "\n",
        "# Scale features\n",
        "scaler = RobustScaler()\n",
        "for t in range(sequence_length):\n",
        "    X_train[:, t, [0, 1, 2, 7]] = scaler.fit_transform(X_train[:, t, [0, 1, 2, 7]]).astype(np.float32)\n",
        "    X_test[:, t, [0, 1, 2, 7]] = scaler.transform(X_test[:, t, [0, 1, 2, 7]]).astype(np.float32)\n",
        "joblib.dump(scaler, 'scaler_rnn_gru_transformer_v1.joblib')\n",
        "\n",
        "# RNN Model\n",
        "inputs = Input(shape=(sequence_length, len(features)))\n",
        "x = SimpleRNN(32, return_sequences=False)(inputs)\n",
        "x = Dense(16, activation='relu')(x)\n",
        "outputs = Dense(1)(x)\n",
        "rnn_model = Model(inputs, outputs)\n",
        "rnn_model.compile(optimizer='rmsprop', loss='mse')\n",
        "rnn_model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, y_test),\n",
        "              callbacks=[tf.keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)], verbose=0)\n",
        "joblib.dump(rnn_model, 'rnn_model_v1.joblib')\n",
        "\n",
        "# GRU Model\n",
        "x = GRU(32, return_sequences=False)(inputs)\n",
        "x = Dense(16, activation='relu')(x)\n",
        "outputs = Dense(1)(x)\n",
        "gru_model = Model(inputs, outputs)\n",
        "gru_model.compile(optimizer='rmsprop', loss='mse')\n",
        "gru_model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, y_test),\n",
        "              callbacks=[tf.keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)], verbose=0)\n",
        "joblib.dump(gru_model, 'gru_model_v1.joblib')\n",
        "\n",
        "# Transformer Model\n",
        "class TransformerBlock(Layer):\n",
        "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
        "        super(TransformerBlock, self).__init__()\n",
        "        self.att = MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.ffn = tf.keras.Sequential([Dense(ff_dim, activation='relu'), Dense(embed_dim)])\n",
        "        self.layernorm1 = LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = LayerNormalization(epsilon=1e-6)\n",
        "        self.dropout1 = Dropout(rate)\n",
        "        self.dropout2 = Dropout(rate)\n",
        "    def call(self, inputs, training=False): # Added training=False\n",
        "        attn_output = self.att(inputs, inputs)\n",
        "        attn_output = self.dropout1(attn_output, training=training)\n",
        "        out1 = self.layernorm1(inputs + attn_output)\n",
        "        ffn_output = self.ffn(out1)\n",
        "        ffn_output = self.dropout2(ffn_output, training=training)\n",
        "        return self.layernorm2(out1 + ffn_output)\n",
        "\n",
        "class PositionalEncoding(Layer):\n",
        "    def __init__(self, sequence_length, embed_dim):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        pos_enc = np.array([[pos / np.power(10000, 2 * (i // 2) / embed_dim) for i in range(embed_dim)] for pos in range(sequence_length)])\n",
        "        pos_enc[:, 0::2] = np.sin(pos_enc[:, 0::2])\n",
        "        pos_enc[:, 1::2] = np.cos(pos_enc[:, 1::2])\n",
        "        self.pos_encoding = tf.cast(pos_enc, dtype=tf.float32)\n",
        "    def call(self, inputs):\n",
        "        return inputs + self.pos_encoding\n",
        "\n",
        "inputs = Input(shape=(sequence_length, len(features)))\n",
        "x = PositionalEncoding(sequence_length, len(features))(inputs)\n",
        "x = TransformerBlock(embed_dim=len(features), num_heads=2, ff_dim=32)(x)\n",
        "x = tf.keras.layers.GlobalAveragePooling1D()(x)\n",
        "x = Dense(16, activation='relu')(x)\n",
        "outputs = Dense(1)(x)\n",
        "transformer_model = Model(inputs, outputs)\n",
        "transformer_model.compile(optimizer='rmsprop', loss='mse')\n",
        "transformer_model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, y_test),\n",
        "                     callbacks=[tf.keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)], verbose=0)\n",
        "joblib.dump(transformer_model, 'transformer_model_v1.joblib')\n",
        "\n",
        "# Evaluate models\n",
        "y_pred_rnn = rnn_model.predict(X_test, verbose=0).flatten()\n",
        "rnn_r2 = r2_score(y_test, y_pred_rnn)\n",
        "rnn_rmse_log = np.sqrt(mean_squared_error(y_test, y_pred_rnn))\n",
        "rnn_rmse_rm = np.sqrt(mean_squared_error(np.expm1(y_test), np.expm1(y_pred_rnn)))\n",
        "\n",
        "y_pred_gru = gru_model.predict(X_test, verbose=0).flatten()\n",
        "gru_r2 = r2_score(y_test, y_pred_gru)\n",
        "gru_rmse_log = np.sqrt(mean_squared_error(y_test, y_pred_gru))\n",
        "gru_rmse_rm = np.sqrt(mean_squared_error(np.expm1(y_test), np.expm1(y_pred_gru)))\n",
        "\n",
        "y_pred_transformer = transformer_model.predict(X_test, verbose=0).flatten()\n",
        "transformer_r2 = r2_score(y_test, y_pred_transformer)\n",
        "transformer_rmse_log = np.sqrt(mean_squared_error(y_test, y_pred_transformer))\n",
        "transformer_rmse_rm = np.sqrt(mean_squared_error(np.expm1(y_test), np.expm1(y_pred_transformer)))\n",
        "\n",
        "print(\"RNN R:\", rnn_r2)\n",
        "print(\"RNN RMSE (log-scale):\", rnn_rmse_log)\n",
        "print(\"RNN RMSE (RM):\", rnn_rmse_rm)\n",
        "print(\"GRU R:\", gru_r2)\n",
        "print(\"GRU RMSE (log-scale):\", gru_rmse_log)\n",
        "print(\"GRU RMSE (RM):\", gru_rmse_rm)\n",
        "print(\"Transformer R:\", transformer_r2)\n",
        "print(\"Transformer RMSE (log-scale):\", transformer_rmse_log)\n",
        "print(\"Transformer RMSE (RM):\", transformer_rmse_rm)\n",
        "\n",
        "# Preprocessing function for samples\n",
        "def preprocess_sample(sample, scheme_encoding, scaler, features, area_cap, year_max=2025.0, sequence_length=3):\n",
        "    df_sample = pd.DataFrame([sample])\n",
        "    df_sample['Year'] = np.clip(df_sample['Year'], 2021.0, year_max).astype(np.float32)\n",
        "    print(f\"\\nSample: {sample}\")\n",
        "    print(f\"Year capped to {df_sample['Year'].iloc[0]} (training range: 20212025)\")\n",
        "    df_sample['ParcelArea'] = np.log1p(np.clip(df_sample['ParcelArea'], 0, area_cap)).astype(np.float32)\n",
        "    raw_scheme_encoding = df_sample['SchemeName'].map(scheme_encoding).fillna(scheme_encoding.mean()).astype(np.float32)\n",
        "    print(f\"Raw Scheme_Name_encoded: {raw_scheme_encoding.iloc[0]} (log-scale, mean={scheme_encoding.mean():.4f})\")\n",
        "    df_sample['Scheme_Name_encoded'] = raw_scheme_encoding\n",
        "    df_sample['Tenure'] = df_sample['Tenure'].map({'Freehold': 1, 'Leasehold': 0}).fillna(0).astype(np.float32)\n",
        "    unit_level_map = {'03A': 4, '12B': 12, '13A': 14, '23A': 24, '33A': 34, '43A': 44, '53A': 54,\n",
        "                      'B': 0, 'D': 0, 'G': 0, 'LG': 0, 'MZ': 0, 'P': 0, 'UG': 0,\n",
        "                      '1/5/2025': 0, '2/3/2025': 0, '1/4/2025': 0}\n",
        "    df_sample['UnitLevel_clean'] = df_sample['UnitLevel'].replace(unit_level_map)\n",
        "    df_sample['UnitLevel_clean'] = pd.to_numeric(df_sample['UnitLevel_clean'], errors='coerce').fillna(10.0).astype(np.float32)\n",
        "    df_sample['UnitLevel_binned'] = pd.cut(df_sample['UnitLevel_clean'], bins=[-float('inf'), 5, 15, 25, float('inf')], labels=['Low', 'Mid-Low', 'Mid-High', 'High'])\n",
        "    print(f\"UnitLevel_clean: {df_sample['UnitLevel_clean'].iloc[0]}, UnitLevel_binned: {df_sample['UnitLevel_binned'].iloc[0]}\")\n",
        "    level_dummies = pd.get_dummies(df_sample['UnitLevel_binned'], prefix='UnitLevel', dtype=np.float32)\n",
        "    if 'UnitLevel_Mid-High' not in level_dummies:\n",
        "        level_dummies['UnitLevel_Mid-High'] = 0.0\n",
        "    if 'UnitLevel_High' not in level_dummies:\n",
        "        level_dummies['UnitLevel_High'] = 0.0\n",
        "    level_dummies = level_dummies[['UnitLevel_Mid-High', 'UnitLevel_High']].astype(np.float32)\n",
        "    df_sample['Mukim_Mukim Setapak_Tenure'] = (df_sample['Mukim'].eq('Mukim Setapak').astype(np.float32) * df_sample['Tenure']).astype(np.float32)\n",
        "    df_sample['Mukim_Mukim Setapak_ParcelArea'] = (df_sample['Mukim'].eq('Mukim Setapak').astype(np.float32) * df_sample['ParcelArea']).astype(np.float32)\n",
        "    df_sample['ParcelArea_UnitLevel'] = (df_sample['ParcelArea'] * df_sample['UnitLevel_clean']).astype(np.float32)\n",
        "    X_sample = pd.concat([df_sample[['Scheme_Name_encoded', 'ParcelArea', 'Year', 'ParcelArea_UnitLevel']],\n",
        "                          df_sample[['Mukim_Mukim Setapak_Tenure', 'Mukim_Mukim Setapak_ParcelArea']],\n",
        "                          level_dummies[['UnitLevel_Mid-High', 'UnitLevel_High']]], axis=1).astype(np.float32)\n",
        "    X_sample_seq = np.zeros((1, sequence_length, len(features)), dtype=np.float32)\n",
        "    X_sample_seq[0, -1] = X_sample[features].values\n",
        "    for t in range(1, sequence_length):\n",
        "        if df_sample['Year'].iloc[0] - t >= 2021:\n",
        "            X_sample_seq[0, sequence_length - t - 1] = X_sample[features].values\n",
        "            X_sample_seq[0, sequence_length - t - 1, 2] = (df_sample['Year'].iloc[0] - t - 2023) / 2.0\n",
        "    X_sample_seq[:, :, [0, 1, 2, 7]] = scaler.transform(X_sample_seq[:, :, [0, 1, 2, 7]].reshape(-1, 4)).reshape(1, sequence_length, 4)\n",
        "    return X_sample_seq\n",
        "\n",
        "# Define sample inputs\n",
        "sample_inputs = [\n",
        "    {'SchemeName': 'The Edge', 'ParcelArea': 80.0, 'Year': 2025.0, 'Mukim': 'Mukim Setapak', 'Tenure': 'Freehold', 'UnitLevel': 15},\n",
        "    {'SchemeName': 'The Edge', 'ParcelArea': 80.0, 'Year': 2025.0, 'Mukim': 'Mukim Setapak', 'Tenure': 'Freehold', 'UnitLevel': 25}\n",
        "]\n",
        "\n",
        "# Predict for both inputs\n",
        "area_cap = 90.0\n",
        "features = ['Scheme_Name_encoded', 'ParcelArea', 'Year', 'Mukim_Mukim Setapak_Tenure', 'Mukim_Mukim Setapak_ParcelArea', 'UnitLevel_Mid-High', 'UnitLevel_High', 'ParcelArea_UnitLevel']\n",
        "for sample in sample_inputs:\n",
        "    X_sample = preprocess_sample(sample, scheme_encoding, scaler, features, area_cap)\n",
        "    y_pred_rnn_log = rnn_model.predict(X_sample, verbose=0).flatten()[0]\n",
        "    y_pred_rnn_rm = np.expm1(y_pred_rnn_log)\n",
        "    y_pred_gru_log = gru_model.predict(X_sample, verbose=0).flatten()[0]\n",
        "    y_pred_gru_rm = np.expm1(y_pred_gru_log)\n",
        "    y_pred_transformer_log = transformer_model.predict(X_sample, verbose=0).flatten()[0]\n",
        "    y_pred_transformer_rm = np.expm1(y_pred_transformer_log)\n",
        "    print(\"Preprocessed X_sample:\\n\", X_sample[0])\n",
        "    print(\"RNN Predicted TransactionPrice (log-scale):\", y_pred_rnn_log)\n",
        "    print(\"RNN Predicted TransactionPrice (RM):\", y_pred_rnn_rm)\n",
        "    print(\"GRU Predicted TransactionPrice (log-scale):\", y_pred_gru_log)\n",
        "    print(\"GRU Predicted TransactionPrice (RM):\", y_pred_gru_rm)\n",
        "    print(\"Transformer Predicted TransactionPrice (log-scale):\", y_pred_transformer_log)\n",
        "    print(\"Transformer Predicted TransactionPrice (RM):\", y_pred_transformer_rm)\n",
        "    print(\"Difference (RNN - GRU, RM):\", y_pred_rnn_rm - y_pred_gru_rm)\n",
        "    print(\"Difference (RNN - Transformer, RM):\", y_pred_rnn_rm - y_pred_transformer_rm)\n",
        "    print(\"Difference (GRU - Transformer, RM):\", y_pred_gru_rm - y_pred_transformer_rm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C0epS7LaScud",
        "outputId": "f9deea8e-302c-40d8-98a7-43877f185ab0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<>:14: SyntaxWarning: invalid escape sequence '\\d'\n",
            "<>:14: SyntaxWarning: invalid escape sequence '\\d'\n",
            "/tmp/ipython-input-3852120017.py:14: SyntaxWarning: invalid escape sequence '\\d'\n",
            "  df['ParcelArea'] = df['ParcelArea'].astype(str).str.extract('(\\d+\\.?\\d*)').astype(np.float32)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RNN R: 0.0011399388313293457\n",
            "RNN RMSE (log-scale): 0.7206995273903475\n",
            "RNN RMSE (RM): 986335.3765692479\n",
            "GRU R: -0.0032126903533935547\n",
            "GRU RMSE (log-scale): 0.7222680776254244\n",
            "GRU RMSE (RM): 989279.1010185144\n",
            "Transformer R: -6.723403930664062e-05\n",
            "Transformer RMSE (log-scale): 0.7211348731650687\n",
            "Transformer RMSE (RM): 987233.8208793295\n",
            "\n",
            "Sample: {'SchemeName': 'The Edge', 'ParcelArea': 80.0, 'Year': 2025.0, 'Mukim': 'Mukim Setapak', 'Tenure': 'Freehold', 'UnitLevel': 15}\n",
            "Year capped to 2025.0 (training range: 20212025)\n",
            "Raw Scheme_Name_encoded: 13.317193031311035 (log-scale, mean=13.3172)\n",
            "UnitLevel_clean: 15.0, UnitLevel_binned: Mid-Low\n",
            "Preprocessed X_sample:\n",
            " [[ 1.3972817e-01 -7.2834879e-01 -1.0115000e+03  1.0000000e+00\n",
            "   4.3944492e+00  0.0000000e+00  0.0000000e+00  1.2256704e-01]\n",
            " [ 1.3972817e-01 -7.2834879e-01 -1.0112500e+03  1.0000000e+00\n",
            "   4.3944492e+00  0.0000000e+00  0.0000000e+00  1.2256704e-01]\n",
            " [ 1.3972817e-01 -7.2834879e-01  1.0000000e+00  1.0000000e+00\n",
            "   4.3944492e+00  0.0000000e+00  0.0000000e+00  1.2256704e-01]]\n",
            "RNN Predicted TransactionPrice (log-scale): 5.64471\n",
            "RNN Predicted TransactionPrice (RM): 281.79156\n",
            "GRU Predicted TransactionPrice (log-scale): 8.483237\n",
            "GRU Predicted TransactionPrice (RM): 4832.0703\n",
            "Transformer Predicted TransactionPrice (log-scale): 13.369828\n",
            "Transformer Predicted TransactionPrice (RM): 640386.2\n",
            "Difference (RNN - GRU, RM): -4550.279\n",
            "Difference (RNN - Transformer, RM): -640104.4\n",
            "Difference (GRU - Transformer, RM): -635554.1\n",
            "\n",
            "Sample: {'SchemeName': 'The Edge', 'ParcelArea': 80.0, 'Year': 2025.0, 'Mukim': 'Mukim Setapak', 'Tenure': 'Freehold', 'UnitLevel': 25}\n",
            "Year capped to 2025.0 (training range: 20212025)\n",
            "Raw Scheme_Name_encoded: 13.317193031311035 (log-scale, mean=13.3172)\n",
            "UnitLevel_clean: 25.0, UnitLevel_binned: Mid-High\n",
            "Preprocessed X_sample:\n",
            " [[ 1.3972817e-01 -7.2834879e-01 -1.0115000e+03  1.0000000e+00\n",
            "   4.3944492e+00  1.0000000e+00  0.0000000e+00  7.6628447e-01]\n",
            " [ 1.3972817e-01 -7.2834879e-01 -1.0112500e+03  1.0000000e+00\n",
            "   4.3944492e+00  1.0000000e+00  0.0000000e+00  7.6628447e-01]\n",
            " [ 1.3972817e-01 -7.2834879e-01  1.0000000e+00  1.0000000e+00\n",
            "   4.3944492e+00  1.0000000e+00  0.0000000e+00  7.6628447e-01]]\n",
            "RNN Predicted TransactionPrice (log-scale): 6.469664\n",
            "RNN Predicted TransactionPrice (RM): 644.26697\n",
            "GRU Predicted TransactionPrice (log-scale): 8.540983\n",
            "GRU Predicted TransactionPrice (RM): 5119.376\n",
            "Transformer Predicted TransactionPrice (log-scale): 13.3704605\n",
            "Transformer Predicted TransactionPrice (RM): 640791.2\n",
            "Difference (RNN - GRU, RM): -4475.109\n",
            "Difference (RNN - Transformer, RM): -640146.94\n",
            "Difference (GRU - Transformer, RM): -635671.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import RobustScaler, StandardScaler\n",
        "from sklearn.metrics import r2_score, mean_squared_error\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, SimpleRNN, GRU, Dense, Layer, MultiHeadAttention, LayerNormalization, Dropout\n",
        "import joblib\n",
        "\n",
        "# Load data\n",
        "url = \"https://raw.githubusercontent.com/englian1123/KL-High-Rise-Data/refs/heads/main/KLHighRise.csv\"\n",
        "df = pd.read_csv(url)\n",
        "df.rename(columns={'TransactionPrice  ': 'TransactionPrice', 'Parcel Area': 'ParcelArea', 'Scheme Name/Area': 'SchemeName'}, inplace=True)\n",
        "df['ParcelArea'] = df['ParcelArea'].astype(str).str.extract('(\\d+\\.?\\d*)').astype(np.float32)\n",
        "df['Tenure'] = df['Tenure'].map({'Freehold': 1, 'Leasehold': 0}).fillna(0).astype(np.float32)\n",
        "\n",
        "# Outlier capping (only ParcelArea)\n",
        "area_cap = df['ParcelArea'].quantile(0.90)\n",
        "df['ParcelArea'] = np.clip(df['ParcelArea'], 0, area_cap).astype(np.float32)\n",
        "\n",
        "# Log-transform\n",
        "df['TransactionPrice'] = np.log1p(df['TransactionPrice']).astype(np.float32)\n",
        "df['ParcelArea'] = np.log1p(df['ParcelArea']).astype(np.float32)\n",
        "\n",
        "# Target encode SchemeName\n",
        "scheme_encoding = df.groupby('SchemeName')['TransactionPrice'].mean().astype(np.float32)\n",
        "df['Scheme_Name_encoded'] = df['SchemeName'].map(scheme_encoding).fillna(scheme_encoding.mean()).astype(np.float32)\n",
        "joblib.dump(scheme_encoding, 'scheme_encoding_rnn_gru_transformer_v2.joblib')\n",
        "\n",
        "# Add Year\n",
        "df['TransactionDate'] = pd.to_datetime(df['TransactionDate'], format='%b-%y')\n",
        "df['Year'] = df['TransactionDate'].dt.year.astype(np.float32)\n",
        "\n",
        "# Clean UnitLevel\n",
        "unit_level_map = {'03A': 4, '12B': 12, '13A': 14, '23A': 24, '33A': 34, '43A': 44, '53A': 54,\n",
        "                  'B': 0, 'D': 0, 'G': 0, 'LG': 0, 'MZ': 0, 'P': 0, 'UG': 0,\n",
        "                  '1/5/2025': 0, '2/3/2025': 0, '1/4/2025': 0}\n",
        "df['UnitLevel_clean'] = df['UnitLevel'].replace(unit_level_map)\n",
        "unit_level_mean = pd.to_numeric(df['UnitLevel_clean'], errors='coerce').mean()\n",
        "df['UnitLevel_clean'] = pd.to_numeric(df['UnitLevel_clean'], errors='coerce').fillna(unit_level_mean).astype(np.float32)\n",
        "df['UnitLevel_binned'] = pd.cut(df['UnitLevel_clean'], bins=[-float('inf'), 5, 15, 25, float('inf')], labels=['Low', 'Mid-Low', 'Mid-High', 'High'])\n",
        "level_dummies = pd.get_dummies(df['UnitLevel_binned'], prefix='UnitLevel', dtype=np.float32)\n",
        "\n",
        "# Setapak interactions\n",
        "mukim_dummies = pd.get_dummies(df['Mukim'], prefix='Mukim', dtype=np.float32)\n",
        "df['Mukim_Mukim Setapak_Tenure'] = (mukim_dummies.get('Mukim_Mukim Setapak', pd.Series(0, index=df.index)) * df['Tenure']).astype(np.float32)\n",
        "df['Mukim_Mukim Setapak_ParcelArea'] = (mukim_dummies.get('Mukim_Mukim Setapak', pd.Series(0, index=df.index)) * df['ParcelArea']).astype(np.float32)\n",
        "df['ParcelArea_UnitLevel'] = (df['ParcelArea'] * df['UnitLevel_clean']).astype(np.float32)\n",
        "\n",
        "# Features\n",
        "features = ['Scheme_Name_encoded', 'ParcelArea', 'Year', 'Mukim_Mukim Setapak_Tenure', 'Mukim_Mukim Setapak_ParcelArea', 'UnitLevel_Mid-High', 'UnitLevel_High', 'ParcelArea_UnitLevel']\n",
        "X = pd.concat([df[['Scheme_Name_encoded', 'ParcelArea', 'Year', 'ParcelArea_UnitLevel']],\n",
        "               df[['Mukim_Mukim Setapak_Tenure', 'Mukim_Mukim Setapak_ParcelArea']],\n",
        "               level_dummies[['UnitLevel_Mid-High', 'UnitLevel_High']]], axis=1).astype(np.float32)\n",
        "y = df['TransactionPrice'].astype(np.float32)\n",
        "\n",
        "# Standardize target\n",
        "y_scaler = StandardScaler()\n",
        "y = y_scaler.fit_transform(y.values.reshape(-1, 1)).flatten().astype(np.float32)\n",
        "joblib.dump(y_scaler, 'y_scaler_rnn_gru_transformer_v2.joblib')\n",
        "\n",
        "# Create sequences (3 timesteps)\n",
        "sequence_length = 3\n",
        "X_seq = []\n",
        "y_seq = []\n",
        "for idx in range(len(X)):\n",
        "    year = X.iloc[idx]['Year']\n",
        "    sample = X.iloc[idx][features].values\n",
        "    seq = np.zeros((sequence_length, len(features)), dtype=np.float32)\n",
        "    seq[-1] = sample  # Current year\n",
        "    for t in range(1, sequence_length):\n",
        "        if year - t >= 2021:\n",
        "            seq[sequence_length - t - 1] = sample.copy()\n",
        "            seq[sequence_length - t - 1][2] = (year - t - 2023) / 2.0  # Correct Year scaling\n",
        "    X_seq.append(seq)\n",
        "    y_seq.append(y[idx])\n",
        "X_seq = np.array(X_seq)\n",
        "y_seq = np.array(y_seq)\n",
        "\n",
        "# Split data\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_seq, y_seq, test_size=0.2, random_state=42)\n",
        "\n",
        "# Scale features\n",
        "scaler = RobustScaler()\n",
        "for t in range(sequence_length):\n",
        "    X_train[:, t, [0, 1, 2, 7]] = scaler.fit_transform(X_train[:, t, [0, 1, 2, 7]]).astype(np.float32)\n",
        "    X_test[:, t, [0, 1, 2, 7]] = scaler.transform(X_test[:, t, [0, 1, 2, 7]]).astype(np.float32)\n",
        "joblib.dump(scaler, 'scaler_rnn_gru_transformer_v2.joblib')\n",
        "\n",
        "# RNN Model\n",
        "inputs = Input(shape=(sequence_length, len(features)))\n",
        "x = SimpleRNN(64, return_sequences=False)(inputs)\n",
        "x = Dense(32, activation='relu')(x)\n",
        "outputs = Dense(1)(x)\n",
        "rnn_model = Model(inputs, outputs)\n",
        "rnn_model.compile(optimizer='rmsprop', loss='mse')\n",
        "rnn_model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test),\n",
        "              callbacks=[tf.keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)], verbose=0)\n",
        "joblib.dump(rnn_model, 'rnn_model_v2.joblib')\n",
        "\n",
        "# GRU Model\n",
        "x = GRU(64, return_sequences=False)(inputs)\n",
        "x = Dense(32, activation='relu')(x)\n",
        "outputs = Dense(1)(x)\n",
        "gru_model = Model(inputs, outputs)\n",
        "gru_model.compile(optimizer='rmsprop', loss='mse')\n",
        "gru_model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test),\n",
        "              callbacks=[tf.keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)], verbose=0)\n",
        "joblib.dump(gru_model, 'gru_model_v2.joblib')\n",
        "\n",
        "# Transformer Model\n",
        "class TransformerBlock(Layer):\n",
        "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
        "        super(TransformerBlock, self).__init__()\n",
        "        self.att = MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.ffn = tf.keras.Sequential([Dense(ff_dim, activation='relu'), Dense(embed_dim)])\n",
        "        self.layernorm1 = LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = LayerNormalization(epsilon=1e-6)\n",
        "        self.dropout1 = Dropout(rate)\n",
        "        self.dropout2 = Dropout(rate)\n",
        "    def call(self, inputs, training=False):\n",
        "        attn_output = self.att(inputs, inputs)\n",
        "        attn_output = self.dropout1(attn_output, training=training)\n",
        "        out1 = self.layernorm1(inputs + attn_output)\n",
        "        ffn_output = self.ffn(out1)\n",
        "        ffn_output = self.dropout2(ffn_output, training=training)\n",
        "        return self.layernorm2(out1 + ffn_output)\n",
        "\n",
        "class PositionalEncoding(Layer):\n",
        "    def __init__(self, sequence_length, embed_dim):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        pos_enc = np.array([[pos / np.power(10000, 2 * (i // 2) / embed_dim) for i in range(embed_dim)] for pos in range(sequence_length)])\n",
        "        pos_enc[:, 0::2] = np.sin(pos_enc[:, 0::2])\n",
        "        pos_enc[:, 1::2] = np.cos(pos_enc[:, 1::2])\n",
        "        self.pos_encoding = tf.cast(pos_enc, dtype=tf.float32)\n",
        "    def call(self, inputs):\n",
        "        return inputs + self.pos_encoding\n",
        "\n",
        "inputs = Input(shape=(sequence_length, len(features)))\n",
        "# Adjust input dimension for TransformerBlock\n",
        "x = PositionalEncoding(sequence_length, len(features))(inputs)\n",
        "# Pass the embedded dimension to TransformerBlock\n",
        "x = TransformerBlock(embed_dim=len(features), num_heads=4, ff_dim=64)(x, training=True) # Added training=True\n",
        "x = TransformerBlock(embed_dim=len(features), num_heads=4, ff_dim=64)(x, training=True) # Added training=True\n",
        "x = tf.keras.layers.GlobalAveragePooling1D()(x)\n",
        "x = Dense(32, activation='relu')(x)\n",
        "outputs = Dense(1)(x)\n",
        "transformer_model = Model(inputs, outputs)\n",
        "transformer_model.compile(optimizer='rmsprop', loss='mse')\n",
        "transformer_model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test),\n",
        "                     callbacks=[tf.keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)], verbose=0)\n",
        "joblib.dump(transformer_model, 'transformer_model_v2.joblib')\n",
        "\n",
        "# Evaluate models\n",
        "y_pred_rnn = rnn_model.predict(X_test, verbose=0).flatten()\n",
        "y_pred_rnn = y_scaler.inverse_transform(y_pred_rnn.reshape(-1, 1)).flatten()\n",
        "y_test_inv = y_scaler.inverse_transform(y_test.reshape(-1, 1)).flatten()\n",
        "rnn_r2 = r2_score(y_test_inv, y_pred_rnn)\n",
        "rnn_rmse_log = np.sqrt(mean_squared_error(y_test_inv, y_pred_rnn))\n",
        "rnn_rmse_rm = np.sqrt(mean_squared_error(np.expm1(y_test_inv), np.expm1(y_pred_rnn)))\n",
        "\n",
        "y_pred_gru = gru_model.predict(X_test, verbose=0).flatten()\n",
        "y_pred_gru = y_scaler.inverse_transform(y_pred_gru.reshape(-1, 1)).flatten()\n",
        "gru_r2 = r2_score(y_test_inv, y_pred_gru)\n",
        "gru_rmse_log = np.sqrt(mean_squared_error(y_test_inv, y_pred_gru))\n",
        "gru_rmse_rm = np.sqrt(mean_squared_error(np.expm1(y_test_inv), np.expm1(y_pred_gru)))\n",
        "\n",
        "y_pred_transformer = transformer_model.predict(X_test, verbose=0).flatten()\n",
        "y_pred_transformer = y_scaler.inverse_transform(y_pred_transformer.reshape(-1, 1)).flatten()\n",
        "transformer_r2 = r2_score(y_test_inv, y_pred_transformer)\n",
        "transformer_rmse_log = np.sqrt(mean_squared_error(y_test_inv, y_pred_transformer))\n",
        "transformer_rmse_rm = np.sqrt(mean_squared_error(np.expm1(y_test_inv), np.expm1(y_pred_transformer)))\n",
        "\n",
        "print(\"RNN R:\", rnn_r2)\n",
        "print(\"RNN RMSE (log-scale):\", rnn_rmse_log)\n",
        "print(\"RNN RMSE (RM):\", rnn_rmse_rm)\n",
        "print(\"GRU R:\", gru_r2)\n",
        "print(\"GRU RMSE (log-scale):\", gru_rmse_log)\n",
        "print(\"GRU RMSE (RM):\", gru_rmse_rm)\n",
        "print(\"Transformer R:\", transformer_r2)\n",
        "print(\"Transformer RMSE (log-scale):\", transformer_rmse_log)\n",
        "print(\"Transformer RMSE (RM):\", transformer_rmse_rm)\n",
        "\n",
        "# Preprocessing function for samples\n",
        "def preprocess_sample(sample, scheme_encoding, scaler, y_scaler, features, area_cap, year_max=2025.0, sequence_length=3):\n",
        "    df_sample = pd.DataFrame([sample])\n",
        "    df_sample['Year'] = np.clip(df_sample['Year'], 2021.0, year_max).astype(np.float32)\n",
        "    print(f\"\\nSample: {sample}\")\n",
        "    print(f\"Year capped to {df_sample['Year'].iloc[0]} (training range: 20212025)\")\n",
        "    df_sample['ParcelArea'] = np.log1p(np.clip(df_sample['ParcelArea'], 0, area_cap)).astype(np.float32)\n",
        "    raw_scheme_encoding = df_sample['SchemeName'].map(scheme_encoding).fillna(scheme_encoding.mean()).astype(np.float32)\n",
        "    print(f\"Raw Scheme_Name_encoded: {raw_scheme_encoding.iloc[0]} (log-scale, mean={scheme_encoding.mean():.4f})\")\n",
        "    df_sample['Scheme_Name_encoded'] = raw_scheme_encoding\n",
        "    df_sample['Tenure'] = df_sample['Tenure'].map({'Freehold': 1, 'Leasehold': 0}).fillna(0).astype(np.float32)\n",
        "    unit_level_map = {'03A': 4, '12B': 12, '13A': 14, '23A': 24, '33A': 34, '43A': 44, '53A': 54,\n",
        "                      'B': 0, 'D': 0, 'G': 0, 'LG': 0, 'MZ': 0, 'P': 0, 'UG': 0,\n",
        "                      '1/5/2025': 0, '2/3/2025': 0, '1/4/2025': 0}\n",
        "    df_sample['UnitLevel_clean'] = df_sample['UnitLevel'].replace(unit_level_map)\n",
        "    df_sample['UnitLevel_clean'] = pd.to_numeric(df_sample['UnitLevel_clean'], errors='coerce').fillna(10.0).astype(np.float32)\n",
        "    df_sample['UnitLevel_binned'] = pd.cut(df_sample['UnitLevel_clean'], bins=[-float('inf'), 5, 15, 25, float('inf')], labels=['Low', 'Mid-Low', 'Mid-High', 'High'])\n",
        "    print(f\"UnitLevel_clean: {df_sample['UnitLevel_clean'].iloc[0]}, UnitLevel_binned: {df_sample['UnitLevel_binned'].iloc[0]}\")\n",
        "    level_dummies = pd.get_dummies(df_sample['UnitLevel_binned'], prefix='UnitLevel', dtype=np.float32)\n",
        "    if 'UnitLevel_Mid-High' not in level_dummies:\n",
        "        level_dummies['UnitLevel_Mid-High'] = 0.0\n",
        "    if 'UnitLevel_High' not in level_dummies:\n",
        "        level_dummies['UnitLevel_High'] = 0.0\n",
        "    level_dummies = level_dummies[['UnitLevel_Mid-High', 'UnitLevel_High']].astype(np.float32)\n",
        "    df_sample['Mukim_Mukim Setapak_Tenure'] = (df_sample['Mukim'].eq('Mukim Setapak').astype(np.float32) * df_sample['Tenure']).astype(np.float32)\n",
        "    df_sample['Mukim_Mukim Setapak_ParcelArea'] = (df_sample['Mukim'].eq('Mukim Setapak').astype(np.float32) * df_sample['ParcelArea']).astype(np.float32)\n",
        "    df_sample['ParcelArea_UnitLevel'] = (df_sample['ParcelArea'] * df_sample['UnitLevel_clean']).astype(np.float32)\n",
        "    X_sample = pd.concat([df_sample[['Scheme_Name_encoded', 'ParcelArea', 'Year', 'ParcelArea_UnitLevel']],\n",
        "                          df_sample[['Mukim_Mukim Setapak_Tenure', 'Mukim_Mukim Setapak_ParcelArea']],\n",
        "                          level_dummies[['UnitLevel_Mid-High', 'UnitLevel_High']]], axis=1).astype(np.float32)\n",
        "    X_sample_seq = np.zeros((1, sequence_length, len(features)), dtype=np.float32)\n",
        "    X_sample_seq[0, -1] = X_sample[features].values\n",
        "    for t in range(1, sequence_length):\n",
        "        if df_sample['Year'].iloc[0] - t >= 2021:\n",
        "            X_sample_seq[0, sequence_length - t - 1] = X_sample[features].values\n",
        "            X_sample_seq[0, sequence_length - t - 1, 2] = (df_sample['Year'].iloc[0] - t - 2023) / 2.0\n",
        "    X_sample_seq[:, :, [0, 1, 2, 7]] = scaler.transform(X_sample_seq[:, :, [0, 1, 2, 7]].reshape(-1, 4)).reshape(1, sequence_length, 4)\n",
        "    return X_sample_seq\n",
        "\n",
        "# Define sample inputs\n",
        "sample_inputs = [\n",
        "    {'SchemeName': 'The Edge', 'ParcelArea': 80.0, 'Year': 2025.0, 'Mukim': 'Mukim Setapak', 'Tenure': 'Freehold', 'UnitLevel': 15},\n",
        "    {'SchemeName': 'The Edge', 'ParcelArea': 80.0, 'Year': 2025.0, 'Mukim': 'Mukim Setapak', 'Tenure': 'Freehold', 'UnitLevel': 25}\n",
        "]\n",
        "\n",
        "# Predict for both inputs\n",
        "area_cap = 90.0\n",
        "features = ['Scheme_Name_encoded', 'ParcelArea', 'Year', 'Mukim_Mukim Setapak_Tenure', 'Mukim_Mukim Setapak_ParcelArea', 'UnitLevel_Mid-High', 'UnitLevel_High', 'ParcelArea_UnitLevel']\n",
        "for sample in sample_inputs:\n",
        "    X_sample = preprocess_sample(sample, scheme_encoding, scaler, y_scaler, features, area_cap)\n",
        "    y_pred_rnn_log = rnn_model.predict(X_sample, verbose=0).flatten()[0]\n",
        "    y_pred_rnn_rm = np.expm1(y_pred_rnn_log)\n",
        "    y_pred_gru_log = gru_model.predict(X_sample, verbose=0).flatten()[0]\n",
        "    y_pred_gru_rm = np.expm1(y_pred_gru_log)\n",
        "    y_pred_transformer_log = transformer_model.predict(X_sample, verbose=0).flatten()[0]\n",
        "    y_pred_transformer_rm = np.expm1(y_pred_transformer_log)\n",
        "    print(\"Preprocessed X_sample:\\n\", X_sample[0])\n",
        "    print(\"RNN Predicted TransactionPrice (log-scale):\", y_pred_rnn_log)\n",
        "    print(\"RNN Predicted TransactionPrice (RM):\", y_pred_rnn_rm)\n",
        "    print(\"GRU Predicted TransactionPrice (log-scale):\", y_pred_gru_log)\n",
        "    print(\"GRU Predicted TransactionPrice (RM):\", y_pred_gru_rm)\n",
        "    print(\"Transformer Predicted TransactionPrice (log-scale):\", y_pred_transformer_log)\n",
        "    print(\"Transformer Predicted TransactionPrice (RM):\", y_pred_transformer_rm)\n",
        "    print(\"Difference (RNN - GRU, RM):\", y_pred_rnn_rm - y_pred_gru_rm)\n",
        "    print(\"Difference (RNN - Transformer, RM):\", y_pred_rnn_rm - y_pred_transformer_rm)\n",
        "    print(\"Difference (GRU - Transformer, RM):\", y_pred_gru_rm - y_pred_transformer_rm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2omcGaYpaRMk",
        "outputId": "5272a360-f0ac-4794-b155-fce8dcbacfb3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<>:14: SyntaxWarning: invalid escape sequence '\\d'\n",
            "<>:14: SyntaxWarning: invalid escape sequence '\\d'\n",
            "/tmp/ipython-input-1753153507.py:14: SyntaxWarning: invalid escape sequence '\\d'\n",
            "  df['ParcelArea'] = df['ParcelArea'].astype(str).str.extract('(\\d+\\.?\\d*)').astype(np.float32)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RNN R: 0.9413411021232605\n",
            "RNN RMSE (log-scale): 0.17465010259760702\n",
            "RNN RMSE (RM): 385345.63161919976\n",
            "GRU R: 0.9407809972763062\n",
            "GRU RMSE (log-scale): 0.17548191757424342\n",
            "GRU RMSE (RM): 376925.72747425985\n",
            "Transformer R: 0.9403591156005859\n",
            "Transformer RMSE (log-scale): 0.17610589883321665\n",
            "Transformer RMSE (RM): 379463.1836054718\n",
            "\n",
            "Sample: {'SchemeName': 'The Edge', 'ParcelArea': 80.0, 'Year': 2025.0, 'Mukim': 'Mukim Setapak', 'Tenure': 'Freehold', 'UnitLevel': 15}\n",
            "Year capped to 2025.0 (training range: 20212025)\n",
            "Raw Scheme_Name_encoded: 13.317193031311035 (log-scale, mean=13.3172)\n",
            "UnitLevel_clean: 15.0, UnitLevel_binned: Mid-Low\n",
            "Preprocessed X_sample:\n",
            " [[ 1.3972817e-01 -7.2834879e-01 -1.0115000e+03  1.0000000e+00\n",
            "   4.3944492e+00  0.0000000e+00  0.0000000e+00  1.2256704e-01]\n",
            " [ 1.3972817e-01 -7.2834879e-01 -1.0112500e+03  1.0000000e+00\n",
            "   4.3944492e+00  0.0000000e+00  0.0000000e+00  1.2256704e-01]\n",
            " [ 1.3972817e-01 -7.2834879e-01  1.0000000e+00  1.0000000e+00\n",
            "   4.3944492e+00  0.0000000e+00  0.0000000e+00  1.2256704e-01]]\n",
            "RNN Predicted TransactionPrice (log-scale): -0.007512576\n",
            "RNN Predicted TransactionPrice (RM): -0.007484427\n",
            "GRU Predicted TransactionPrice (log-scale): -0.49225765\n",
            "GRU Predicted TransactionPrice (RM): -0.38875514\n",
            "Transformer Predicted TransactionPrice (log-scale): 0.9012306\n",
            "Transformer Predicted TransactionPrice (RM): 1.4626317\n",
            "Difference (RNN - GRU, RM): 0.3812707\n",
            "Difference (RNN - Transformer, RM): -1.4701161\n",
            "Difference (GRU - Transformer, RM): -1.8513868\n",
            "\n",
            "Sample: {'SchemeName': 'The Edge', 'ParcelArea': 80.0, 'Year': 2025.0, 'Mukim': 'Mukim Setapak', 'Tenure': 'Freehold', 'UnitLevel': 25}\n",
            "Year capped to 2025.0 (training range: 20212025)\n",
            "Raw Scheme_Name_encoded: 13.317193031311035 (log-scale, mean=13.3172)\n",
            "UnitLevel_clean: 25.0, UnitLevel_binned: Mid-High\n",
            "Preprocessed X_sample:\n",
            " [[ 1.3972817e-01 -7.2834879e-01 -1.0115000e+03  1.0000000e+00\n",
            "   4.3944492e+00  1.0000000e+00  0.0000000e+00  7.6628447e-01]\n",
            " [ 1.3972817e-01 -7.2834879e-01 -1.0112500e+03  1.0000000e+00\n",
            "   4.3944492e+00  1.0000000e+00  0.0000000e+00  7.6628447e-01]\n",
            " [ 1.3972817e-01 -7.2834879e-01  1.0000000e+00  1.0000000e+00\n",
            "   4.3944492e+00  1.0000000e+00  0.0000000e+00  7.6628447e-01]]\n",
            "RNN Predicted TransactionPrice (log-scale): 0.0252601\n",
            "RNN Predicted TransactionPrice (RM): 0.02558184\n",
            "GRU Predicted TransactionPrice (log-scale): -0.43105423\n",
            "GRU Predicted TransactionPrice (RM): -0.35017633\n",
            "Transformer Predicted TransactionPrice (log-scale): 0.9012588\n",
            "Transformer Predicted TransactionPrice (RM): 1.4627013\n",
            "Difference (RNN - GRU, RM): 0.37575817\n",
            "Difference (RNN - Transformer, RM): -1.4371195\n",
            "Difference (GRU - Transformer, RM): -1.8128777\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import RobustScaler, StandardScaler\n",
        "from sklearn.metrics import r2_score, mean_squared_error\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, SimpleRNN, GRU, Dense, Layer, MultiHeadAttention, LayerNormalization, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import joblib\n",
        "\n",
        "# Load data\n",
        "url = \"https://raw.githubusercontent.com/englian1123/KL-High-Rise-Data/refs/heads/main/KLHighRise.csv\"\n",
        "df = pd.read_csv(url)\n",
        "df.rename(columns={'TransactionPrice  ': 'TransactionPrice', 'Parcel Area': 'ParcelArea', 'Scheme Name/Area': 'SchemeName'}, inplace=True)\n",
        "df['ParcelArea'] = df['ParcelArea'].astype(str).str.extract('(\\d+\\.?\\d*)').astype(np.float32)\n",
        "df['Tenure'] = df['Tenure'].map({'Freehold': 1, 'Leasehold': 0}).fillna(0).astype(np.float32)\n",
        "\n",
        "# Outlier capping (only ParcelArea)\n",
        "area_cap = df['ParcelArea'].quantile(0.90)\n",
        "df['ParcelArea'] = np.clip(df['ParcelArea'], 0, area_cap).astype(np.float32)\n",
        "\n",
        "# Log-transform\n",
        "df['TransactionPrice'] = np.log1p(df['TransactionPrice']).astype(np.float32)\n",
        "df['ParcelArea'] = np.log1p(df['ParcelArea']).astype(np.float32)\n",
        "\n",
        "# Target encode SchemeName\n",
        "scheme_encoding = df.groupby('SchemeName')['TransactionPrice'].mean().astype(np.float32)\n",
        "df['Scheme_Name_encoded'] = df['SchemeName'].map(scheme_encoding).fillna(scheme_encoding.mean()).astype(np.float32)\n",
        "joblib.dump(scheme_encoding, 'scheme_encoding_rnn_gru_transformer_v4.joblib')\n",
        "\n",
        "# Add Year\n",
        "df['TransactionDate'] = pd.to_datetime(df['TransactionDate'], format='%b-%y')\n",
        "df['Year'] = df['TransactionDate'].dt.year.astype(np.float32)\n",
        "\n",
        "# Clean UnitLevel\n",
        "unit_level_map = {'03A': 4, '12B': 12, '13A': 14, '23A': 24, '33A': 34, '43A': 44, '53A': 54,\n",
        "                  'B': 0, 'D': 0, 'G': 0, 'LG': 0, 'MZ': 0, 'P': 0, 'UG': 0,\n",
        "                  '1/5/2025': 0, '2/3/2025': 0, '1/4/2025': 0}\n",
        "df['UnitLevel_clean'] = df['UnitLevel'].replace(unit_level_map)\n",
        "unit_level_mean = pd.to_numeric(df['UnitLevel_clean'], errors='coerce').mean()\n",
        "df['UnitLevel_clean'] = pd.to_numeric(df['UnitLevel_clean'], errors='coerce').fillna(unit_level_mean).astype(np.float32)\n",
        "df['UnitLevel_binned'] = pd.cut(df['UnitLevel_clean'], bins=[-float('inf'), 5, 15, 25, float('inf')], labels=['Low', 'Mid-Low', 'Mid-High', 'High'], right=False)\n",
        "level_dummies = pd.get_dummies(df['UnitLevel_binned'], prefix='UnitLevel', dtype=np.float32)\n",
        "\n",
        "# Setapak interactions\n",
        "mukim_dummies = pd.get_dummies(df['Mukim'], prefix='Mukim', dtype=np.float32)\n",
        "df['Mukim_Mukim Setapak_Tenure'] = (mukim_dummies.get('Mukim_Mukim Setapak', pd.Series(0, index=df.index)) * df['Tenure']).astype(np.float32)\n",
        "df['Mukim_Mukim Setapak_ParcelArea'] = (mukim_dummies.get('Mukim_Mukim Setapak', pd.Series(0, index=df.index)) * df['ParcelArea']).astype(np.float32)\n",
        "df['ParcelArea_UnitLevel'] = (df['ParcelArea'] * df['UnitLevel_clean']).astype(np.float32)\n",
        "\n",
        "# Features\n",
        "features = ['Scheme_Name_encoded', 'ParcelArea', 'Year', 'Mukim_Mukim Setapak_Tenure', 'Mukim_Mukim Setapak_ParcelArea', 'UnitLevel_Mid-High', 'UnitLevel_High', 'ParcelArea_UnitLevel']\n",
        "X = pd.concat([df[['Scheme_Name_encoded', 'ParcelArea', 'Year', 'ParcelArea_UnitLevel']],\n",
        "               df[['Mukim_Mukim Setapak_Tenure', 'Mukim_Mukim Setapak_ParcelArea']],\n",
        "               level_dummies[['UnitLevel_Mid-High', 'UnitLevel_High']]], axis=1).astype(np.float32)\n",
        "y = df['TransactionPrice'].astype(np.float32)\n",
        "\n",
        "# Standardize target\n",
        "y_scaler = StandardScaler()\n",
        "y = y_scaler.fit_transform(y.values.reshape(-1, 1)).flatten().astype(np.float32)\n",
        "joblib.dump(y_scaler, 'y_scaler_rnn_gru_transformer_v4.joblib')\n",
        "\n",
        "# Create sequences (3 timesteps)\n",
        "sequence_length = 3\n",
        "X_seq = []\n",
        "y_seq = []\n",
        "for idx in range(len(X)):\n",
        "    year = X.iloc[idx]['Year']\n",
        "    sample = X.iloc[idx][features].values\n",
        "    seq = np.zeros((sequence_length, len(features)), dtype=np.float32)\n",
        "    seq[-1] = sample  # Current year\n",
        "    for t in range(1, sequence_length):\n",
        "        if year - t >= 2021:\n",
        "            seq[sequence_length - t - 1] = sample.copy()\n",
        "            seq[sequence_length - t - 1][2] = (year - t - 2023) / 2.0  # Year scaling: 2023=-2/2=-1, 2024=-1/2=-0.5, 2025=0/2=0\n",
        "    X_seq.append(seq)\n",
        "    y_seq.append(y[idx])\n",
        "X_seq = np.array(X_seq)\n",
        "y_seq = np.array(y_seq)\n",
        "\n",
        "# Split data\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_seq, y_seq, test_size=0.2, random_state=42)\n",
        "\n",
        "# Scale features\n",
        "scaler = RobustScaler()\n",
        "for t in range(sequence_length):\n",
        "    X_train[:, t, [0, 1, 2, 7]] = scaler.fit_transform(X_train[:, t, [0, 1, 2, 7]]).astype(np.float32)\n",
        "    X_test[:, t, [0, 1, 2, 7]] = scaler.transform(X_test[:, t, [0, 1, 2, 7]]).astype(np.float32)\n",
        "joblib.dump(scaler, 'scaler_rnn_gru_transformer_v4.joblib')\n",
        "\n",
        "# RNN Model\n",
        "inputs = Input(shape=(sequence_length, len(features)))\n",
        "x = SimpleRNN(128, return_sequences=False)(inputs)\n",
        "x = Dropout(0.2)(x)\n",
        "x = Dense(64, activation='relu')(x)\n",
        "x = Dropout(0.2)(x)\n",
        "outputs = Dense(1)(x)\n",
        "rnn_model = Model(inputs, outputs)\n",
        "rnn_model.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n",
        "rnn_model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test),\n",
        "              callbacks=[tf.keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)], verbose=0)\n",
        "joblib.dump(rnn_model, 'rnn_model_v4.joblib')\n",
        "\n",
        "# GRU Model\n",
        "x = GRU(128, return_sequences=False)(inputs)\n",
        "x = Dropout(0.2)(x)\n",
        "x = Dense(64, activation='relu')(x)\n",
        "x = Dropout(0.2)(x)\n",
        "outputs = Dense(1)(x)\n",
        "gru_model = Model(inputs, outputs)\n",
        "gru_model.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n",
        "gru_model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test),\n",
        "              callbacks=[tf.keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)], verbose=0)\n",
        "joblib.dump(gru_model, 'gru_model_v4.joblib')\n",
        "\n",
        "# Transformer Model\n",
        "class TransformerBlock(Layer):\n",
        "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.2):\n",
        "        super(TransformerBlock, self).__init__()\n",
        "        self.att = MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.ffn = tf.keras.Sequential([Dense(ff_dim, activation='relu'), Dense(embed_dim)])\n",
        "        self.layernorm1 = LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = LayerNormalization(epsilon=1e-6)\n",
        "        self.dropout1 = Dropout(rate)\n",
        "        self.dropout2 = Dropout(rate)\n",
        "    def call(self, inputs, training=False):\n",
        "        attn_output = self.att(inputs, inputs)\n",
        "        attn_output = self.dropout1(attn_output, training=training)\n",
        "        out1 = self.layernorm1(inputs + attn_output)\n",
        "        ffn_output = self.ffn(out1)\n",
        "        ffn_output = self.dropout2(ffn_output, training=training)\n",
        "        return self.layernorm2(out1 + ffn_output)\n",
        "\n",
        "class PositionalEncoding(Layer):\n",
        "    def __init__(self, sequence_length, embed_dim):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        pos_enc = np.array([[pos / np.power(10000, 2 * (i // 2) / embed_dim) for i in range(embed_dim)] for pos in range(sequence_length)])\n",
        "        pos_enc[:, 0::2] = np.sin(pos_enc[:, 0::2])\n",
        "        pos_enc[:, 1::2] = np.cos(pos_enc[:, 1::2])\n",
        "        self.pos_encoding = tf.cast(pos_enc, dtype=tf.float32)\n",
        "    def call(self, inputs):\n",
        "        return inputs + self.pos_encoding\n",
        "\n",
        "inputs = Input(shape=(sequence_length, len(features)))\n",
        "x = PositionalEncoding(sequence_length, len(features))(inputs)\n",
        "x = TransformerBlock(embed_dim=len(features), num_heads=8, ff_dim=128)(x, training=True)\n",
        "x = TransformerBlock(embed_dim=len(features), num_heads=8, ff_dim=128)(x, training=True)\n",
        "x = tf.keras.layers.GlobalAveragePooling1D()(x)\n",
        "x = Dense(64, activation='relu')(x)\n",
        "x = Dropout(0.2)(x)\n",
        "outputs = Dense(1)(x)\n",
        "transformer_model = Model(inputs, outputs)\n",
        "transformer_model.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n",
        "transformer_model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test),\n",
        "                     callbacks=[tf.keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)], verbose=0)\n",
        "joblib.dump(transformer_model, 'transformer_model_v4.joblib')\n",
        "\n",
        "# Evaluate models\n",
        "y_pred_rnn = rnn_model.predict(X_test, verbose=0).flatten()\n",
        "y_pred_rnn_log = y_scaler.inverse_transform(y_pred_rnn.reshape(-1, 1)).flatten()\n",
        "y_test_log = y_scaler.inverse_transform(y_test.reshape(-1, 1)).flatten()\n",
        "rnn_r2 = r2_score(y_test_log, y_pred_rnn_log)\n",
        "rnn_rmse_log = np.sqrt(mean_squared_error(y_test_log, y_pred_rnn_log))\n",
        "rnn_rmse_rm = np.sqrt(mean_squared_error(np.expm1(y_test_log), np.expm1(y_pred_rnn_log)))\n",
        "\n",
        "y_pred_gru = gru_model.predict(X_test, verbose=0).flatten()\n",
        "y_pred_gru_log = y_scaler.inverse_transform(y_pred_gru.reshape(-1, 1)).flatten()\n",
        "gru_r2 = r2_score(y_test_log, y_pred_gru_log)\n",
        "gru_rmse_log = np.sqrt(mean_squared_error(y_test_log, y_pred_gru_log))\n",
        "gru_rmse_rm = np.sqrt(mean_squared_error(np.expm1(y_test_log), np.expm1(y_pred_gru_log)))\n",
        "\n",
        "y_pred_transformer = transformer_model.predict(X_test, verbose=0).flatten()\n",
        "y_pred_transformer_log = y_scaler.inverse_transform(y_pred_transformer.reshape(-1, 1)).flatten()\n",
        "transformer_r2 = r2_score(y_test_log, y_pred_transformer_log)\n",
        "transformer_rmse_log = np.sqrt(mean_squared_error(y_test_log, y_pred_transformer_log))\n",
        "transformer_rmse_rm = np.sqrt(mean_squared_error(np.expm1(y_test_log), np.expm1(y_pred_transformer_log)))\n",
        "\n",
        "print(\"RNN R:\", rnn_r2)\n",
        "print(\"RNN RMSE (log-scale):\", rnn_rmse_log)\n",
        "print(\"RNN RMSE (RM):\", rnn_rmse_rm)\n",
        "print(\"GRU R:\", gru_r2)\n",
        "print(\"GRU RMSE (log-scale):\", gru_rmse_log)\n",
        "print(\"GRU RMSE (RM):\", gru_rmse_rm)\n",
        "print(\"Transformer R:\", transformer_r2)\n",
        "print(\"Transformer RMSE (log-scale):\", transformer_rmse_log)\n",
        "print(\"Transformer RMSE (RM):\", transformer_rmse_rm)\n",
        "\n",
        "# Preprocessing function for samples\n",
        "def preprocess_sample(sample, scheme_encoding, scaler, y_scaler, features, area_cap, year_max=2025.0, sequence_length=3):\n",
        "    df_sample = pd.DataFrame([sample])\n",
        "    df_sample['Year'] = np.clip(df_sample['Year'], 2021.0, year_max).astype(np.float32)\n",
        "    print(f\"\\nSample: {sample}\")\n",
        "    print(f\"Year capped to {df_sample['Year'].iloc[0]} (training range: 20212025)\")\n",
        "    df_sample['ParcelArea'] = np.log1p(np.clip(df_sample['ParcelArea'], 0, area_cap)).astype(np.float32)\n",
        "    raw_scheme_encoding = df_sample['SchemeName'].map(scheme_encoding).fillna(scheme_encoding.mean()).astype(np.float32)\n",
        "    print(f\"Raw Scheme_Name_encoded: {raw_scheme_encoding.iloc[0]} (log-scale, mean={scheme_encoding.mean():.4f})\")\n",
        "    df_sample['Scheme_Name_encoded'] = raw_scheme_encoding\n",
        "    df_sample['Tenure'] = df_sample['Tenure'].map({'Freehold': 1, 'Leasehold': 0}).fillna(0).astype(np.float32)\n",
        "    unit_level_map = {'03A': 4, '12B': 12, '13A': 14, '23A': 24, '33A': 34, '43A': 44, '53A': 54,\n",
        "                      'B': 0, 'D': 0, 'G': 0, 'LG': 0, 'MZ': 0, 'P': 0, 'UG': 0,\n",
        "                      '1/5/2025': 0, '2/3/2025': 0, '1/4/2025': 0}\n",
        "    df_sample['UnitLevel_clean'] = df_sample['UnitLevel'].replace(unit_level_map)\n",
        "    df_sample['UnitLevel_clean'] = pd.to_numeric(df_sample['UnitLevel_clean'], errors='coerce').fillna(10.0).astype(np.float32)\n",
        "    df_sample['UnitLevel_binned'] = pd.cut(df_sample['UnitLevel_clean'], bins=[-float('inf'), 5, 15, 25, float('inf')], labels=['Low', 'Mid-Low', 'Mid-High', 'High'], right=False)\n",
        "    print(f\"UnitLevel_clean: {df_sample['UnitLevel_clean'].iloc[0]}, UnitLevel_binned: {df_sample['UnitLevel_binned'].iloc[0]}\")\n",
        "    level_dummies = pd.get_dummies(df_sample['UnitLevel_binned'], prefix='UnitLevel', dtype=np.float32)\n",
        "    if 'UnitLevel_Mid-High' not in level_dummies:\n",
        "        level_dummies['UnitLevel_Mid-High'] = 0.0\n",
        "    if 'UnitLevel_High' not in level_dummies:\n",
        "        level_dummies['UnitLevel_High'] = 0.0\n",
        "    level_dummies = level_dummies[['UnitLevel_Mid-High', 'UnitLevel_High']].astype(np.float32)\n",
        "    df_sample['Mukim_Mukim Setapak_Tenure'] = (df_sample['Mukim'].eq('Mukim Setapak').astype(np.float32) * df_sample['Tenure']).astype(np.float32)\n",
        "    df_sample['Mukim_Mukim Setapak_ParcelArea'] = (df_sample['Mukim'].eq('Mukim Setapak').astype(np.float32) * df_sample['ParcelArea']).astype(np.float32)\n",
        "    df_sample['ParcelArea_UnitLevel'] = (df_sample['ParcelArea'] * df_sample['UnitLevel_clean']).astype(np.float32)\n",
        "    X_sample = pd.concat([df_sample[['Scheme_Name_encoded', 'ParcelArea', 'Year', 'ParcelArea_UnitLevel']],\n",
        "                          df_sample[['Mukim_Mukim Setapak_Tenure', 'Mukim_Mukim Setapak_ParcelArea']],\n",
        "                          level_dummies[['UnitLevel_Mid-High', 'UnitLevel_High']]], axis=1).astype(np.float32)\n",
        "    X_sample_seq = np.zeros((1, sequence_length, len(features)), dtype=np.float32)\n",
        "    X_sample_seq[0, -1] = X_sample[features].values\n",
        "    for t in range(1, sequence_length):\n",
        "        if df_sample['Year'].iloc[0] - t >= 2021:\n",
        "            X_sample_seq[0, sequence_length - t - 1] = X_sample[features].values\n",
        "            X_sample_seq[0, sequence_length - t - 1, 2] = (df_sample['Year'].iloc[0] - t - 2023) / 2.0\n",
        "    X_sample_seq[:, :, [0, 1, 2, 7]] = scaler.transform(X_sample_seq[:, :, [0, 1, 2, 7]].reshape(-1, 4)).reshape(1, sequence_length, 4)\n",
        "    return X_sample_seq\n",
        "\n",
        "# Define sample inputs\n",
        "sample_inputs = [\n",
        "    {'SchemeName': 'The Edge', 'ParcelArea': 80.0, 'Year': 2025.0, 'Mukim': 'Mukim Setapak', 'Tenure': 'Freehold', 'UnitLevel': 15},\n",
        "    {'SchemeName': 'The Edge', 'ParcelArea': 80.0, 'Year': 2025.0, 'Mukim': 'Mukim Setapak', 'Tenure': 'Freehold', 'UnitLevel': 25}\n",
        "]\n",
        "\n",
        "# Predict for both inputs\n",
        "area_cap = 90.0\n",
        "features = ['Scheme_Name_encoded', 'ParcelArea', 'Year', 'Mukim_Mukim Setapak_Tenure', 'Mukim_Mukim Setapak_ParcelArea', 'UnitLevel_Mid-High', 'UnitLevel_High', 'ParcelArea_UnitLevel']\n",
        "for sample in sample_inputs:\n",
        "    X_sample = preprocess_sample(sample, scheme_encoding, scaler, y_scaler, features, area_cap)\n",
        "    y_pred_rnn = rnn_model.predict(X_sample, verbose=0).flatten()[0]\n",
        "    y_pred_rnn_log = y_scaler.inverse_transform([[y_pred_rnn]])[0, 0]\n",
        "    y_pred_rnn_rm = np.expm1(y_pred_rnn_log)\n",
        "    y_pred_gru = gru_model.predict(X_sample, verbose=0).flatten()[0]\n",
        "    y_pred_gru_log = y_scaler.inverse_transform([[y_pred_gru]])[0, 0]\n",
        "    y_pred_gru_rm = np.expm1(y_pred_gru_log)\n",
        "    y_pred_transformer = transformer_model.predict(X_sample, verbose=0).flatten()[0]\n",
        "    y_pred_transformer_log = y_scaler.inverse_transform([[y_pred_transformer]])[0, 0]\n",
        "    y_pred_transformer_rm = np.expm1(y_pred_transformer_log)\n",
        "    print(\"Preprocessed X_sample:\\n\", X_sample[0])\n",
        "    print(\"RNN Predicted TransactionPrice (log-scale):\", y_pred_rnn_log)\n",
        "    print(\"RNN Predicted TransactionPrice (RM):\", y_pred_rnn_rm)\n",
        "    print(\"GRU Predicted TransactionPrice (log-scale):\", y_pred_gru_log)\n",
        "    print(\"GRU Predicted TransactionPrice (RM):\", y_pred_gru_rm)\n",
        "    print(\"Transformer Predicted TransactionPrice (log-scale):\", y_pred_transformer_log)\n",
        "    print(\"Transformer Predicted TransactionPrice (RM):\", y_pred_transformer_rm)\n",
        "    print(\"Difference (RNN - GRU, RM):\", y_pred_rnn_rm - y_pred_gru_rm)\n",
        "    print(\"Difference (RNN - Transformer, RM):\", y_pred_rnn_rm - y_pred_transformer_rm)\n",
        "    print(\"Difference (GRU - Transformer, RM):\", y_pred_gru_rm - y_pred_transformer_rm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "maJP3zCgyuOo",
        "outputId": "870afc0d-48f1-4432-b4c5-e18dc1c5aea3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<>:15: SyntaxWarning: invalid escape sequence '\\d'\n",
            "<>:15: SyntaxWarning: invalid escape sequence '\\d'\n",
            "/tmp/ipython-input-2396877442.py:15: SyntaxWarning: invalid escape sequence '\\d'\n",
            "  df['ParcelArea'] = df['ParcelArea'].astype(str).str.extract('(\\d+\\.?\\d*)').astype(np.float32)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RNN R: 0.9350842237472534\n",
            "RNN RMSE (log-scale): 0.18372869604874964\n",
            "RNN RMSE (RM): 396891.1792015539\n",
            "GRU R: 0.9417749047279358\n",
            "GRU RMSE (log-scale): 0.1740031432831831\n",
            "GRU RMSE (RM): 360479.43044784124\n",
            "Transformer R: 0.9390714764595032\n",
            "Transformer RMSE (log-scale): 0.17799680848689417\n",
            "Transformer RMSE (RM): 368943.60830891214\n",
            "\n",
            "Sample: {'SchemeName': 'The Edge', 'ParcelArea': 80.0, 'Year': 2025.0, 'Mukim': 'Mukim Setapak', 'Tenure': 'Freehold', 'UnitLevel': 15}\n",
            "Year capped to 2025.0 (training range: 20212025)\n",
            "Raw Scheme_Name_encoded: 13.317193031311035 (log-scale, mean=13.3172)\n",
            "UnitLevel_clean: 15.0, UnitLevel_binned: Mid-High\n",
            "Preprocessed X_sample:\n",
            " [[ 1.3972817e-01 -7.2834879e-01 -1.0115000e+03  1.0000000e+00\n",
            "   4.3944492e+00  1.0000000e+00  0.0000000e+00  1.2256704e-01]\n",
            " [ 1.3972817e-01 -7.2834879e-01 -1.0112500e+03  1.0000000e+00\n",
            "   4.3944492e+00  1.0000000e+00  0.0000000e+00  1.2256704e-01]\n",
            " [ 1.3972817e-01 -7.2834879e-01  1.0000000e+00  1.0000000e+00\n",
            "   4.3944492e+00  1.0000000e+00  0.0000000e+00  1.2256704e-01]]\n",
            "RNN Predicted TransactionPrice (log-scale): 13.334184275128703\n",
            "RNN Predicted TransactionPrice (RM): 617962.254002218\n",
            "GRU Predicted TransactionPrice (log-scale): 12.666590427511629\n",
            "GRU Predicted TransactionPrice (RM): 316977.8804683069\n",
            "Transformer Predicted TransactionPrice (log-scale): 14.881231961251592\n",
            "Transformer Predicted TransactionPrice (RM): 2902931.4138514916\n",
            "Difference (RNN - GRU, RM): 300984.37353391113\n",
            "Difference (RNN - Transformer, RM): -2284969.1598492735\n",
            "Difference (GRU - Transformer, RM): -2585953.5333831846\n",
            "\n",
            "Sample: {'SchemeName': 'The Edge', 'ParcelArea': 80.0, 'Year': 2025.0, 'Mukim': 'Mukim Setapak', 'Tenure': 'Freehold', 'UnitLevel': 25}\n",
            "Year capped to 2025.0 (training range: 20212025)\n",
            "Raw Scheme_Name_encoded: 13.317193031311035 (log-scale, mean=13.3172)\n",
            "UnitLevel_clean: 25.0, UnitLevel_binned: High\n",
            "Preprocessed X_sample:\n",
            " [[ 1.3972817e-01 -7.2834879e-01 -1.0115000e+03  1.0000000e+00\n",
            "   4.3944492e+00  0.0000000e+00  1.0000000e+00  7.6628447e-01]\n",
            " [ 1.3972817e-01 -7.2834879e-01 -1.0112500e+03  1.0000000e+00\n",
            "   4.3944492e+00  0.0000000e+00  1.0000000e+00  7.6628447e-01]\n",
            " [ 1.3972817e-01 -7.2834879e-01  1.0000000e+00  1.0000000e+00\n",
            "   4.3944492e+00  0.0000000e+00  1.0000000e+00  7.6628447e-01]]\n",
            "RNN Predicted TransactionPrice (log-scale): 13.437359582284305\n",
            "RNN Predicted TransactionPrice (RM): 685126.0553341579\n",
            "GRU Predicted TransactionPrice (log-scale): 12.851592419961012\n",
            "GRU Predicted TransactionPrice (RM): 381394.5940211583\n",
            "Transformer Predicted TransactionPrice (log-scale): 14.883132982453862\n",
            "Transformer Predicted TransactionPrice (RM): 2908455.1986714853\n",
            "Difference (RNN - GRU, RM): 303731.4613129996\n",
            "Difference (RNN - Transformer, RM): -2223329.1433373275\n",
            "Difference (GRU - Transformer, RM): -2527060.604650327\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import RobustScaler, StandardScaler\n",
        "from sklearn.metrics import r2_score, mean_squared_error\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, SimpleRNN, GRU, Dense, Layer, MultiHeadAttention, LayerNormalization, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "import joblib\n",
        "\n",
        "# Load data\n",
        "url = \"https://raw.githubusercontent.com/englian1123/KL-High-Rise-Data/refs/heads/main/KLHighRise.csv\"\n",
        "df = pd.read_csv(url)\n",
        "df.rename(columns={'TransactionPrice  ': 'TransactionPrice', 'Parcel Area': 'ParcelArea', 'Scheme Name/Area': 'SchemeName'}, inplace=True)\n",
        "df['ParcelArea'] = df['ParcelArea'].astype(str).str.extract('(\\d+\\.?\\d*)').astype(np.float32)\n",
        "df['Tenure'] = df['Tenure'].map({'Freehold': 1, 'Leasehold': 0}).fillna(0).astype(np.float32)\n",
        "\n",
        "# Outlier capping (only ParcelArea)\n",
        "area_cap = df['ParcelArea'].quantile(0.90)\n",
        "df['ParcelArea'] = np.clip(df['ParcelArea'], 0, area_cap).astype(np.float32)\n",
        "\n",
        "# Log-transform\n",
        "df['TransactionPrice'] = np.log1p(df['TransactionPrice']).astype(np.float32)\n",
        "df['ParcelArea'] = np.log1p(df['ParcelArea']).astype(np.float32)\n",
        "\n",
        "# Target encode SchemeName\n",
        "scheme_encoding = df.groupby('SchemeName')['TransactionPrice'].mean().astype(np.float32)\n",
        "df['Scheme_Name_encoded'] = df['SchemeName'].map(scheme_encoding).fillna(scheme_encoding.mean()).astype(np.float32)\n",
        "joblib.dump(scheme_encoding, 'scheme_encoding_rnn_gru_transformer_v5.joblib')\n",
        "\n",
        "# Add Year\n",
        "df['TransactionDate'] = pd.to_datetime(df['TransactionDate'], format='%b-%y')\n",
        "df['Year'] = df['TransactionDate'].dt.year.astype(np.float32)\n",
        "\n",
        "# Clean UnitLevel\n",
        "unit_level_map = {'03A': 4, '12B': 12, '13A': 14, '23A': 24, '33A': 34, '43A': 44, '53A': 54,\n",
        "                  'B': 0, 'D': 0, 'G': 0, 'LG': 0, 'MZ': 0, 'P': 0, 'UG': 0,\n",
        "                  '1/5/2025': 0, '2/3/2025': 0, '1/4/2025': 0}\n",
        "df['UnitLevel_clean'] = df['UnitLevel'].replace(unit_level_map)\n",
        "unit_level_mean = pd.to_numeric(df['UnitLevel_clean'], errors='coerce').mean()\n",
        "df['UnitLevel_clean'] = pd.to_numeric(df['UnitLevel_clean'], errors='coerce').fillna(unit_level_mean).astype(np.float32)\n",
        "df['UnitLevel_binned'] = pd.cut(df['UnitLevel_clean'], bins=[-float('inf'), 5, 15, 25, float('inf')], labels=['Low', 'Mid-Low', 'Mid-High', 'High'], right=False)\n",
        "level_dummies = pd.get_dummies(df['UnitLevel_binned'], prefix='UnitLevel', dtype=np.float32)\n",
        "\n",
        "# Setapak interactions\n",
        "mukim_dummies = pd.get_dummies(df['Mukim'], prefix='Mukim', dtype=np.float32)\n",
        "df['Mukim_Mukim Setapak_Tenure'] = (mukim_dummies.get('Mukim_Mukim Setapak', pd.Series(0, index=df.index)) * df['Tenure']).astype(np.float32)\n",
        "df['Mukim_Mukim Setapak_ParcelArea'] = (mukim_dummies.get('Mukim_Mukim Setapak', pd.Series(0, index=df.index)) * df['ParcelArea']).astype(np.float32)\n",
        "df['ParcelArea_UnitLevel'] = (df['ParcelArea'] * df['UnitLevel_clean']).astype(np.float32)\n",
        "\n",
        "# Features\n",
        "features = ['Scheme_Name_encoded', 'ParcelArea', 'Year', 'Mukim_Mukim Setapak_Tenure', 'Mukim_Mukim Setapak_ParcelArea', 'UnitLevel_Mid-High', 'UnitLevel_High', 'ParcelArea_UnitLevel']\n",
        "X = pd.concat([df[['Scheme_Name_encoded', 'ParcelArea', 'Year', 'ParcelArea_UnitLevel']],\n",
        "               df[['Mukim_Mukim Setapak_Tenure', 'Mukim_Mukim Setapak_ParcelArea']],\n",
        "               level_dummies[['UnitLevel_Mid-High', 'UnitLevel_High']]], axis=1).astype(np.float32)\n",
        "y = df['TransactionPrice'].astype(np.float32)\n",
        "\n",
        "# Standardize target\n",
        "y_scaler = StandardScaler()\n",
        "y = y_scaler.fit_transform(y.values.reshape(-1, 1)).flatten().astype(np.float32)\n",
        "joblib.dump(y_scaler, 'y_scaler_rnn_gru_transformer_v5.joblib')\n",
        "\n",
        "# Create sequences (3 timesteps)\n",
        "sequence_length = 3\n",
        "X_seq = []\n",
        "y_seq = []\n",
        "for idx in range(len(X)):\n",
        "    year = X.iloc[idx]['Year']\n",
        "    sample = X.iloc[idx][features].values\n",
        "    seq = np.zeros((sequence_length, len(features)), dtype=np.float32)\n",
        "    seq[-1] = sample  # Current year\n",
        "    for t in range(1, sequence_length):\n",
        "        if year - t >= 2021:\n",
        "            seq[sequence_length - t - 1] = sample.copy()\n",
        "            seq[sequence_length - t - 1][2] = (year - t - 2023) / 2.0  # Year scaling: 2023=-1, 2024=-0.5, 2025=0\n",
        "    X_seq.append(seq)\n",
        "    y_seq.append(y[idx])\n",
        "X_seq = np.array(X_seq)\n",
        "y_seq = np.array(y_seq)\n",
        "\n",
        "# Split data\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_seq, y_seq, test_size=0.2, random_state=42)\n",
        "\n",
        "# Scale features\n",
        "scaler = RobustScaler()\n",
        "for t in range(sequence_length):\n",
        "    X_train[:, t, [0, 1, 2, 7]] = scaler.fit_transform(X_train[:, t, [0, 1, 2, 7]]).astype(np.float32)\n",
        "    X_test[:, t, [0, 1, 2, 7]] = scaler.transform(X_test[:, t, [0, 1, 2, 7]]).astype(np.float32)\n",
        "joblib.dump(scaler, 'scaler_rnn_gru_transformer_v5.joblib')\n",
        "\n",
        "# RNN Model\n",
        "inputs = Input(shape=(sequence_length, len(features)))\n",
        "x = SimpleRNN(128, return_sequences=False, kernel_regularizer=tf.keras.regularizers.l2(0.01))(inputs)\n",
        "x = Dropout(0.3)(x)\n",
        "x = Dense(64, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01))(x)\n",
        "x = Dropout(0.3)(x)\n",
        "outputs = Dense(1)(x)\n",
        "rnn_model = Model(inputs, outputs)\n",
        "rnn_model.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n",
        "rnn_model.fit(X_train, y_train, epochs=200, batch_size=32, validation_data=(X_test, y_test),\n",
        "              callbacks=[tf.keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True),\n",
        "                         ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-5)], verbose=0)\n",
        "joblib.dump(rnn_model, 'rnn_model_v5.joblib')\n",
        "\n",
        "# GRU Model\n",
        "x = GRU(128, return_sequences=False, kernel_regularizer=tf.keras.regularizers.l2(0.01))(inputs)\n",
        "x = Dropout(0.3)(x)\n",
        "x = Dense(64, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01))(x)\n",
        "x = Dropout(0.3)(x)\n",
        "outputs = Dense(1)(x)\n",
        "gru_model = Model(inputs, outputs)\n",
        "gru_model.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n",
        "gru_model.fit(X_train, y_train, epochs=200, batch_size=32, validation_data=(X_test, y_test),\n",
        "              callbacks=[tf.keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True),\n",
        "                         ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-5)], verbose=0)\n",
        "joblib.dump(gru_model, 'gru_model_v5.joblib')\n",
        "\n",
        "# Transformer Model\n",
        "class TransformerBlock(Layer):\n",
        "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.3):\n",
        "        super(TransformerBlock, self).__init__()\n",
        "        self.att = MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.ffn = tf.keras.Sequential([Dense(ff_dim, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
        "                                        Dense(embed_dim)])\n",
        "        self.layernorm1 = LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = LayerNormalization(epsilon=1e-6)\n",
        "        self.dropout1 = Dropout(rate)\n",
        "        self.dropout2 = Dropout(rate)\n",
        "    def call(self, inputs, training=False):\n",
        "        attn_output = self.att(inputs, inputs)\n",
        "        attn_output = self.dropout1(attn_output, training=training)\n",
        "        out1 = self.layernorm1(inputs + attn_output)\n",
        "        ffn_output = self.ffn(out1)\n",
        "        ffn_output = self.dropout2(ffn_output, training=training)\n",
        "        return self.layernorm2(out1 + ffn_output)\n",
        "\n",
        "class PositionalEncoding(Layer):\n",
        "    def __init__(self, sequence_length, embed_dim):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        pos_enc = np.array([[pos / np.power(10000, 2 * (i // 2) / embed_dim) for i in range(embed_dim)] for pos in range(sequence_length)])\n",
        "        pos_enc[:, 0::2] = np.sin(pos_enc[:, 0::2])\n",
        "        pos_enc[:, 1::2] = np.cos(pos_enc[:, 1::2])\n",
        "        self.pos_encoding = tf.cast(pos_enc, dtype=tf.float32)\n",
        "    def call(self, inputs):\n",
        "        return inputs + self.pos_encoding\n",
        "\n",
        "inputs = Input(shape=(sequence_length, len(features)))\n",
        "x = PositionalEncoding(sequence_length, len(features))(inputs)\n",
        "x = TransformerBlock(embed_dim=len(features), num_heads=8, ff_dim=128)(x, training=True)\n",
        "x = TransformerBlock(embed_dim=len(features), num_heads=8, ff_dim=128)(x, training=True)\n",
        "x = tf.keras.layers.GlobalAveragePooling1D()(x)\n",
        "x = Dense(64, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01))(x)\n",
        "x = Dropout(0.3)(x)\n",
        "outputs = Dense(1)(x)\n",
        "transformer_model = Model(inputs, outputs)\n",
        "transformer_model.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n",
        "transformer_model.fit(X_train, y_train, epochs=200, batch_size=32, validation_data=(X_test, y_test),\n",
        "                     callbacks=[tf.keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True),\n",
        "                                ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-5)], verbose=0)\n",
        "joblib.dump(transformer_model, 'transformer_model_v5.joblib')\n",
        "\n",
        "# Evaluate models\n",
        "y_pred_rnn = rnn_model.predict(X_test, verbose=0).flatten()\n",
        "y_pred_rnn_log = y_scaler.inverse_transform(y_pred_rnn.reshape(-1, 1)).flatten()\n",
        "y_test_log = y_scaler.inverse_transform(y_test.reshape(-1, 1)).flatten()\n",
        "rnn_r2 = r2_score(y_test_log, y_pred_rnn_log)\n",
        "rnn_rmse_log = np.sqrt(mean_squared_error(y_test_log, y_pred_rnn_log))\n",
        "rnn_rmse_rm = np.sqrt(mean_squared_error(np.expm1(y_test_log), np.expm1(y_pred_rnn_log)))\n",
        "\n",
        "y_pred_gru = gru_model.predict(X_test, verbose=0).flatten()\n",
        "y_pred_gru_log = y_scaler.inverse_transform(y_pred_gru.reshape(-1, 1)).flatten()\n",
        "gru_r2 = r2_score(y_test_log, y_pred_gru_log)\n",
        "gru_rmse_log = np.sqrt(mean_squared_error(y_test_log, y_pred_gru_log))\n",
        "gru_rmse_rm = np.sqrt(mean_squared_error(np.expm1(y_test_log), np.expm1(y_pred_gru_log)))\n",
        "\n",
        "y_pred_transformer = transformer_model.predict(X_test, verbose=0).flatten()\n",
        "y_pred_transformer_log = y_scaler.inverse_transform(y_pred_transformer.reshape(-1, 1)).flatten()\n",
        "transformer_r2 = r2_score(y_test_log, y_pred_transformer_log)\n",
        "transformer_rmse_log = np.sqrt(mean_squared_error(y_test_log, y_pred_transformer_log))\n",
        "transformer_rmse_rm = np.sqrt(mean_squared_error(np.expm1(y_test_log), np.expm1(y_pred_transformer_log)))\n",
        "\n",
        "print(\"RNN R:\", rnn_r2)\n",
        "print(\"RNN RMSE (log-scale):\", rnn_rmse_log)\n",
        "print(\"RNN RMSE (RM):\", rnn_rmse_rm)\n",
        "print(\"GRU R:\", gru_r2)\n",
        "print(\"GRU RMSE (log-scale):\", gru_rmse_log)\n",
        "print(\"GRU RMSE (RM):\", gru_rmse_rm)\n",
        "print(\"Transformer R:\", transformer_r2)\n",
        "print(\"Transformer RMSE (log-scale):\", transformer_rmse_log)\n",
        "print(\"Transformer RMSE (RM):\", transformer_rmse_rm)\n",
        "\n",
        "# Preprocessing function for samples\n",
        "def preprocess_sample(sample, scheme_encoding, scaler, y_scaler, features, area_cap, year_max=2025.0, sequence_length=3):\n",
        "    df_sample = pd.DataFrame([sample])\n",
        "    df_sample['Year'] = np.clip(df_sample['Year'], 2021.0, year_max).astype(np.float32)\n",
        "    print(f\"\\nSample: {sample}\")\n",
        "    print(f\"Year capped to {df_sample['Year'].iloc[0]} (training range: 20212025)\")\n",
        "    df_sample['ParcelArea'] = np.log1p(np.clip(df_sample['ParcelArea'], 0, area_cap)).astype(np.float32)\n",
        "    raw_scheme_encoding = df_sample['SchemeName'].map(scheme_encoding).fillna(scheme_encoding.mean()).astype(np.float32)\n",
        "    print(f\"Raw Scheme_Name_encoded: {raw_scheme_encoding.iloc[0]} (log-scale, mean={scheme_encoding.mean():.4f})\")\n",
        "    df_sample['Scheme_Name_encoded'] = raw_scheme_encoding\n",
        "    df_sample['Tenure'] = df_sample['Tenure'].map({'Freehold': 1, 'Leasehold': 0}).fillna(0).astype(np.float32)\n",
        "    unit_level_map = {'03A': 4, '12B': 12, '13A': 14, '23A': 24, '33A': 34, '43A': 44, '53A': 54,\n",
        "                      'B': 0, 'D': 0, 'G': 0, 'LG': 0, 'MZ': 0, 'P': 0, 'UG': 0,\n",
        "                      '1/5/2025': 0, '2/3/2025': 0, '1/4/2025': 0}\n",
        "    df_sample['UnitLevel_clean'] = df_sample['UnitLevel'].replace(unit_level_map)\n",
        "    df_sample['UnitLevel_clean'] = pd.to_numeric(df_sample['UnitLevel_clean'], errors='coerce').fillna(10.0).astype(np.float32)\n",
        "    df_sample['UnitLevel_binned'] = pd.cut(df_sample['UnitLevel_clean'], bins=[-float('inf'), 5, 15, 25, float('inf')], labels=['Low', 'Mid-Low', 'Mid-High', 'High'], right=False)\n",
        "    print(f\"UnitLevel_clean: {df_sample['UnitLevel_clean'].iloc[0]}, UnitLevel_binned: {df_sample['UnitLevel_binned'].iloc[0]}\")\n",
        "    level_dummies = pd.get_dummies(df_sample['UnitLevel_binned'], prefix='UnitLevel', dtype=np.float32)\n",
        "    if 'UnitLevel_Mid-High' not in level_dummies:\n",
        "        level_dummies['UnitLevel_Mid-High'] = 0.0\n",
        "    if 'UnitLevel_High' not in level_dummies:\n",
        "        level_dummies['UnitLevel_High'] = 0.0\n",
        "    level_dummies = level_dummies[['UnitLevel_Mid-High', 'UnitLevel_High']].astype(np.float32)\n",
        "    df_sample['Mukim_Mukim Setapak_Tenure'] = (df_sample['Mukim'].eq('Mukim Setapak').astype(np.float32) * df_sample['Tenure']).astype(np.float32)\n",
        "    df_sample['Mukim_Mukim Setapak_ParcelArea'] = (df_sample['Mukim'].eq('Mukim Setapak').astype(np.float32) * df_sample['ParcelArea']).astype(np.float32)\n",
        "    df_sample['ParcelArea_UnitLevel'] = (df_sample['ParcelArea'] * df_sample['UnitLevel_clean']).astype(np.float32)\n",
        "    X_sample = pd.concat([df_sample[['Scheme_Name_encoded', 'ParcelArea', 'Year', 'ParcelArea_UnitLevel']],\n",
        "                          df_sample[['Mukim_Mukim Setapak_Tenure', 'Mukim_Mukim Setapak_ParcelArea']],\n",
        "                          level_dummies[['UnitLevel_Mid-High', 'UnitLevel_High']]], axis=1).astype(np.float32)\n",
        "    X_sample_seq = np.zeros((1, sequence_length, len(features)), dtype=np.float32)\n",
        "    X_sample_seq[0, -1] = X_sample[features].values\n",
        "    for t in range(1, sequence_length):\n",
        "        if df_sample['Year'].iloc[0] - t >= 2021:\n",
        "            X_sample_seq[0, sequence_length - t - 1] = X_sample[features].values\n",
        "            X_sample_seq[0, sequence_length - t - 1, 2] = (df_sample['Year'].iloc[0] - t - 2023) / 2.0\n",
        "    X_sample_seq[:, :, [0, 1, 2, 7]] = scaler.transform(X_sample_seq[:, :, [0, 1, 2, 7]].reshape(-1, 4)).reshape(1, sequence_length, 4)\n",
        "    return X_sample_seq\n",
        "\n",
        "# Define sample inputs\n",
        "sample_inputs = [\n",
        "    {'SchemeName': 'The Edge', 'ParcelArea': 80.0, 'Year': 2025.0, 'Mukim': 'Mukim Setapak', 'Tenure': 'Freehold', 'UnitLevel': 15},\n",
        "    {'SchemeName': 'The Edge', 'ParcelArea': 80.0, 'Year': 2025.0, 'Mukim': 'Mukim Setapak', 'Tenure': 'Freehold', 'UnitLevel': 25}\n",
        "]\n",
        "\n",
        "# Predict for both inputs\n",
        "area_cap = 90.0\n",
        "features = ['Scheme_Name_encoded', 'ParcelArea', 'Year', 'Mukim_Mukim Setapak_Tenure', 'Mukim_Mukim Setapak_ParcelArea', 'UnitLevel_Mid-High', 'UnitLevel_High', 'ParcelArea_UnitLevel']\n",
        "for sample in sample_inputs:\n",
        "    X_sample = preprocess_sample(sample, scheme_encoding, scaler, y_scaler, features, area_cap)\n",
        "    y_pred_rnn = rnn_model.predict(X_sample, verbose=0).flatten()[0]\n",
        "    y_pred_rnn_log = y_scaler.inverse_transform([[y_pred_rnn]])[0, 0]\n",
        "    y_pred_rnn_rm = np.expm1(y_pred_rnn_log)\n",
        "    y_pred_gru = gru_model.predict(X_sample, verbose=0).flatten()[0]\n",
        "    y_pred_gru_log = y_scaler.inverse_transform([[y_pred_gru]])[0, 0]\n",
        "    y_pred_gru_rm = np.expm1(y_pred_gru_log)\n",
        "    y_pred_transformer = transformer_model.predict(X_sample, verbose=0).flatten()[0]\n",
        "    y_pred_transformer_log = y_scaler.inverse_transform([[y_pred_transformer]])[0, 0]\n",
        "    y_pred_transformer_rm = np.expm1(y_pred_transformer_log)\n",
        "    print(\"Preprocessed X_sample:\\n\", X_sample[0])\n",
        "    print(\"RNN Predicted TransactionPrice (log-scale):\", y_pred_rnn_log)\n",
        "    print(\"RNN Predicted TransactionPrice (RM):\", y_pred_rnn_rm)\n",
        "    print(\"GRU Predicted TransactionPrice (log-scale):\", y_pred_gru_log)\n",
        "    print(\"GRU Predicted TransactionPrice (RM):\", y_pred_gru_rm)\n",
        "    print(\"Transformer Predicted TransactionPrice (log-scale):\", y_pred_transformer_log)\n",
        "    print(\"Transformer Predicted TransactionPrice (RM):\", y_pred_transformer_rm)\n",
        "    print(\"Difference (RNN - GRU, RM):\", y_pred_rnn_rm - y_pred_gru_rm)\n",
        "    print(\"Difference (RNN - Transformer, RM):\", y_pred_rnn_rm - y_pred_transformer_rm)\n",
        "    print(\"Difference (GRU - Transformer, RM):\", y_pred_gru_rm - y_pred_transformer_rm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0rXlQqLe7OqW",
        "outputId": "0cbcc389-ff20-44b8-b40f-3f567fa13b50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<>:16: SyntaxWarning: invalid escape sequence '\\d'\n",
            "<>:16: SyntaxWarning: invalid escape sequence '\\d'\n",
            "/tmp/ipython-input-3987708383.py:16: SyntaxWarning: invalid escape sequence '\\d'\n",
            "  df['ParcelArea'] = df['ParcelArea'].astype(str).str.extract('(\\d+\\.?\\d*)').astype(np.float32)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RNN R: 0.931297242641449\n",
            "RNN RMSE (log-scale): 0.18901184640888327\n",
            "RNN RMSE (RM): 411002.16003325337\n",
            "GRU R: 0.934729814529419\n",
            "GRU RMSE (log-scale): 0.18422955134323332\n",
            "GRU RMSE (RM): 385752.2474542436\n",
            "Transformer R: 0.9400649070739746\n",
            "Transformer RMSE (log-scale): 0.176539744961645\n",
            "Transformer RMSE (RM): 370348.34162447654\n",
            "\n",
            "Sample: {'SchemeName': 'The Edge', 'ParcelArea': 80.0, 'Year': 2025.0, 'Mukim': 'Mukim Setapak', 'Tenure': 'Freehold', 'UnitLevel': 15}\n",
            "Year capped to 2025.0 (training range: 20212025)\n",
            "Raw Scheme_Name_encoded: 13.317193031311035 (log-scale, mean=13.3172)\n",
            "UnitLevel_clean: 15.0, UnitLevel_binned: Mid-High\n",
            "Preprocessed X_sample:\n",
            " [[ 1.3972817e-01 -7.2834879e-01 -1.0115000e+03  1.0000000e+00\n",
            "   4.3944492e+00  1.0000000e+00  0.0000000e+00  1.2256704e-01]\n",
            " [ 1.3972817e-01 -7.2834879e-01 -1.0112500e+03  1.0000000e+00\n",
            "   4.3944492e+00  1.0000000e+00  0.0000000e+00  1.2256704e-01]\n",
            " [ 1.3972817e-01 -7.2834879e-01  1.0000000e+00  1.0000000e+00\n",
            "   4.3944492e+00  1.0000000e+00  0.0000000e+00  1.2256704e-01]]\n",
            "RNN Predicted TransactionPrice (log-scale): 8.545680641916988\n",
            "RNN Predicted TransactionPrice (RM): 5143.485493050682\n",
            "GRU Predicted TransactionPrice (log-scale): 12.029031937593809\n",
            "GRU Predicted TransactionPrice (RM): 167548.13618619714\n",
            "Transformer Predicted TransactionPrice (log-scale): 13.960636151887051\n",
            "Transformer Predicted TransactionPrice (RM): 1156183.770930507\n",
            "Difference (RNN - GRU, RM): -162404.65069314645\n",
            "Difference (RNN - Transformer, RM): -1151040.2854374563\n",
            "Difference (GRU - Transformer, RM): -988635.6347443098\n",
            "\n",
            "Sample: {'SchemeName': 'The Edge', 'ParcelArea': 80.0, 'Year': 2025.0, 'Mukim': 'Mukim Setapak', 'Tenure': 'Freehold', 'UnitLevel': 25}\n",
            "Year capped to 2025.0 (training range: 20212025)\n",
            "Raw Scheme_Name_encoded: 13.317193031311035 (log-scale, mean=13.3172)\n",
            "UnitLevel_clean: 25.0, UnitLevel_binned: High\n",
            "Preprocessed X_sample:\n",
            " [[ 1.3972817e-01 -7.2834879e-01 -1.0115000e+03  1.0000000e+00\n",
            "   4.3944492e+00  0.0000000e+00  1.0000000e+00  7.6628447e-01]\n",
            " [ 1.3972817e-01 -7.2834879e-01 -1.0112500e+03  1.0000000e+00\n",
            "   4.3944492e+00  0.0000000e+00  1.0000000e+00  7.6628447e-01]\n",
            " [ 1.3972817e-01 -7.2834879e-01  1.0000000e+00  1.0000000e+00\n",
            "   4.3944492e+00  0.0000000e+00  1.0000000e+00  7.6628447e-01]]\n",
            "RNN Predicted TransactionPrice (log-scale): 8.570150109750887\n",
            "RNN Predicted TransactionPrice (RM): 5270.921097563811\n",
            "GRU Predicted TransactionPrice (log-scale): 12.03285997483649\n",
            "GRU Predicted TransactionPrice (RM): 168190.74970901513\n",
            "Transformer Predicted TransactionPrice (log-scale): 13.935274959164412\n",
            "Transformer Predicted TransactionPrice (RM): 1127230.2459637055\n",
            "Difference (RNN - GRU, RM): -162919.82861145132\n",
            "Difference (RNN - Transformer, RM): -1121959.3248661417\n",
            "Difference (GRU - Transformer, RM): -959039.4962546903\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import RobustScaler, StandardScaler\n",
        "from sklearn.metrics import r2_score, mean_squared_error\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, SimpleRNN, GRU, Dense, Layer, MultiHeadAttention, LayerNormalization, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "import joblib\n",
        "\n",
        "# Load data\n",
        "url = \"https://raw.githubusercontent.com/englian1123/KL-High-Rise-Data/refs/heads/main/KLHighRise.csv\"\n",
        "df = pd.read_csv(url)\n",
        "df.rename(columns={'TransactionPrice  ': 'TransactionPrice', 'Parcel Area': 'ParcelArea', 'Scheme Name/Area': 'SchemeName'}, inplace=True)\n",
        "df['ParcelArea'] = df['ParcelArea'].astype(str).str.extract('(\\d+\\.?\\d*)').astype(np.float32)\n",
        "df['Tenure'] = df['Tenure'].map({'Freehold': 1, 'Leasehold': 0}).fillna(0).astype(np.float32)\n",
        "\n",
        "# Outlier capping (only ParcelArea)\n",
        "area_cap = df['ParcelArea'].quantile(0.90)\n",
        "df['ParcelArea'] = np.clip(df['ParcelArea'], 0, area_cap).astype(np.float32)\n",
        "\n",
        "# Log-transform\n",
        "df['TransactionPrice'] = np.log1p(df['TransactionPrice']).astype(np.float32)\n",
        "df['ParcelArea'] = np.log1p(df['ParcelArea']).astype(np.float32)\n",
        "\n",
        "# Target encode SchemeName\n",
        "scheme_encoding = df.groupby('SchemeName')['TransactionPrice'].mean().astype(np.float32)\n",
        "df['Scheme_Name_encoded'] = df['SchemeName'].map(scheme_encoding).fillna(scheme_encoding.mean()).astype(np.float32)\n",
        "joblib.dump(scheme_encoding, 'scheme_encoding_rnn_gru_transformer_v6.joblib')\n",
        "\n",
        "# Add Year\n",
        "df['TransactionDate'] = pd.to_datetime(df['TransactionDate'], format='%b-%y')\n",
        "df['Year'] = df['TransactionDate'].dt.year.astype(np.float32)\n",
        "\n",
        "# Clean UnitLevel\n",
        "unit_level_map = {'03A': 4, '12B': 12, '13A': 14, '23A': 24, '33A': 34, '43A': 44, '53A': 54,\n",
        "                  'B': 0, 'D': 0, 'G': 0, 'LG': 0, 'MZ': 0, 'P': 0, 'UG': 0,\n",
        "                  '1/5/2025': 0, '2/3/2025': 0, '1/4/2025': 0}\n",
        "df['UnitLevel_clean'] = df['UnitLevel'].replace(unit_level_map)\n",
        "unit_level_mean = pd.to_numeric(df['UnitLevel_clean'], errors='coerce').mean()\n",
        "df['UnitLevel_clean'] = pd.to_numeric(df['UnitLevel_clean'], errors='coerce').fillna(unit_level_mean).astype(np.float32)\n",
        "df['UnitLevel_binned'] = pd.cut(df['UnitLevel_clean'], bins=[-float('inf'), 5, 15, 25, float('inf')], labels=['Low', 'Mid-Low', 'Mid-High', 'High'], right=False)\n",
        "level_dummies = pd.get_dummies(df['UnitLevel_binned'], prefix='UnitLevel', dtype=np.float32)\n",
        "\n",
        "# Setapak interactions\n",
        "mukim_dummies = pd.get_dummies(df['Mukim'], prefix='Mukim', dtype=np.float32)\n",
        "df['Mukim_Mukim Setapak_Tenure'] = (mukim_dummies.get('Mukim_Mukim Setapak', pd.Series(0, index=df.index)) * df['Tenure']).astype(np.float32)\n",
        "df['Mukim_Mukim Setapak_ParcelArea'] = (mukim_dummies.get('Mukim_Mukim Setapak', pd.Series(0, index=df.index)) * df['ParcelArea']).astype(np.float32)\n",
        "df['ParcelArea_UnitLevel'] = (df['ParcelArea'] * df['UnitLevel_clean']).astype(np.float32)\n",
        "\n",
        "# Features\n",
        "features = ['Scheme_Name_encoded', 'ParcelArea', 'Year', 'Mukim_Mukim Setapak_Tenure', 'Mukim_Mukim Setapak_ParcelArea', 'UnitLevel_Mid-High', 'UnitLevel_High', 'ParcelArea_UnitLevel']\n",
        "X = pd.concat([df[['Scheme_Name_encoded', 'ParcelArea', 'Year', 'ParcelArea_UnitLevel']],\n",
        "               df[['Mukim_Mukim Setapak_Tenure', 'Mukim_Mukim Setapak_ParcelArea']],\n",
        "               level_dummies[['UnitLevel_Mid-High', 'UnitLevel_High']]], axis=1).astype(np.float32)\n",
        "y = df['TransactionPrice'].astype(np.float32)\n",
        "\n",
        "# Standardize target\n",
        "y_scaler = StandardScaler()\n",
        "y = y_scaler.fit_transform(y.values.reshape(-1, 1)).flatten().astype(np.float32)\n",
        "joblib.dump(y_scaler, 'y_scaler_rnn_gru_transformer_v6.joblib')\n",
        "\n",
        "# Create sequences (3 timesteps)\n",
        "sequence_length = 3\n",
        "X_seq = []\n",
        "y_seq = []\n",
        "for idx in range(len(X)):\n",
        "    year = X.iloc[idx]['Year']\n",
        "    sample = X.iloc[idx][features].values\n",
        "    seq = np.zeros((sequence_length, len(features)), dtype=np.float32)\n",
        "    seq[-1] = sample  # Current year\n",
        "    for t in range(1, sequence_length):\n",
        "        if year - t >= 2021:\n",
        "            seq[sequence_length - t - 1] = sample.copy()\n",
        "            seq[sequence_length - t - 1][2] = (year - t - 2023) / 2.0\n",
        "    X_seq.append(seq)\n",
        "    y_seq.append(y[idx])\n",
        "X_seq = np.array(X_seq)\n",
        "y_seq = np.array(y_seq)\n",
        "\n",
        "# Split data\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_seq, y_seq, test_size=0.2, random_state=42)\n",
        "\n",
        "# Scale features\n",
        "scaler = RobustScaler()\n",
        "for t in range(sequence_length):\n",
        "    X_train[:, t, [0, 1, 2, 7]] = scaler.fit_transform(X_train[:, t, [0, 1, 2, 7]]).astype(np.float32)\n",
        "    X_test[:, t, [0, 1, 2, 7]] = scaler.transform(X_test[:, t, [0, 1, 2, 7]]).astype(np.float32)\n",
        "joblib.dump(scaler, 'scaler_rnn_gru_transformer_v6.joblib')\n",
        "print(\"Scaler center:\", scaler.center_, \"Scaler scale:\", scaler.scale_)\n",
        "\n",
        "# RNN Model\n",
        "inputs = Input(shape=(sequence_length, len(features)))\n",
        "x = SimpleRNN(256, return_sequences=False, kernel_regularizer=tf.keras.regularizers.l2(0.02))(inputs)\n",
        "x = Dropout(0.4)(x)\n",
        "x = Dense(128, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.02))(x)\n",
        "x = Dropout(0.4)(x)\n",
        "outputs = Dense(1)(x)\n",
        "rnn_model = Model(inputs, outputs)\n",
        "rnn_model.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n",
        "rnn_model.fit(X_train, y_train, epochs=200, batch_size=32, validation_data=(X_test, y_test),\n",
        "              callbacks=[tf.keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True),\n",
        "                         ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-5)], verbose=0)\n",
        "joblib.dump(rnn_model, 'rnn_model_v6.joblib')\n",
        "\n",
        "# GRU Model\n",
        "x = GRU(256, return_sequences=False, kernel_regularizer=tf.keras.regularizers.l2(0.02))(inputs)\n",
        "x = Dropout(0.4)(x)\n",
        "x = Dense(128, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.02))(x)\n",
        "x = Dropout(0.4)(x)\n",
        "outputs = Dense(1)(x)\n",
        "gru_model = Model(inputs, outputs)\n",
        "gru_model.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n",
        "gru_model.fit(X_train, y_train, epochs=200, batch_size=32, validation_data=(X_test, y_test),\n",
        "              callbacks=[tf.keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True),\n",
        "                         ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-5)], verbose=0)\n",
        "joblib.dump(gru_model, 'gru_model_v6.joblib')\n",
        "\n",
        "# Transformer Model\n",
        "class TransformerBlock(Layer):\n",
        "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.4):\n",
        "        super(TransformerBlock, self).__init__()\n",
        "        self.att = MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.ffn = tf.keras.Sequential([Dense(ff_dim, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.02)),\n",
        "                                        Dense(embed_dim)])\n",
        "        self.layernorm1 = LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = LayerNormalization(epsilon=1e-6)\n",
        "        self.dropout1 = Dropout(rate)\n",
        "        self.dropout2 = Dropout(rate)\n",
        "    def call(self, inputs, training=False):\n",
        "        attn_output = self.att(inputs, inputs)\n",
        "        attn_output = self.dropout1(attn_output, training=training)\n",
        "        out1 = self.layernorm1(inputs + attn_output)\n",
        "        ffn_output = self.ffn(out1)\n",
        "        ffn_output = self.dropout2(ffn_output, training=training)\n",
        "        return self.layernorm2(out1 + ffn_output)\n",
        "\n",
        "class PositionalEncoding(Layer):\n",
        "    def __init__(self, sequence_length, embed_dim):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        pos_enc = np.array([[pos / np.power(10000, 2 * (i // 2) / embed_dim) for i in range(embed_dim)] for pos in range(sequence_length)])\n",
        "        pos_enc[:, 0::2] = np.sin(pos_enc[:, 0::2])\n",
        "        pos_enc[:, 1::2] = np.cos(pos_enc[:, 1::2])\n",
        "        self.pos_encoding = tf.cast(pos_enc, dtype=tf.float32)\n",
        "    def call(self, inputs):\n",
        "        return inputs + self.pos_encoding\n",
        "\n",
        "inputs = Input(shape=(sequence_length, len(features)))\n",
        "x = PositionalEncoding(sequence_length, len(features))(inputs)\n",
        "x = TransformerBlock(embed_dim=len(features), num_heads=8, ff_dim=256)(x, training=True)\n",
        "x = TransformerBlock(embed_dim=len(features), num_heads=8, ff_dim=256)(x, training=True)\n",
        "x = TransformerBlock(embed_dim=len(features), num_heads=8, ff_dim=256)(x, training=True)\n",
        "x = tf.keras.layers.GlobalAveragePooling1D()(x)\n",
        "x = Dense(128, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.02))(x)\n",
        "x = Dropout(0.4)(x)\n",
        "outputs = Dense(1)(x)\n",
        "transformer_model = Model(inputs, outputs)\n",
        "transformer_model.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n",
        "transformer_model.fit(X_train, y_train, epochs=200, batch_size=32, validation_data=(X_test, y_test),\n",
        "                     callbacks=[tf.keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True),\n",
        "                                ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-5)], verbose=0)\n",
        "joblib.dump(transformer_model, 'transformer_model_v6.joblib')\n",
        "\n",
        "# Evaluate models\n",
        "y_pred_rnn = rnn_model.predict(X_test, verbose=0).flatten()\n",
        "y_pred_rnn_log = y_scaler.inverse_transform(y_pred_rnn.reshape(-1, 1)).flatten()\n",
        "y_test_log = y_scaler.inverse_transform(y_test.reshape(-1, 1)).flatten()\n",
        "rnn_r2 = r2_score(y_test_log, y_pred_rnn_log)\n",
        "rnn_rmse_log = np.sqrt(mean_squared_error(y_test_log, y_pred_rnn_log))\n",
        "rnn_rmse_rm = np.sqrt(mean_squared_error(np.expm1(y_test_log), np.expm1(y_pred_rnn_log)))\n",
        "\n",
        "y_pred_gru = gru_model.predict(X_test, verbose=0).flatten()\n",
        "y_pred_gru_log = y_scaler.inverse_transform(y_pred_gru.reshape(-1, 1)).flatten()\n",
        "gru_r2 = r2_score(y_test_log, y_pred_gru_log)\n",
        "gru_rmse_log = np.sqrt(mean_squared_error(y_test_log, y_pred_gru_log))\n",
        "gru_rmse_rm = np.sqrt(mean_squared_error(np.expm1(y_test_log), np.expm1(y_pred_gru_log)))\n",
        "\n",
        "y_pred_transformer = transformer_model.predict(X_test, verbose=0).flatten()\n",
        "y_pred_transformer_log = y_scaler.inverse_transform(y_pred_transformer.reshape(-1, 1)).flatten()\n",
        "transformer_r2 = r2_score(y_test_log, y_pred_transformer_log)\n",
        "transformer_rmse_log = np.sqrt(mean_squared_error(y_test_log, y_pred_transformer_log))\n",
        "transformer_rmse_rm = np.sqrt(mean_squared_error(np.expm1(y_test_log), np.expm1(y_pred_transformer_log)))\n",
        "\n",
        "print(\"RNN R:\", rnn_r2)\n",
        "print(\"RNN RMSE (log-scale):\", rnn_rmse_log)\n",
        "print(\"RNN RMSE (RM):\", rnn_rmse_rm)\n",
        "print(\"GRU R:\", gru_r2)\n",
        "print(\"GRU RMSE (log-scale):\", gru_rmse_log)\n",
        "print(\"GRU RMSE (RM):\", gru_rmse_rm)\n",
        "print(\"Transformer R:\", transformer_r2)\n",
        "print(\"Transformer RMSE (log-scale):\", transformer_rmse_log)\n",
        "print(\"Transformer RMSE (RM):\", transformer_rmse_rm)\n",
        "\n",
        "# Preprocessing function for samples\n",
        "def preprocess_sample(sample, scheme_encoding, scaler, y_scaler, features, area_cap, year_max=2025.0, sequence_length=3):\n",
        "    df_sample = pd.DataFrame([sample])\n",
        "    df_sample['Year'] = np.clip(df_sample['Year'], 2021.0, year_max).astype(np.float32)\n",
        "    print(f\"\\nSample: {sample}\")\n",
        "    print(f\"Year capped to {df_sample['Year'].iloc[0]} (training range: 20212025)\")\n",
        "    df_sample['ParcelArea'] = np.log1p(np.clip(df_sample['ParcelArea'], 0, area_cap)).astype(np.float32)\n",
        "    raw_scheme_encoding = df_sample['SchemeName'].map(scheme_encoding).fillna(scheme_encoding.mean()).astype(np.float32)\n",
        "    print(f\"Raw Scheme_Name_encoded: {raw_scheme_encoding.iloc[0]} (log-scale, mean={scheme_encoding.mean():.4f})\")\n",
        "    df_sample['Scheme_Name_encoded'] = raw_scheme_encoding\n",
        "    df_sample['Tenure'] = df_sample['Tenure'].map({'Freehold': 1, 'Leasehold': 0}).fillna(0).astype(np.float32)\n",
        "    unit_level_map = {'03A': 4, '12B': 12, '13A': 14, '23A': 24, '33A': 34, '43A': 44, '53A': 54,\n",
        "                      'B': 0, 'D': 0, 'G': 0, 'LG': 0, 'MZ': 0, 'P': 0, 'UG': 0,\n",
        "                      '1/5/2025': 0, '2/3/2025': 0, '1/4/2025': 0}\n",
        "    df_sample['UnitLevel_clean'] = df_sample['UnitLevel'].replace(unit_level_map)\n",
        "    df_sample['UnitLevel_clean'] = pd.to_numeric(df_sample['UnitLevel_clean'], errors='coerce').fillna(10.0).astype(np.float32)\n",
        "    df_sample['UnitLevel_binned'] = pd.cut(df_sample['UnitLevel_clean'], bins=[-float('inf'), 5, 15, 25, float('inf')], labels=['Low', 'Mid-Low', 'Mid-High', 'High'], right=False)\n",
        "    print(f\"UnitLevel_clean: {df_sample['UnitLevel_clean'].iloc[0]}, UnitLevel_binned: {df_sample['UnitLevel_binned'].iloc[0]}\")\n",
        "    level_dummies = pd.get_dummies(df_sample['UnitLevel_binned'], prefix='UnitLevel', dtype=np.float32)\n",
        "    if 'UnitLevel_Mid-High' not in level_dummies:\n",
        "        level_dummies['UnitLevel_Mid-High'] = 0.0\n",
        "    if 'UnitLevel_High' not in level_dummies:\n",
        "        level_dummies['UnitLevel_High'] = 0.0\n",
        "    level_dummies = level_dummies[['UnitLevel_Mid-High', 'UnitLevel_High']].astype(np.float32)\n",
        "    df_sample['Mukim_Mukim Setapak_Tenure'] = (df_sample['Mukim'].eq('Mukim Setapak').astype(np.float32) * df_sample['Tenure']).astype(np.float32)\n",
        "    df_sample['Mukim_Mukim Setapak_ParcelArea'] = (df_sample['Mukim'].eq('Mukim Setapak').astype(np.float32) * df_sample['ParcelArea']).astype(np.float32)\n",
        "    df_sample['ParcelArea_UnitLevel'] = (df_sample['ParcelArea'] * df_sample['UnitLevel_clean']).astype(np.float32)\n",
        "    X_sample = pd.concat([df_sample[['Scheme_Name_encoded', 'ParcelArea', 'Year', 'ParcelArea_UnitLevel']],\n",
        "                          df_sample[['Mukim_Mukim Setapak_Tenure', 'Mukim_Mukim Setapak_ParcelArea']],\n",
        "                          level_dummies[['UnitLevel_Mid-High', 'UnitLevel_High']]], axis=1).astype(np.float32)\n",
        "    X_sample_seq = np.zeros((1, sequence_length, len(features)), dtype=np.float32)\n",
        "    X_sample_seq[0, -1] = X_sample[features].values\n",
        "    for t in range(1, sequence_length):\n",
        "        if df_sample['Year'].iloc[0] - t >= 2021:\n",
        "            X_sample_seq[0, sequence_length - t - 1] = X_sample[features].values\n",
        "            X_sample_seq[0, sequence_length - t - 1, 2] = (df_sample['Year'].iloc[0] - t - 2023) / 2.0\n",
        "    print(\"Year before scaling:\", X_sample_seq[0, :, 2])\n",
        "    X_sample_seq[:, :, [0, 1, 2, 7]] = scaler.transform(X_sample_seq[:, :, [0, 1, 2, 7]].reshape(-1, 4)).reshape(1, sequence_length, 4)\n",
        "    return X_sample_seq\n",
        "\n",
        "# Define sample inputs\n",
        "sample_inputs = [\n",
        "    {'SchemeName': 'The Edge', 'ParcelArea': 80.0, 'Year': 2025.0, 'Mukim': 'Mukim Setapak', 'Tenure': 'Freehold', 'UnitLevel': 15},\n",
        "    {'SchemeName': 'The Edge', 'ParcelArea': 80.0, 'Year': 2025.0, 'Mukim': 'Mukim Setapak', 'Tenure': 'Freehold', 'UnitLevel': 25}\n",
        "]\n",
        "\n",
        "# Predict for both inputs\n",
        "area_cap = 90.0\n",
        "features = ['Scheme_Name_encoded', 'ParcelArea', 'Year', 'Mukim_Mukim Setapak_Tenure', 'Mukim_Mukim Setapak_ParcelArea', 'UnitLevel_Mid-High', 'UnitLevel_High', 'ParcelArea_UnitLevel']\n",
        "for sample in sample_inputs:\n",
        "    X_sample = preprocess_sample(sample, scheme_encoding, scaler, y_scaler, features, area_cap)\n",
        "    y_pred_rnn = rnn_model.predict(X_sample, verbose=0).flatten()[0]\n",
        "    y_pred_rnn_log = y_scaler.inverse_transform([[y_pred_rnn]])[0, 0]\n",
        "    y_pred_rnn_rm = np.expm1(y_pred_rnn_log)\n",
        "    y_pred_gru = gru_model.predict(X_sample, verbose=0).flatten()[0]\n",
        "    y_pred_gru_log = y_scaler.inverse_transform([[y_pred_gru]])[0, 0]\n",
        "    y_pred_gru_rm = np.expm1(y_pred_gru_log)\n",
        "    y_pred_transformer = transformer_model.predict(X_sample, verbose=0).flatten()[0]\n",
        "    y_pred_transformer_log = y_scaler.inverse_transform([[y_pred_transformer]])[0, 0]\n",
        "    y_pred_transformer_rm = np.expm1(y_pred_transformer_log)\n",
        "    print(\"Preprocessed X_sample:\\n\", X_sample[0])\n",
        "    print(\"RNN Predicted TransactionPrice (log-scale):\", y_pred_rnn_log)\n",
        "    print(\"RNN Predicted TransactionPrice (RM):\", y_pred_rnn_rm)\n",
        "    print(\"GRU Predicted TransactionPrice (log-scale):\", y_pred_gru_log)\n",
        "    print(\"GRU Predicted TransactionPrice (RM):\", y_pred_gru_rm)\n",
        "    print(\"Transformer Predicted TransactionPrice (log-scale):\", y_pred_transformer_log)\n",
        "    print(\"Transformer Predicted TransactionPrice (RM):\", y_pred_transformer_rm)\n",
        "    print(\"Difference (RNN - GRU, RM):\", y_pred_rnn_rm - y_pred_gru_rm)\n",
        "    print(\"Difference (RNN - Transformer, RM):\", y_pred_rnn_rm - y_pred_transformer_rm)\n",
        "    print(\"Difference (GRU - Transformer, RM):\", y_pred_gru_rm - y_pred_transformer_rm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fXh_usJIHI_H",
        "outputId": "c0106690-3b1a-4ccf-c42c-0e26991816e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<>:16: SyntaxWarning: invalid escape sequence '\\d'\n",
            "<>:16: SyntaxWarning: invalid escape sequence '\\d'\n",
            "/tmp/ipython-input-2592401602.py:16: SyntaxWarning: invalid escape sequence '\\d'\n",
            "  df['ParcelArea'] = df['ParcelArea'].astype(str).str.extract('(\\d+\\.?\\d*)').astype(np.float32)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scaler center: [  13.185597     4.7004805 2023.          57.549488 ] Scaler scale: [ 0.94179726  0.42017126  2.         68.26673889]\n",
            "RNN R: 0.9291989803314209\n",
            "RNN RMSE (log-scale): 0.19187641786306178\n",
            "RNN RMSE (RM): 410805.2866651061\n",
            "GRU R: 0.9342986941337585\n",
            "GRU RMSE (log-scale): 0.1848370073431746\n",
            "GRU RMSE (RM): 388227.9037060577\n",
            "Transformer R: 0.9393892884254456\n",
            "Transformer RMSE (log-scale): 0.17753197600235207\n",
            "Transformer RMSE (RM): 379132.69411117793\n",
            "\n",
            "Sample: {'SchemeName': 'The Edge', 'ParcelArea': 80.0, 'Year': 2025.0, 'Mukim': 'Mukim Setapak', 'Tenure': 'Freehold', 'UnitLevel': 15}\n",
            "Year capped to 2025.0 (training range: 20212025)\n",
            "Raw Scheme_Name_encoded: 13.317193031311035 (log-scale, mean=13.3172)\n",
            "UnitLevel_clean: 15.0, UnitLevel_binned: Mid-High\n",
            "Year before scaling: [0.000e+00 5.000e-01 2.025e+03]\n",
            "Preprocessed X_sample:\n",
            " [[ 1.3972817e-01 -7.2834879e-01 -1.0115000e+03  1.0000000e+00\n",
            "   4.3944492e+00  1.0000000e+00  0.0000000e+00  1.2256704e-01]\n",
            " [ 1.3972817e-01 -7.2834879e-01 -1.0112500e+03  1.0000000e+00\n",
            "   4.3944492e+00  1.0000000e+00  0.0000000e+00  1.2256704e-01]\n",
            " [ 1.3972817e-01 -7.2834879e-01  1.0000000e+00  1.0000000e+00\n",
            "   4.3944492e+00  1.0000000e+00  0.0000000e+00  1.2256704e-01]]\n",
            "RNN Predicted TransactionPrice (log-scale): 4.618693793003773\n",
            "RNN Predicted TransactionPrice (RM): 100.36154646039371\n",
            "GRU Predicted TransactionPrice (log-scale): 11.3199357380654\n",
            "GRU Predicted TransactionPrice (RM): 82448.04441644024\n",
            "Transformer Predicted TransactionPrice (log-scale): 14.780397134602353\n",
            "Transformer Predicted TransactionPrice (RM): 2624488.9611173724\n",
            "Difference (RNN - GRU, RM): -82347.68286997985\n",
            "Difference (RNN - Transformer, RM): -2624388.599570912\n",
            "Difference (GRU - Transformer, RM): -2542040.916700932\n",
            "\n",
            "Sample: {'SchemeName': 'The Edge', 'ParcelArea': 80.0, 'Year': 2025.0, 'Mukim': 'Mukim Setapak', 'Tenure': 'Freehold', 'UnitLevel': 25}\n",
            "Year capped to 2025.0 (training range: 20212025)\n",
            "Raw Scheme_Name_encoded: 13.317193031311035 (log-scale, mean=13.3172)\n",
            "UnitLevel_clean: 25.0, UnitLevel_binned: High\n",
            "Year before scaling: [0.000e+00 5.000e-01 2.025e+03]\n",
            "Preprocessed X_sample:\n",
            " [[ 1.3972817e-01 -7.2834879e-01 -1.0115000e+03  1.0000000e+00\n",
            "   4.3944492e+00  0.0000000e+00  1.0000000e+00  7.6628447e-01]\n",
            " [ 1.3972817e-01 -7.2834879e-01 -1.0112500e+03  1.0000000e+00\n",
            "   4.3944492e+00  0.0000000e+00  1.0000000e+00  7.6628447e-01]\n",
            " [ 1.3972817e-01 -7.2834879e-01  1.0000000e+00  1.0000000e+00\n",
            "   4.3944492e+00  0.0000000e+00  1.0000000e+00  7.6628447e-01]]\n",
            "RNN Predicted TransactionPrice (log-scale): 4.629423374822151\n",
            "RNN Predicted TransactionPrice (RM): 101.45496895955712\n",
            "GRU Predicted TransactionPrice (log-scale): 11.337055122940011\n",
            "GRU Predicted TransactionPrice (RM): 83871.67238916043\n",
            "Transformer Predicted TransactionPrice (log-scale): 14.60126840398924\n",
            "Transformer Predicted TransactionPrice (RM): 2194068.0773606235\n",
            "Difference (RNN - GRU, RM): -83770.21742020088\n",
            "Difference (RNN - Transformer, RM): -2193966.622391664\n",
            "Difference (GRU - Transformer, RM): -2110196.404971463\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import RobustScaler, StandardScaler\n",
        "from sklearn.metrics import r2_score, mean_squared_error\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, SimpleRNN, GRU, Dense, Layer, MultiHeadAttention, LayerNormalization, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "import joblib\n",
        "\n",
        "# Load data\n",
        "url = \"https://raw.githubusercontent.com/englian1123/KL-High-Rise-Data/refs/heads/main/KLHighRise.csv\"\n",
        "df = pd.read_csv(url)\n",
        "df.rename(columns={'TransactionPrice  ': 'TransactionPrice', 'Parcel Area': 'ParcelArea', 'Scheme Name/Area': 'SchemeName'}, inplace=True)\n",
        "df['ParcelArea'] = df['ParcelArea'].astype(str).str.extract('(\\d+\\.?\\d*)').astype(np.float32)\n",
        "df['Tenure'] = df['Tenure'].map({'Freehold': 1, 'Leasehold': 0}).fillna(0).astype(np.float32)\n",
        "\n",
        "# Outlier capping (only ParcelArea)\n",
        "area_cap = df['ParcelArea'].quantile(0.90)\n",
        "df['ParcelArea'] = np.clip(df['ParcelArea'], 0, area_cap).astype(np.float32)\n",
        "\n",
        "# Log-transform\n",
        "df['TransactionPrice'] = np.log1p(df['TransactionPrice']).astype(np.float32)\n",
        "df['ParcelArea'] = np.log1p(df['ParcelArea']).astype(np.float32)\n",
        "\n",
        "# Target encode SchemeName\n",
        "scheme_encoding = df.groupby('SchemeName')['TransactionPrice'].mean().astype(np.float32)\n",
        "df['Scheme_Name_encoded'] = df['SchemeName'].map(scheme_encoding).fillna(scheme_encoding.mean()).astype(np.float32)\n",
        "joblib.dump(scheme_encoding, 'scheme_encoding_rnn_gru_transformer_v7.joblib')\n",
        "\n",
        "# Add Year\n",
        "df['TransactionDate'] = pd.to_datetime(df['TransactionDate'], format='%b-%y')\n",
        "df['Year'] = df['TransactionDate'].dt.year.astype(np.float32)\n",
        "\n",
        "# Clean UnitLevel\n",
        "unit_level_map = {'03A': 4, '12B': 12, '13A': 14, '23A': 24, '33A': 34, '43A': 44, '53A': 54,\n",
        "                  'B': 0, 'D': 0, 'G': 0, 'LG': 0, 'MZ': 0, 'P': 0, 'UG': 0,\n",
        "                  '1/5/2025': 0, '2/3/2025': 0, '1/4/2025': 0}\n",
        "df['UnitLevel_clean'] = df['UnitLevel'].replace(unit_level_map)\n",
        "unit_level_mean = pd.to_numeric(df['UnitLevel_clean'], errors='coerce').mean()\n",
        "df['UnitLevel_clean'] = pd.to_numeric(df['UnitLevel_clean'], errors='coerce').fillna(unit_level_mean).astype(np.float32)\n",
        "df['UnitLevel_binned'] = pd.cut(df['UnitLevel_clean'], bins=[-float('inf'), 5, 15, 25, float('inf')], labels=['Low', 'Mid-Low', 'Mid-High', 'High'], right=False)\n",
        "level_dummies = pd.get_dummies(df['UnitLevel_binned'], prefix='UnitLevel', dtype=np.float32)\n",
        "\n",
        "# Setapak interactions\n",
        "mukim_dummies = pd.get_dummies(df['Mukim'], prefix='Mukim', dtype=np.float32)\n",
        "df['Mukim_Mukim Setapak_Tenure'] = (mukim_dummies.get('Mukim_Mukim Setapak', pd.Series(0, index=df.index)) * df['Tenure']).astype(np.float32)\n",
        "df['Mukim_Mukim Setapak_ParcelArea'] = (mukim_dummies.get('Mukim_Mukim Setapak', pd.Series(0, index=df.index)) * df['ParcelArea']).astype(np.float32)\n",
        "df['ParcelArea_UnitLevel'] = (df['ParcelArea'] * df['UnitLevel_clean']).astype(np.float32)\n",
        "\n",
        "# Features\n",
        "features = ['Scheme_Name_encoded', 'ParcelArea', 'Year', 'Mukim_Mukim Setapak_Tenure', 'Mukim_Mukim Setapak_ParcelArea', 'UnitLevel_Mid-High', 'UnitLevel_High', 'ParcelArea_UnitLevel']\n",
        "X = pd.concat([df[['Scheme_Name_encoded', 'ParcelArea', 'Year', 'ParcelArea_UnitLevel']],\n",
        "               df[['Mukim_Mukim Setapak_Tenure', 'Mukim_Mukim Setapak_ParcelArea']],\n",
        "               level_dummies[['UnitLevel_Mid-High', 'UnitLevel_High']]], axis=1).astype(np.float32)\n",
        "y = df['TransactionPrice'].astype(np.float32)\n",
        "\n",
        "# Standardize target\n",
        "y_scaler = StandardScaler()\n",
        "y = y_scaler.fit_transform(y.values.reshape(-1, 1)).flatten().astype(np.float32)\n",
        "joblib.dump(y_scaler, 'y_scaler_rnn_gru_transformer_v7.joblib')\n",
        "print(\"y_scaler mean:\", y_scaler.mean_, \"y_scaler scale:\", y_scaler.scale_)\n",
        "\n",
        "# Create sequences (3 timesteps)\n",
        "sequence_length = 3\n",
        "X_seq = []\n",
        "y_seq = []\n",
        "for idx in range(len(X)):\n",
        "    year = X.iloc[idx]['Year']\n",
        "    sample = X.iloc[idx][features].values\n",
        "    seq = np.zeros((sequence_length, len(features)), dtype=np.float32)\n",
        "    seq[-1] = sample  # Current year\n",
        "    for t in range(1, sequence_length):\n",
        "        if year - t >= 2021:\n",
        "            seq[sequence_length - t - 1] = sample.copy()\n",
        "            seq[sequence_length - t - 1][2] = (year - t - 2023) / 2.0\n",
        "    X_seq.append(seq)\n",
        "    y_seq.append(y[idx])\n",
        "X_seq = np.array(X_seq)\n",
        "y_seq = np.array(y_seq)\n",
        "\n",
        "# Split data\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_seq, y_seq, test_size=0.2, random_state=42)\n",
        "\n",
        "# Scale features\n",
        "scaler = RobustScaler()\n",
        "for t in range(sequence_length):\n",
        "    X_train[:, t, [0, 1, 2, 7]] = scaler.fit_transform(X_train[:, t, [0, 1, 2, 7]]).astype(np.float32)\n",
        "    X_test[:, t, [0, 1, 2, 7]] = scaler.transform(X_test[:, t, [0, 1, 2, 7]]).astype(np.float32)\n",
        "joblib.dump(scaler, 'scaler_rnn_gru_transformer_v7.joblib')\n",
        "print(\"Scaler center:\", scaler.center_, \"Scaler scale:\", scaler.scale_)\n",
        "\n",
        "# RNN Model\n",
        "inputs = Input(shape=(sequence_length, len(features)))\n",
        "x = SimpleRNN(256, return_sequences=False, kernel_regularizer=tf.keras.regularizers.l2(0.03))(inputs)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(128, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.03))(x)\n",
        "x = Dropout(0.5)(x)\n",
        "outputs = Dense(1)(x)\n",
        "rnn_model = Model(inputs, outputs)\n",
        "rnn_model.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n",
        "rnn_model.fit(X_train, y_train, epochs=200, batch_size=32, validation_data=(X_test, y_test),\n",
        "              callbacks=[tf.keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True),\n",
        "                         ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-5)], verbose=0)\n",
        "joblib.dump(rnn_model, 'rnn_model_v7.joblib')\n",
        "\n",
        "# GRU Model\n",
        "x = GRU(256, return_sequences=False, kernel_regularizer=tf.keras.regularizers.l2(0.03))(inputs)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(128, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.03))(x)\n",
        "x = Dropout(0.5)(x)\n",
        "outputs = Dense(1)(x)\n",
        "gru_model = Model(inputs, outputs)\n",
        "gru_model.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n",
        "gru_model.fit(X_train, y_train, epochs=200, batch_size=32, validation_data=(X_test, y_test),\n",
        "              callbacks=[tf.keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True),\n",
        "                         ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-5)], verbose=0)\n",
        "joblib.dump(gru_model, 'gru_model_v7.joblib')\n",
        "\n",
        "# Transformer Model\n",
        "class TransformerBlock(Layer):\n",
        "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.5):\n",
        "        super(TransformerBlock, self).__init__()\n",
        "        self.att = MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.ffn = tf.keras.Sequential([Dense(ff_dim, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.03)),\n",
        "                                        Dense(embed_dim)])\n",
        "        self.layernorm1 = LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = LayerNormalization(epsilon=1e-6)\n",
        "        self.dropout1 = Dropout(rate)\n",
        "        self.dropout2 = Dropout(rate)\n",
        "    def call(self, inputs, training=False):\n",
        "        attn_output = self.att(inputs, inputs)\n",
        "        attn_output = self.dropout1(attn_output, training=training)\n",
        "        out1 = self.layernorm1(inputs + attn_output)\n",
        "        ffn_output = self.ffn(out1)\n",
        "        ffn_output = self.dropout2(ffn_output, training=training)\n",
        "        return self.layernorm2(out1 + ffn_output)\n",
        "\n",
        "class PositionalEncoding(Layer):\n",
        "    def __init__(self, sequence_length, embed_dim):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        pos_enc = np.array([[pos / np.power(10000, 2 * (i // 2) / embed_dim) for i in range(embed_dim)] for pos in range(sequence_length)])\n",
        "        pos_enc[:, 0::2] = np.sin(pos_enc[:, 0::2])\n",
        "        pos_enc[:, 1::2] = np.cos(pos_enc[:, 1::2])\n",
        "        self.pos_encoding = tf.cast(pos_enc, dtype=tf.float32)\n",
        "    def call(self, inputs):\n",
        "        return inputs + self.pos_encoding\n",
        "\n",
        "inputs = Input(shape=(sequence_length, len(features)))\n",
        "x = PositionalEncoding(sequence_length, len(features))(inputs)\n",
        "x = TransformerBlock(embed_dim=len(features), num_heads=8, ff_dim=256)(x, training=True)\n",
        "x = TransformerBlock(embed_dim=len(features), num_heads=8, ff_dim=256)(x, training=True)\n",
        "x = TransformerBlock(embed_dim=len(features), num_heads=8, ff_dim=256)(x, training=True)\n",
        "x = tf.keras.layers.GlobalAveragePooling1D()(x)\n",
        "x = Dense(128, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.03))(x)\n",
        "x = Dropout(0.5)(x)\n",
        "outputs = Dense(1)(x)\n",
        "transformer_model = Model(inputs, outputs)\n",
        "transformer_model.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n",
        "transformer_model.fit(X_train, y_train, epochs=200, batch_size=32, validation_data=(X_test, y_test),\n",
        "                     callbacks=[tf.keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True),\n",
        "                                ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-5)], verbose=0)\n",
        "joblib.dump(transformer_model, 'transformer_model_v7.joblib')\n",
        "\n",
        "# Evaluate models\n",
        "y_pred_rnn = rnn_model.predict(X_test, verbose=0).flatten()\n",
        "y_pred_rnn_log = y_scaler.inverse_transform(y_pred_rnn.reshape(-1, 1)).flatten()\n",
        "y_test_log = y_scaler.inverse_transform(y_test.reshape(-1, 1)).flatten()\n",
        "rnn_r2 = r2_score(y_test_log, y_pred_rnn_log)\n",
        "rnn_rmse_log = np.sqrt(mean_squared_error(y_test_log, y_pred_rnn_log))\n",
        "rnn_rmse_rm = np.sqrt(mean_squared_error(np.expm1(y_test_log), np.expm1(y_pred_rnn_log)))\n",
        "print(\"RNN y_pred_log (sample):\", y_pred_rnn_log[:5])\n",
        "print(\"RNN y_test_log (sample):\", y_test_log[:5])\n",
        "\n",
        "y_pred_gru = gru_model.predict(X_test, verbose=0).flatten()\n",
        "y_pred_gru_log = y_scaler.inverse_transform(y_pred_gru.reshape(-1, 1)).flatten()\n",
        "gru_r2 = r2_score(y_test_log, y_pred_gru_log)\n",
        "gru_rmse_log = np.sqrt(mean_squared_error(y_test_log, y_pred_gru_log))\n",
        "gru_rmse_rm = np.sqrt(mean_squared_error(np.expm1(y_test_log), np.expm1(y_pred_gru_log)))\n",
        "print(\"GRU y_pred_log (sample):\", y_pred_gru_log[:5])\n",
        "\n",
        "y_pred_transformer = transformer_model.predict(X_test, verbose=0).flatten()\n",
        "y_pred_transformer_log = y_scaler.inverse_transform(y_pred_transformer.reshape(-1, 1)).flatten()\n",
        "transformer_r2 = r2_score(y_test_log, y_pred_transformer_log)\n",
        "transformer_rmse_log = np.sqrt(mean_squared_error(y_test_log, y_pred_transformer_log))\n",
        "transformer_rmse_rm = np.sqrt(mean_squared_error(np.expm1(y_test_log), np.expm1(y_pred_transformer_log)))\n",
        "print(\"Transformer y_pred_log (sample):\", y_pred_transformer_log[:5])\n",
        "\n",
        "print(\"RNN R:\", rnn_r2)\n",
        "print(\"RNN RMSE (log-scale):\", rnn_rmse_log)\n",
        "print(\"RNN RMSE (RM):\", rnn_rmse_rm)\n",
        "print(\"GRU R:\", gru_r2)\n",
        "print(\"GRU RMSE (log-scale):\", gru_rmse_log)\n",
        "print(\"GRU RMSE (RM):\", gru_rmse_rm)\n",
        "print(\"Transformer R:\", transformer_r2)\n",
        "print(\"Transformer RMSE (log-scale):\", transformer_rmse_log)\n",
        "print(\"Transformer RMSE (RM):\", transformer_rmse_rm)\n",
        "\n",
        "# Preprocessing function for samples\n",
        "def preprocess_sample(sample, scheme_encoding, scaler, y_scaler, features, area_cap, year_max=2025.0, sequence_length=3):\n",
        "    df_sample = pd.DataFrame([sample])\n",
        "    df_sample['Year'] = np.clip(df_sample['Year'], 2021.0, year_max).astype(np.float32)\n",
        "    print(f\"\\nSample: {sample}\")\n",
        "    print(f\"Year capped to {df_sample['Year'].iloc[0]} (training range: 20212025)\")\n",
        "    df_sample['ParcelArea'] = np.log1p(np.clip(df_sample['ParcelArea'], 0, area_cap)).astype(np.float32)\n",
        "    raw_scheme_encoding = df_sample['SchemeName'].map(scheme_encoding).fillna(scheme_encoding.mean()).astype(np.float32)\n",
        "    print(f\"Raw Scheme_Name_encoded: {raw_scheme_encoding.iloc[0]} (log-scale, mean={scheme_encoding.mean():.4f})\")\n",
        "    df_sample['Scheme_Name_encoded'] = raw_scheme_encoding\n",
        "    df_sample['Tenure'] = df_sample['Tenure'].map({'Freehold': 1, 'Leasehold': 0}).fillna(0).astype(np.float32)\n",
        "    unit_level_map = {'03A': 4, '12B': 12, '13A': 14, '23A': 24, '33A': 34, '43A': 44, '53A': 54,\n",
        "                      'B': 0, 'D': 0, 'G': 0, 'LG': 0, 'MZ': 0, 'P': 0, 'UG': 0,\n",
        "                      '1/5/2025': 0, '2/3/2025': 0, '1/4/2025': 0}\n",
        "    df_sample['UnitLevel_clean'] = df_sample['UnitLevel'].replace(unit_level_map)\n",
        "    df_sample['UnitLevel_clean'] = pd.to_numeric(df_sample['UnitLevel_clean'], errors='coerce').fillna(10.0).astype(np.float32)\n",
        "    df_sample['UnitLevel_binned'] = pd.cut(df_sample['UnitLevel_clean'], bins=[-float('inf'), 5, 15, 25, float('inf')], labels=['Low', 'Mid-Low', 'Mid-High', 'High'], right=False)\n",
        "    print(f\"UnitLevel_clean: {df_sample['UnitLevel_clean'].iloc[0]}, UnitLevel_binned: {df_sample['UnitLevel_binned'].iloc[0]}\")\n",
        "    level_dummies = pd.get_dummies(df_sample['UnitLevel_binned'], prefix='UnitLevel', dtype=np.float32)\n",
        "    if 'UnitLevel_Mid-High' not in level_dummies:\n",
        "        level_dummies['UnitLevel_Mid-High'] = 0.0\n",
        "    if 'UnitLevel_High' not in level_dummies:\n",
        "        level_dummies['UnitLevel_High'] = 0.0\n",
        "    level_dummies = level_dummies[['UnitLevel_Mid-High', 'UnitLevel_High']].astype(np.float32)\n",
        "    df_sample['Mukim_Mukim Setapak_Tenure'] = (df_sample['Mukim'].eq('Mukim Setapak').astype(np.float32) * df_sample['Tenure']).astype(np.float32)\n",
        "    df_sample['Mukim_Mukim Setapak_ParcelArea'] = (df_sample['Mukim'].eq('Mukim Setapak').astype(np.float32) * df_sample['ParcelArea']).astype(np.float32)\n",
        "    df_sample['ParcelArea_UnitLevel'] = (df_sample['ParcelArea'] * df_sample['UnitLevel_clean']).astype(np.float32)\n",
        "    X_sample = pd.concat([df_sample[['Scheme_Name_encoded', 'ParcelArea', 'Year', 'ParcelArea_UnitLevel']],\n",
        "                          df_sample[['Mukim_Mukim Setapak_Tenure', 'Mukim_Mukim Setapak_ParcelArea']],\n",
        "                          level_dummies[['UnitLevel_Mid-High', 'UnitLevel_High']]], axis=1).astype(np.float32)\n",
        "    X_sample_seq = np.zeros((1, sequence_length, len(features)), dtype=np.float32)\n",
        "    X_sample_seq[0, -1] = X_sample[features].values\n",
        "    for t in range(1, sequence_length):\n",
        "        if df_sample['Year'].iloc[0] - t >= 2021:\n",
        "            X_sample_seq[0, sequence_length - t - 1] = X_sample[features].values\n",
        "            X_sample_seq[0, sequence_length - t - 1, 2] = (df_sample['Year'].iloc[0] - t - 2023) / 2.0\n",
        "    print(\"Year before scaling:\", X_sample_seq[0, :, 2])\n",
        "    X_sample_seq[:, :, [0, 1, 2, 7]] = scaler.transform(X_sample_seq[:, :, [0, 1, 2, 7]].reshape(-1, 4)).reshape(1, sequence_length, 4)\n",
        "    return X_sample_seq\n",
        "\n",
        "# Define sample inputs\n",
        "sample_inputs = [\n",
        "    {'SchemeName': 'The Edge', 'ParcelArea': 80.0, 'Year': 2025.0, 'Mukim': 'Mukim Setapak', 'Tenure': 'Freehold', 'UnitLevel': 15},\n",
        "    {'SchemeName': 'The Edge', 'ParcelArea': 80.0, 'Year': 2025.0, 'Mukim': 'Mukim Setapak', 'Tenure': 'Freehold', 'UnitLevel': 25}\n",
        "]\n",
        "\n",
        "# Predict for both inputs\n",
        "area_cap = 90.0\n",
        "features = ['Scheme_Name_encoded', 'ParcelArea', 'Year', 'Mukim_Mukim Setapak_Tenure', 'Mukim_Mukim Setapak_ParcelArea', 'UnitLevel_Mid-High', 'UnitLevel_High', 'ParcelArea_UnitLevel']\n",
        "for sample in sample_inputs:\n",
        "    X_sample = preprocess_sample(sample, scheme_encoding, scaler, y_scaler, features, area_cap)\n",
        "    y_pred_rnn = rnn_model.predict(X_sample, verbose=0).flatten()[0]\n",
        "    y_pred_rnn_log = y_scaler.inverse_transform([[y_pred_rnn]])[0, 0]\n",
        "    y_pred_rnn_rm = np.expm1(y_pred_rnn_log)\n",
        "    y_pred_gru = gru_model.predict(X_sample, verbose=0).flatten()[0]\n",
        "    y_pred_gru_log = y_scaler.inverse_transform([[y_pred_gru]])[0, 0]\n",
        "    y_pred_gru_rm = np.expm1(y_pred_gru_log)\n",
        "    y_pred_transformer = transformer_model.predict(X_sample, verbose=0).flatten()[0]\n",
        "    y_pred_transformer_log = y_scaler.inverse_transform([[y_pred_transformer]])[0, 0]\n",
        "    y_pred_transformer_rm = np.expm1(y_pred_transformer_log)\n",
        "    print(\"Preprocessed X_sample:\\n\", X_sample[0])\n",
        "    print(\"RNN Predicted TransactionPrice (log-scale):\", y_pred_rnn_log)\n",
        "    print(\"RNN Predicted TransactionPrice (RM):\", y_pred_rnn_rm)\n",
        "    print(\"GRU Predicted TransactionPrice (log-scale):\", y_pred_gru_log)\n",
        "    print(\"GRU Predicted TransactionPrice (RM):\", y_pred_gru_rm)\n",
        "    print(\"Transformer Predicted TransactionPrice (log-scale):\", y_pred_transformer_log)\n",
        "    print(\"Transformer Predicted TransactionPrice (RM):\", y_pred_transformer_rm)\n",
        "    print(\"Difference (RNN - GRU, RM):\", y_pred_rnn_rm - y_pred_gru_rm)\n",
        "    print(\"Difference (RNN - Transformer, RM):\", y_pred_rnn_rm - y_pred_transformer_rm)\n",
        "    print(\"Difference (GRU - Transformer, RM):\", y_pred_gru_rm - y_pred_transformer_rm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hMI8HNxP-fyd",
        "outputId": "f9f89f8f-af9a-4b06-b4aa-996a311b6262"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<>:16: SyntaxWarning: invalid escape sequence '\\d'\n",
            "<>:16: SyntaxWarning: invalid escape sequence '\\d'\n",
            "/tmp/ipython-input-1631543606.py:16: SyntaxWarning: invalid escape sequence '\\d'\n",
            "  df['ParcelArea'] = df['ParcelArea'].astype(str).str.extract('(\\d+\\.?\\d*)').astype(np.float32)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "y_scaler mean: [13.38469146] y_scaler scale: [0.71261604]\n",
            "Scaler center: [  13.185597     4.7004805 2023.          57.549488 ] Scaler scale: [ 0.94179726  0.42017126  2.         68.26673889]\n",
            "RNN y_pred_log (sample): [13.078077 13.346302 14.19821  14.048986 13.082576]\n",
            "RNN y_test_log (sample): [12.9854   13.381647 14.093143 14.077875 13.122365]\n",
            "GRU y_pred_log (sample): [13.064397 13.368207 14.156523 14.00617  13.11625 ]\n",
            "Transformer y_pred_log (sample): [13.081892 13.348038 14.143297 13.985456 13.077363]\n",
            "RNN R: 0.927683413028717\n",
            "RNN RMSE (log-scale): 0.1939191902447525\n",
            "RNN RMSE (RM): 406231.4888434918\n",
            "GRU R: 0.9336517453193665\n",
            "GRU RMSE (log-scale): 0.1857448124424305\n",
            "GRU RMSE (RM): 391760.5355111717\n",
            "Transformer R: 0.9378165602684021\n",
            "Transformer RMSE (log-scale): 0.17982049871255157\n",
            "Transformer RMSE (RM): 384481.2344549471\n",
            "\n",
            "Sample: {'SchemeName': 'The Edge', 'ParcelArea': 80.0, 'Year': 2025.0, 'Mukim': 'Mukim Setapak', 'Tenure': 'Freehold', 'UnitLevel': 15}\n",
            "Year capped to 2025.0 (training range: 20212025)\n",
            "Raw Scheme_Name_encoded: 13.317193031311035 (log-scale, mean=13.3172)\n",
            "UnitLevel_clean: 15.0, UnitLevel_binned: Mid-High\n",
            "Year before scaling: [0.000e+00 5.000e-01 2.025e+03]\n",
            "Preprocessed X_sample:\n",
            " [[ 1.3972817e-01 -7.2834879e-01 -1.0115000e+03  1.0000000e+00\n",
            "   4.3944492e+00  1.0000000e+00  0.0000000e+00  1.2256704e-01]\n",
            " [ 1.3972817e-01 -7.2834879e-01 -1.0112500e+03  1.0000000e+00\n",
            "   4.3944492e+00  1.0000000e+00  0.0000000e+00  1.2256704e-01]\n",
            " [ 1.3972817e-01 -7.2834879e-01  1.0000000e+00  1.0000000e+00\n",
            "   4.3944492e+00  1.0000000e+00  0.0000000e+00  1.2256704e-01]]\n",
            "RNN Predicted TransactionPrice (log-scale): 4.548818988480074\n",
            "RNN Predicted TransactionPrice (RM): 93.52071232065644\n",
            "GRU Predicted TransactionPrice (log-scale): 14.688381014316855\n",
            "GRU Predicted TransactionPrice (RM): 2393771.219861919\n",
            "Transformer Predicted TransactionPrice (log-scale): 13.288495543732907\n",
            "Transformer Predicted TransactionPrice (RM): 590363.5720236461\n",
            "Difference (RNN - GRU, RM): -2393677.6991495984\n",
            "Difference (RNN - Transformer, RM): -590270.0513113254\n",
            "Difference (GRU - Transformer, RM): 1803407.647838273\n",
            "\n",
            "Sample: {'SchemeName': 'The Edge', 'ParcelArea': 80.0, 'Year': 2025.0, 'Mukim': 'Mukim Setapak', 'Tenure': 'Freehold', 'UnitLevel': 25}\n",
            "Year capped to 2025.0 (training range: 20212025)\n",
            "Raw Scheme_Name_encoded: 13.317193031311035 (log-scale, mean=13.3172)\n",
            "UnitLevel_clean: 25.0, UnitLevel_binned: High\n",
            "Year before scaling: [0.000e+00 5.000e-01 2.025e+03]\n",
            "Preprocessed X_sample:\n",
            " [[ 1.3972817e-01 -7.2834879e-01 -1.0115000e+03  1.0000000e+00\n",
            "   4.3944492e+00  0.0000000e+00  1.0000000e+00  7.6628447e-01]\n",
            " [ 1.3972817e-01 -7.2834879e-01 -1.0112500e+03  1.0000000e+00\n",
            "   4.3944492e+00  0.0000000e+00  1.0000000e+00  7.6628447e-01]\n",
            " [ 1.3972817e-01 -7.2834879e-01  1.0000000e+00  1.0000000e+00\n",
            "   4.3944492e+00  0.0000000e+00  1.0000000e+00  7.6628447e-01]]\n",
            "RNN Predicted TransactionPrice (log-scale): 4.555536870179761\n",
            "RNN Predicted TransactionPrice (RM): 94.15782892510151\n",
            "GRU Predicted TransactionPrice (log-scale): 14.709462233395165\n",
            "GRU Predicted TransactionPrice (RM): 2444770.531547484\n",
            "Transformer Predicted TransactionPrice (log-scale): 14.151025319689577\n",
            "Transformer Predicted TransactionPrice (RM): 1398659.1766716845\n",
            "Difference (RNN - GRU, RM): -2444676.373718559\n",
            "Difference (RNN - Transformer, RM): -1398565.0188427593\n",
            "Difference (GRU - Transformer, RM): 1046111.3548757995\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import RobustScaler, StandardScaler\n",
        "from sklearn.metrics import r2_score, mean_squared_error\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, SimpleRNN, GRU, Dense, Layer, MultiHeadAttention, LayerNormalization, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "import joblib\n",
        "\n",
        "# Load data\n",
        "url = \"https://raw.githubusercontent.com/englian1123/KL-High-Rise-Data/refs/heads/main/KLHighRise.csv\"\n",
        "df = pd.read_csv(url)\n",
        "df.rename(columns={'TransactionPrice  ': 'TransactionPrice', 'Parcel Area': 'ParcelArea', 'Scheme Name/Area': 'SchemeName'}, inplace=True)\n",
        "df['ParcelArea'] = df['ParcelArea'].astype(str).str.extract('(\\d+\\.?\\d*)').astype(np.float32)\n",
        "df['Tenure'] = df['Tenure'].map({'Freehold': 1, 'Leasehold': 0}).fillna(0).astype(np.float32)\n",
        "\n",
        "# Outlier capping (only ParcelArea)\n",
        "area_cap = df['ParcelArea'].quantile(0.90)\n",
        "df['ParcelArea'] = np.clip(df['ParcelArea'], 0, area_cap).astype(np.float32)\n",
        "\n",
        "# Log-transform\n",
        "df['TransactionPrice'] = np.log1p(df['TransactionPrice']).astype(np.float32)\n",
        "df['ParcelArea'] = np.log1p(df['ParcelArea']).astype(np.float32)\n",
        "\n",
        "# Target encode SchemeName\n",
        "scheme_encoding = df.groupby('SchemeName')['TransactionPrice'].mean().astype(np.float32)\n",
        "df['Scheme_Name_encoded'] = df['SchemeName'].map(scheme_encoding).fillna(scheme_encoding.mean()).astype(np.float32)\n",
        "joblib.dump(scheme_encoding, 'scheme_encoding_rnn_gru_transformer_v6.joblib')\n",
        "\n",
        "# Add Year\n",
        "df['TransactionDate'] = pd.to_datetime(df['TransactionDate'], format='%b-%y')\n",
        "df['Year'] = df['TransactionDate'].dt.year.astype(np.float32)\n",
        "\n",
        "# Clean UnitLevel\n",
        "unit_level_map = {'03A': 4, '12B': 12, '13A': 14, '23A': 24, '33A': 34, '43A': 44, '53A': 54,\n",
        "                  'B': 0, 'D': 0, 'G': 0, 'LG': 0, 'MZ': 0, 'P': 0, 'UG': 0,\n",
        "                  '1/5/2025': 0, '2/3/2025': 0, '1/4/2025': 0}\n",
        "df['UnitLevel_clean'] = df['UnitLevel'].replace(unit_level_map)\n",
        "unit_level_mean = pd.to_numeric(df['UnitLevel_clean'], errors='coerce').mean()\n",
        "df['UnitLevel_clean'] = pd.to_numeric(df['UnitLevel_clean'], errors='coerce').fillna(unit_level_mean).astype(np.float32)\n",
        "df['UnitLevel_binned'] = pd.cut(df['UnitLevel_clean'], bins=[-float('inf'), 5, 15, 25, float('inf')], labels=['Low', 'Mid-Low', 'Mid-High', 'High'], right=False)\n",
        "level_dummies = pd.get_dummies(df['UnitLevel_binned'], prefix='UnitLevel', dtype=np.float32)\n",
        "\n",
        "# Setapak interactions\n",
        "mukim_dummies = pd.get_dummies(df['Mukim'], prefix='Mukim', dtype=np.float32)\n",
        "df['Mukim_Mukim Setapak_Tenure'] = (mukim_dummies.get('Mukim_Mukim Setapak', pd.Series(0, index=df.index)) * df['Tenure']).astype(np.float32)\n",
        "df['Mukim_Mukim Setapak_ParcelArea'] = (mukim_dummies.get('Mukim_Mukim Setapak', pd.Series(0, index=df.index)) * df['ParcelArea']).astype(np.float32)\n",
        "df['ParcelArea_UnitLevel'] = (df['ParcelArea'] * df['UnitLevel_clean']).astype(np.float32)\n",
        "\n",
        "# Features\n",
        "features = ['Scheme_Name_encoded', 'ParcelArea', 'Year', 'Mukim_Mukim Setapak_Tenure', 'Mukim_Mukim Setapak_ParcelArea', 'UnitLevel_Mid-High', 'UnitLevel_High', 'ParcelArea_UnitLevel']\n",
        "X = pd.concat([df[['Scheme_Name_encoded', 'ParcelArea', 'Year', 'ParcelArea_UnitLevel']],\n",
        "               df[['Mukim_Mukim Setapak_Tenure', 'Mukim_Mukim Setapak_ParcelArea']],\n",
        "               level_dummies[['UnitLevel_Mid-High', 'UnitLevel_High']]], axis=1).astype(np.float32)\n",
        "y = df['TransactionPrice'].astype(np.float32)\n",
        "\n",
        "# Standardize target\n",
        "y_scaler = StandardScaler()\n",
        "y = y_scaler.fit_transform(y.values.reshape(-1, 1)).flatten().astype(np.float32)\n",
        "joblib.dump(y_scaler, 'y_scaler_rnn_gru_transformer_v6.joblib')\n",
        "\n",
        "# Create sequences (3 timesteps)\n",
        "sequence_length = 3\n",
        "X_seq = []\n",
        "y_seq = []\n",
        "for idx in range(len(X)):\n",
        "    year = X.iloc[idx]['Year']\n",
        "    sample = X.iloc[idx][features].values\n",
        "    seq = np.zeros((sequence_length, len(features)), dtype=np.float32)\n",
        "    seq[-1] = sample  # Current year\n",
        "    for t in range(1, sequence_length):\n",
        "        if year - t >= 2021:\n",
        "            seq[sequence_length - t - 1] = sample.copy()\n",
        "            seq[sequence_length - t - 1][2] = (year - t - 2023) / 2.0\n",
        "    X_seq.append(seq)\n",
        "    y_seq.append(y[idx])\n",
        "X_seq = np.array(X_seq)\n",
        "y_seq = np.array(y_seq)\n",
        "\n",
        "# Split data\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_seq, y_seq, test_size=0.2, random_state=42)\n",
        "\n",
        "# Scale features\n",
        "scaler = RobustScaler()\n",
        "for t in range(sequence_length):\n",
        "    X_train[:, t, [0, 1, 2, 7]] = scaler.fit_transform(X_train[:, t, [0, 1, 2, 7]]).astype(np.float32)\n",
        "    X_test[:, t, [0, 1, 2, 7]] = scaler.transform(X_test[:, t, [0, 1, 2, 7]]).astype(np.float32)\n",
        "joblib.dump(scaler, 'scaler_rnn_gru_transformer_v6.joblib')\n",
        "print(\"Scaler center:\", scaler.center_, \"Scaler scale:\", scaler.scale_)\n",
        "\n",
        "# RNN Model\n",
        "inputs = Input(shape=(sequence_length, len(features)))\n",
        "x = SimpleRNN(256, return_sequences=False, kernel_regularizer=tf.keras.regularizers.l2(0.02))(inputs)\n",
        "x = Dropout(0.4)(x)\n",
        "x = Dense(128, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.02))(x)\n",
        "x = Dropout(0.4)(x)\n",
        "outputs = Dense(1)(x)\n",
        "rnn_model = Model(inputs, outputs)\n",
        "rnn_model.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n",
        "rnn_model.fit(X_train, y_train, epochs=200, batch_size=32, validation_data=(X_test, y_test),\n",
        "              callbacks=[tf.keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True),\n",
        "                         ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-5)], verbose=0)\n",
        "joblib.dump(rnn_model, 'rnn_model_v6.joblib')\n",
        "\n",
        "# GRU Model\n",
        "x = GRU(256, return_sequences=False, kernel_regularizer=tf.keras.regularizers.l2(0.02))(inputs)\n",
        "x = Dropout(0.4)(x)\n",
        "x = Dense(128, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.02))(x)\n",
        "x = Dropout(0.4)(x)\n",
        "outputs = Dense(1)(x)\n",
        "gru_model = Model(inputs, outputs)\n",
        "gru_model.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n",
        "gru_model.fit(X_train, y_train, epochs=200, batch_size=32, validation_data=(X_test, y_test),\n",
        "              callbacks=[tf.keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True),\n",
        "                         ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-5)], verbose=0)\n",
        "joblib.dump(gru_model, 'gru_model_v6.joblib')\n",
        "\n",
        "# Transformer Model\n",
        "class TransformerBlock(Layer):\n",
        "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.4):\n",
        "        super(TransformerBlock, self).__init__()\n",
        "        self.att = MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.ffn = tf.keras.Sequential([Dense(ff_dim, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.02)),\n",
        "                                        Dense(embed_dim)])\n",
        "        self.layernorm1 = LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = LayerNormalization(epsilon=1e-6)\n",
        "        self.dropout1 = Dropout(rate)\n",
        "        self.dropout2 = Dropout(rate)\n",
        "    def call(self, inputs, training=False):\n",
        "        attn_output = self.att(inputs, inputs)\n",
        "        attn_output = self.dropout1(attn_output, training=training)\n",
        "        out1 = self.layernorm1(inputs + attn_output)\n",
        "        ffn_output = self.ffn(out1)\n",
        "        ffn_output = self.dropout2(ffn_output, training=training)\n",
        "        return self.layernorm2(out1 + ffn_output)\n",
        "\n",
        "class PositionalEncoding(Layer):\n",
        "    def __init__(self, sequence_length, embed_dim):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        pos_enc = np.array([[pos / np.power(10000, 2 * (i // 2) / embed_dim) for i in range(embed_dim)] for pos in range(sequence_length)])\n",
        "        pos_enc[:, 0::2] = np.sin(pos_enc[:, 0::2])\n",
        "        pos_enc[:, 1::2] = np.cos(pos_enc[:, 1::2])\n",
        "        self.pos_encoding = tf.cast(pos_enc, dtype=tf.float32)\n",
        "    def call(self, inputs):\n",
        "        return inputs + self.pos_encoding\n",
        "\n",
        "inputs = Input(shape=(sequence_length, len(features)))\n",
        "x = PositionalEncoding(sequence_length, len(features))(inputs)\n",
        "x = TransformerBlock(embed_dim=len(features), num_heads=8, ff_dim=256)(x, training=True)\n",
        "x = TransformerBlock(embed_dim=len(features), num_heads=8, ff_dim=256)(x, training=True)\n",
        "x = TransformerBlock(embed_dim=len(features), num_heads=8, ff_dim=256)(x, training=True)\n",
        "x = tf.keras.layers.GlobalAveragePooling1D()(x)\n",
        "x = Dense(128, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.02))(x)\n",
        "x = Dropout(0.4)(x)\n",
        "outputs = Dense(1)(x)\n",
        "transformer_model = Model(inputs, outputs)\n",
        "transformer_model.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n",
        "transformer_model.fit(X_train, y_train, epochs=200, batch_size=32, validation_data=(X_test, y_test),\n",
        "                     callbacks=[tf.keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True),\n",
        "                                ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-5)], verbose=0)\n",
        "joblib.dump(transformer_model, 'transformer_model_v6.joblib')\n",
        "\n",
        "# Evaluate models\n",
        "y_pred_rnn = rnn_model.predict(X_test, verbose=0).flatten()\n",
        "y_pred_rnn_log = y_scaler.inverse_transform(y_pred_rnn.reshape(-1, 1)).flatten()\n",
        "y_test_log = y_scaler.inverse_transform(y_test.reshape(-1, 1)).flatten()\n",
        "rnn_r2 = r2_score(y_test_log, y_pred_rnn_log)\n",
        "rnn_rmse_log = np.sqrt(mean_squared_error(y_test_log, y_pred_rnn_log))\n",
        "rnn_rmse_rm = np.sqrt(mean_squared_error(np.expm1(y_test_log), np.expm1(y_pred_rnn_log)))\n",
        "\n",
        "y_pred_gru = gru_model.predict(X_test, verbose=0).flatten()\n",
        "y_pred_gru_log = y_scaler.inverse_transform(y_pred_gru.reshape(-1, 1)).flatten()\n",
        "gru_r2 = r2_score(y_test_log, y_pred_gru_log)\n",
        "gru_rmse_log = np.sqrt(mean_squared_error(y_test_log, y_pred_gru_log))\n",
        "gru_rmse_rm = np.sqrt(mean_squared_error(np.expm1(y_test_log), np.expm1(y_pred_gru_log)))\n",
        "\n",
        "y_pred_transformer = transformer_model.predict(X_test, verbose=0).flatten()\n",
        "y_pred_transformer_log = y_scaler.inverse_transform(y_pred_transformer.reshape(-1, 1)).flatten()\n",
        "transformer_r2 = r2_score(y_test_log, y_pred_transformer_log)\n",
        "transformer_rmse_log = np.sqrt(mean_squared_error(y_test_log, y_pred_transformer_log))\n",
        "transformer_rmse_rm = np.sqrt(mean_squared_error(np.expm1(y_test_log), np.expm1(y_pred_transformer_log)))\n",
        "\n",
        "print(\"RNN R:\", rnn_r2)\n",
        "print(\"RNN RMSE (log-scale):\", rnn_rmse_log)\n",
        "print(\"RNN RMSE (RM):\", rnn_rmse_rm)\n",
        "print(\"GRU R:\", gru_r2)\n",
        "print(\"GRU RMSE (log-scale):\", gru_rmse_log)\n",
        "print(\"GRU RMSE (RM):\", gru_rmse_rm)\n",
        "print(\"Transformer R:\", transformer_r2)\n",
        "print(\"Transformer RMSE (log-scale):\", transformer_rmse_log)\n",
        "print(\"Transformer RMSE (RM):\", transformer_rmse_rm)\n",
        "\n",
        "# Preprocessing function for samples\n",
        "def preprocess_sample(sample, scheme_encoding, scaler, y_scaler, features, area_cap, year_max=2025.0, sequence_length=3):\n",
        "    df_sample = pd.DataFrame([sample])\n",
        "    df_sample['Year'] = np.clip(df_sample['Year'], 2021.0, year_max).astype(np.float32)\n",
        "    print(f\"\\nSample: {sample}\")\n",
        "    print(f\"Year capped to {df_sample['Year'].iloc[0]} (training range: 20212025)\")\n",
        "    df_sample['ParcelArea'] = np.log1p(np.clip(df_sample['ParcelArea'], 0, area_cap)).astype(np.float32)\n",
        "    raw_scheme_encoding = df_sample['SchemeName'].map(scheme_encoding).fillna(scheme_encoding.mean()).astype(np.float32)\n",
        "    print(f\"Raw Scheme_Name_encoded: {raw_scheme_encoding.iloc[0]} (log-scale, mean={scheme_encoding.mean():.4f})\")\n",
        "    df_sample['Scheme_Name_encoded'] = raw_scheme_encoding\n",
        "    df_sample['Tenure'] = df_sample['Tenure'].map({'Freehold': 1, 'Leasehold': 0}).fillna(0).astype(np.float32)\n",
        "    unit_level_map = {'03A': 4, '12B': 12, '13A': 14, '23A': 24, '33A': 34, '43A': 44, '53A': 54,\n",
        "                      'B': 0, 'D': 0, 'G': 0, 'LG': 0, 'MZ': 0, 'P': 0, 'UG': 0,\n",
        "                      '1/5/2025': 0, '2/3/2025': 0, '1/4/2025': 0}\n",
        "    df_sample['UnitLevel_clean'] = df_sample['UnitLevel'].replace(unit_level_map)\n",
        "    df_sample['UnitLevel_clean'] = pd.to_numeric(df_sample['UnitLevel_clean'], errors='coerce').fillna(10.0).astype(np.float32)\n",
        "    df_sample['UnitLevel_binned'] = pd.cut(df_sample['UnitLevel_clean'], bins=[-float('inf'), 5, 15, 25, float('inf')], labels=['Low', 'Mid-Low', 'Mid-High', 'High'], right=False)\n",
        "    print(f\"UnitLevel_clean: {df_sample['UnitLevel_clean'].iloc[0]}, UnitLevel_binned: {df_sample['UnitLevel_binned'].iloc[0]}\")\n",
        "    level_dummies = pd.get_dummies(df_sample['UnitLevel_binned'], prefix='UnitLevel', dtype=np.float32)\n",
        "    if 'UnitLevel_Mid-High' not in level_dummies:\n",
        "        level_dummies['UnitLevel_Mid-High'] = 0.0\n",
        "    if 'UnitLevel_High' not in level_dummies:\n",
        "        level_dummies['UnitLevel_High'] = 0.0\n",
        "    level_dummies = level_dummies[['UnitLevel_Mid-High', 'UnitLevel_High']].astype(np.float32)\n",
        "    df_sample['Mukim_Mukim Setapak_Tenure'] = (df_sample['Mukim'].eq('Mukim Setapak').astype(np.float32) * df_sample['Tenure']).astype(np.float32)\n",
        "    df_sample['Mukim_Mukim Setapak_ParcelArea'] = (df_sample['Mukim'].eq('Mukim Setapak').astype(np.float32) * df_sample['ParcelArea']).astype(np.float32)\n",
        "    df_sample['ParcelArea_UnitLevel'] = (df_sample['ParcelArea'] * df_sample['UnitLevel_clean']).astype(np.float32)\n",
        "    X_sample = pd.concat([df_sample[['Scheme_Name_encoded', 'ParcelArea', 'Year', 'ParcelArea_UnitLevel']],\n",
        "                          df_sample[['Mukim_Mukim Setapak_Tenure', 'Mukim_Mukim Setapak_ParcelArea']],\n",
        "                          level_dummies[['UnitLevel_Mid-High', 'UnitLevel_High']]], axis=1).astype(np.float32)\n",
        "    X_sample_seq = np.zeros((1, sequence_length, len(features)), dtype=np.float32)\n",
        "    X_sample_seq[0, -1] = X_sample[features].values\n",
        "    for t in range(1, sequence_length):\n",
        "        if df_sample['Year'].iloc[0] - t >= 2021:\n",
        "            X_sample_seq[0, sequence_length - t - 1] = X_sample[features].values\n",
        "            X_sample_seq[0, sequence_length - t - 1, 2] = (df_sample['Year'].iloc[0] - t - 2023) / 2.0\n",
        "    print(\"Year before scaling:\", X_sample_seq[0, :, 2])\n",
        "    X_sample_seq[:, :, [0, 1, 2, 7]] = scaler.transform(X_sample_seq[:, :, [0, 1, 2, 7]].reshape(-1, 4)).reshape(1, sequence_length, 4)\n",
        "    return X_sample_seq\n",
        "\n",
        "# Define sample inputs\n",
        "sample_inputs = [\n",
        "    {'SchemeName': 'The Edge', 'ParcelArea': 80.0, 'Year': 2025.0, 'Mukim': 'Mukim Setapak', 'Tenure': 'Freehold', 'UnitLevel': 15},\n",
        "    {'SchemeName': 'The Edge', 'ParcelArea': 80.0, 'Year': 2025.0, 'Mukim': 'Mukim Setapak', 'Tenure': 'Freehold', 'UnitLevel': 25}\n",
        "]\n",
        "\n",
        "# Predict for both inputs\n",
        "area_cap = 90.0\n",
        "features = ['Scheme_Name_encoded', 'ParcelArea', 'Year', 'Mukim_Mukim Setapak_Tenure', 'Mukim_Mukim Setapak_ParcelArea', 'UnitLevel_Mid-High', 'UnitLevel_High', 'ParcelArea_UnitLevel']\n",
        "for sample in sample_inputs:\n",
        "    X_sample = preprocess_sample(sample, scheme_encoding, scaler, y_scaler, features, area_cap)\n",
        "    y_pred_rnn = rnn_model.predict(X_sample, verbose=0).flatten()[0]\n",
        "    y_pred_rnn_log = y_scaler.inverse_transform([[y_pred_rnn]])[0, 0]\n",
        "    y_pred_rnn_rm = np.expm1(y_pred_rnn_log)\n",
        "    y_pred_gru = gru_model.predict(X_sample, verbose=0).flatten()[0]\n",
        "    y_pred_gru_log = y_scaler.inverse_transform([[y_pred_gru]])[0, 0]\n",
        "    y_pred_gru_rm = np.expm1(y_pred_gru_log)\n",
        "    y_pred_transformer = transformer_model.predict(X_sample, verbose=0).flatten()[0]\n",
        "    y_pred_transformer_log = y_scaler.inverse_transform([[y_pred_transformer]])[0, 0]\n",
        "    y_pred_transformer_rm = np.expm1(y_pred_transformer_log)\n",
        "    print(\"Preprocessed X_sample:\\n\", X_sample[0])\n",
        "    print(\"RNN Predicted TransactionPrice (log-scale):\", y_pred_rnn_log)\n",
        "    print(\"RNN Predicted TransactionPrice (RM):\", y_pred_rnn_rm)\n",
        "    print(\"GRU Predicted TransactionPrice (log-scale):\", y_pred_gru_log)\n",
        "    print(\"GRU Predicted TransactionPrice (RM):\", y_pred_gru_rm)\n",
        "    print(\"Transformer Predicted TransactionPrice (log-scale):\", y_pred_transformer_log)\n",
        "    print(\"Transformer Predicted TransactionPrice (RM):\", y_pred_transformer_rm)\n",
        "    print(\"Difference (RNN - GRU, RM):\", y_pred_rnn_rm - y_pred_gru_rm)\n",
        "    print(\"Difference (RNN - Transformer, RM):\", y_pred_rnn_rm - y_pred_transformer_rm)\n",
        "    print(\"Difference (GRU - Transformer, RM):\", y_pred_gru_rm - y_pred_transformer_rm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BvPYaZyGEmYg",
        "outputId": "4c91f4bb-4353-4da4-aec0-b1c28ae449df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<>:16: SyntaxWarning: invalid escape sequence '\\d'\n",
            "<>:16: SyntaxWarning: invalid escape sequence '\\d'\n",
            "/tmp/ipython-input-2592401602.py:16: SyntaxWarning: invalid escape sequence '\\d'\n",
            "  df['ParcelArea'] = df['ParcelArea'].astype(str).str.extract('(\\d+\\.?\\d*)').astype(np.float32)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scaler center: [  13.185597     4.7004805 2023.          57.549488 ] Scaler scale: [ 0.94179726  0.42017126  2.         68.26673889]\n",
            "RNN R: 0.9290875196456909\n",
            "RNN RMSE (log-scale): 0.19202744634599908\n",
            "RNN RMSE (RM): 413196.17330270616\n",
            "GRU R: 0.9343828558921814\n",
            "GRU RMSE (log-scale): 0.18471857201663333\n",
            "GRU RMSE (RM): 387371.31284595665\n",
            "Transformer R: 0.9388933181762695\n",
            "Transformer RMSE (log-scale): 0.17825681803171325\n",
            "Transformer RMSE (RM): 370294.6199987248\n",
            "\n",
            "Sample: {'SchemeName': 'The Edge', 'ParcelArea': 80.0, 'Year': 2025.0, 'Mukim': 'Mukim Setapak', 'Tenure': 'Freehold', 'UnitLevel': 15}\n",
            "Year capped to 2025.0 (training range: 20212025)\n",
            "Raw Scheme_Name_encoded: 13.317193031311035 (log-scale, mean=13.3172)\n",
            "UnitLevel_clean: 15.0, UnitLevel_binned: Mid-High\n",
            "Year before scaling: [0.000e+00 5.000e-01 2.025e+03]\n",
            "Preprocessed X_sample:\n",
            " [[ 1.3972817e-01 -7.2834879e-01 -1.0115000e+03  1.0000000e+00\n",
            "   4.3944492e+00  1.0000000e+00  0.0000000e+00  1.2256704e-01]\n",
            " [ 1.3972817e-01 -7.2834879e-01 -1.0112500e+03  1.0000000e+00\n",
            "   4.3944492e+00  1.0000000e+00  0.0000000e+00  1.2256704e-01]\n",
            " [ 1.3972817e-01 -7.2834879e-01  1.0000000e+00  1.0000000e+00\n",
            "   4.3944492e+00  1.0000000e+00  0.0000000e+00  1.2256704e-01]]\n",
            "RNN Predicted TransactionPrice (log-scale): 4.929072160394339\n",
            "RNN Predicted TransactionPrice (RM): 137.2511778938973\n",
            "GRU Predicted TransactionPrice (log-scale): 10.167713348207418\n",
            "GRU Predicted TransactionPrice (RM): 26047.444888144568\n",
            "Transformer Predicted TransactionPrice (log-scale): 13.693071750140406\n",
            "Transformer Predicted TransactionPrice (RM): 884759.0436794609\n",
            "Difference (RNN - GRU, RM): -25910.19371025067\n",
            "Difference (RNN - Transformer, RM): -884621.7925015669\n",
            "Difference (GRU - Transformer, RM): -858711.5987913163\n",
            "\n",
            "Sample: {'SchemeName': 'The Edge', 'ParcelArea': 80.0, 'Year': 2025.0, 'Mukim': 'Mukim Setapak', 'Tenure': 'Freehold', 'UnitLevel': 25}\n",
            "Year capped to 2025.0 (training range: 20212025)\n",
            "Raw Scheme_Name_encoded: 13.317193031311035 (log-scale, mean=13.3172)\n",
            "UnitLevel_clean: 25.0, UnitLevel_binned: High\n",
            "Year before scaling: [0.000e+00 5.000e-01 2.025e+03]\n",
            "Preprocessed X_sample:\n",
            " [[ 1.3972817e-01 -7.2834879e-01 -1.0115000e+03  1.0000000e+00\n",
            "   4.3944492e+00  0.0000000e+00  1.0000000e+00  7.6628447e-01]\n",
            " [ 1.3972817e-01 -7.2834879e-01 -1.0112500e+03  1.0000000e+00\n",
            "   4.3944492e+00  0.0000000e+00  1.0000000e+00  7.6628447e-01]\n",
            " [ 1.3972817e-01 -7.2834879e-01  1.0000000e+00  1.0000000e+00\n",
            "   4.3944492e+00  0.0000000e+00  1.0000000e+00  7.6628447e-01]]\n",
            "RNN Predicted TransactionPrice (log-scale): 4.940643091483755\n",
            "RNN Predicted TransactionPrice (RM): 138.8601635255313\n",
            "GRU Predicted TransactionPrice (log-scale): 10.177854393298237\n",
            "GRU Predicted TransactionPrice (RM): 26312.947302911496\n",
            "Transformer Predicted TransactionPrice (log-scale): 13.693038534513894\n",
            "Transformer Predicted TransactionPrice (RM): 884729.6563083596\n",
            "Difference (RNN - GRU, RM): -26174.087139385963\n",
            "Difference (RNN - Transformer, RM): -884590.796144834\n",
            "Difference (GRU - Transformer, RM): -858416.709005448\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import RobustScaler, StandardScaler\n",
        "from sklearn.metrics import r2_score, mean_squared_error\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, SimpleRNN, GRU, Dense, Layer, MultiHeadAttention, LayerNormalization, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "import joblib\n",
        "\n",
        "# Load data\n",
        "url = \"https://raw.githubusercontent.com/englian1123/KL-High-Rise-Data/refs/heads/main/KLHighRise.csv\"\n",
        "df = pd.read_csv(url)\n",
        "df.rename(columns={'TransactionPrice  ': 'TransactionPrice', 'Parcel Area': 'ParcelArea', 'Scheme Name/Area': 'SchemeName'}, inplace=True)\n",
        "df['ParcelArea'] = df['ParcelArea'].astype(str).str.extract('(\\d+\\.?\\d*)').astype(np.float32)\n",
        "df['Tenure'] = df['Tenure'].map({'Freehold': 1, 'Leasehold': 0}).fillna(0).astype(np.float32)\n",
        "\n",
        "# Outlier capping (only ParcelArea)\n",
        "area_cap = df['ParcelArea'].quantile(0.90)\n",
        "df['ParcelArea'] = np.clip(df['ParcelArea'], 0, area_cap).astype(np.float32)\n",
        "\n",
        "# Log-transform\n",
        "df['TransactionPrice'] = np.log1p(df['TransactionPrice']).astype(np.float32)\n",
        "df['ParcelArea'] = np.log1p(df['ParcelArea']).astype(np.float32)\n",
        "\n",
        "# Target encode SchemeName\n",
        "scheme_encoding = df.groupby('SchemeName')['TransactionPrice'].mean().astype(np.float32)\n",
        "df['Scheme_Name_encoded'] = df['SchemeName'].map(scheme_encoding).fillna(scheme_encoding.mean()).astype(np.float32)\n",
        "joblib.dump(scheme_encoding, 'scheme_encoding_rnn_gru_transformer_v9.joblib')\n",
        "\n",
        "# Add Year and pre-scale\n",
        "df['TransactionDate'] = pd.to_datetime(df['TransactionDate'], format='%b-%y')\n",
        "df['Year'] = df['TransactionDate'].dt.year.astype(np.float32)\n",
        "df['Year'] = (df['Year'] - 2023) / 2.0\n",
        "\n",
        "# Clean UnitLevel\n",
        "unit_level_map = {'03A': 4, '12B': 12, '13A': 14, '23A': 24, '33A': 34, '43A': 44, '53A': 54,\n",
        "                  'B': 0, 'D': 0, 'G': 0, 'LG': 0, 'MZ': 0, 'P': 0, 'UG': 0,\n",
        "                  '1/5/2025': 0, '2/3/2025': 0, '1/4/2025': 0}\n",
        "df['UnitLevel_clean'] = df['UnitLevel'].replace(unit_level_map)\n",
        "unit_level_mean = pd.to_numeric(df['UnitLevel_clean'], errors='coerce').mean()\n",
        "df['UnitLevel_clean'] = pd.to_numeric(df['UnitLevel_clean'], errors='coerce').fillna(unit_level_mean).astype(np.float32)\n",
        "df['UnitLevel_binned'] = pd.cut(df['UnitLevel_clean'], bins=[-float('inf'), 5, 15, 25, float('inf')], labels=['Low', 'Mid-Low', 'Mid-High', 'High'], right=False)\n",
        "level_dummies = pd.get_dummies(df['UnitLevel_binned'], prefix='UnitLevel', dtype=np.float32)\n",
        "\n",
        "# Setapak interactions\n",
        "mukim_dummies = pd.get_dummies(df['Mukim'], prefix='Mukim', dtype=np.float32)\n",
        "df['Mukim_Mukim Setapak_Tenure'] = (mukim_dummies.get('Mukim_Mukim Setapak', pd.Series(0, index=df.index)) * df['Tenure']).astype(np.float32)\n",
        "df['Mukim_Mukim Setapak_ParcelArea'] = (mukim_dummies.get('Mukim_Mukim Setapak', pd.Series(0, index=df.index)) * df['ParcelArea']).astype(np.float32)\n",
        "df['ParcelArea_UnitLevel'] = (df['ParcelArea'] * df['UnitLevel_clean']).astype(np.float32)\n",
        "\n",
        "# Features\n",
        "features = ['Scheme_Name_encoded', 'ParcelArea', 'Year', 'Mukim_Mukim Setapak_Tenure', 'Mukim_Mukim Setapak_ParcelArea', 'UnitLevel_Mid-High', 'UnitLevel_High', 'ParcelArea_UnitLevel']\n",
        "X = pd.concat([df[['Scheme_Name_encoded', 'ParcelArea', 'Year', 'ParcelArea_UnitLevel']],\n",
        "               df[['Mukim_Mukim Setapak_Tenure', 'Mukim_Mukim Setapak_ParcelArea']],\n",
        "               level_dummies[['UnitLevel_Mid-High', 'UnitLevel_High']]], axis=1).astype(np.float32)\n",
        "y = df['TransactionPrice'].astype(np.float32)\n",
        "\n",
        "# Standardize target\n",
        "y_scaler = StandardScaler()\n",
        "y = y_scaler.fit_transform(y.values.reshape(-1, 1)).flatten().astype(np.float32)\n",
        "joblib.dump(y_scaler, 'y_scaler_rnn_gru_transformer_v9.joblib')\n",
        "print(\"y_scaler mean:\", y_scaler.mean_, \"y_scaler scale:\", y_scaler.scale_)\n",
        "\n",
        "# Create sequences (3 timesteps)\n",
        "sequence_length = 3\n",
        "X_seq = []\n",
        "y_seq = []\n",
        "for idx in range(len(X)):\n",
        "    year = X.iloc[idx]['Year']  # Already pre-scaled\n",
        "    sample = X.iloc[idx][features].values\n",
        "    seq = np.zeros((sequence_length, len(features)), dtype=np.float32)\n",
        "    seq[-1] = sample  # Current year\n",
        "    for t in range(1, sequence_length):\n",
        "        prev_year = year * 2.0 + 2023 - t  # Reverse scaling to get original year\n",
        "        if prev_year >= 2021:\n",
        "            seq[sequence_length - t - 1] = sample.copy()\n",
        "            seq[sequence_length - t - 1][2] = (prev_year - 2023) / 2.0\n",
        "    X_seq.append(seq)\n",
        "    y_seq.append(y[idx])\n",
        "X_seq = np.array(X_seq)\n",
        "y_seq = np.array(y_seq)\n",
        "\n",
        "# Split data\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_seq, y_seq, test_size=0.2, random_state=42)\n",
        "\n",
        "# Scale features\n",
        "scaler = RobustScaler()\n",
        "for t in range(sequence_length):\n",
        "    X_train[:, t, [0, 1, 2, 7]] = scaler.fit_transform(X_train[:, t, [0, 1, 2, 7]]).astype(np.float32)\n",
        "    X_test[:, t, [0, 1, 2, 7]] = scaler.transform(X_test[:, t, [0, 1, 2, 7]]).astype(np.float32)\n",
        "joblib.dump(scaler, 'scaler_rnn_gru_transformer_v9.joblib')\n",
        "print(\"Scaler center:\", scaler.center_, \"Scaler scale:\", scaler.scale_)\n",
        "\n",
        "# RNN Model\n",
        "inputs = Input(shape=(sequence_length, len(features)))\n",
        "x = SimpleRNN(512, return_sequences=True, kernel_regularizer=tf.keras.regularizers.l2(0.06))(inputs)\n",
        "x = SimpleRNN(256, return_sequences=False, kernel_regularizer=tf.keras.regularizers.l2(0.06))(x)\n",
        "x = Dropout(0.8)(x)\n",
        "x = Dense(128, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.06))(x)\n",
        "x = Dropout(0.8)(x)\n",
        "outputs = Dense(1)(x)\n",
        "rnn_model = Model(inputs, outputs)\n",
        "rnn_model.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n",
        "rnn_model.fit(X_train, y_train, epochs=200, batch_size=32, validation_data=(X_test, y_test),\n",
        "              callbacks=[tf.keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True),\n",
        "                         ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-5)], verbose=0)\n",
        "joblib.dump(rnn_model, 'rnn_model_v9.joblib')\n",
        "\n",
        "# GRU Model\n",
        "x = GRU(512, return_sequences=True, kernel_regularizer=tf.keras.regularizers.l2(0.06))(inputs)\n",
        "x = GRU(256, return_sequences=False, kernel_regularizer=tf.keras.regularizers.l2(0.06))(x)\n",
        "x = Dropout(0.8)(x)\n",
        "x = Dense(128, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.06))(x)\n",
        "x = Dropout(0.8)(x)\n",
        "outputs = Dense(1)(x)\n",
        "gru_model = Model(inputs, outputs)\n",
        "gru_model.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n",
        "gru_model.fit(X_train, y_train, epochs=200, batch_size=32, validation_data=(X_test, y_test),\n",
        "              callbacks=[tf.keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True),\n",
        "                         ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-5)], verbose=0)\n",
        "joblib.dump(gru_model, 'gru_model_v9.joblib')\n",
        "\n",
        "# Transformer Model\n",
        "class TransformerBlock(Layer):\n",
        "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.8):\n",
        "        super(TransformerBlock, self).__init__()\n",
        "        self.att = MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.ffn = tf.keras.Sequential([Dense(ff_dim, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.06)),\n",
        "                                        Dense(embed_dim)])\n",
        "        self.layernorm1 = LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = LayerNormalization(epsilon=1e-6)\n",
        "        self.dropout1 = Dropout(rate)\n",
        "        self.dropout2 = Dropout(rate)\n",
        "    def call(self, inputs, training=False):\n",
        "        attn_output = self.att(inputs, inputs)\n",
        "        attn_output = self.dropout1(attn_output, training=training)\n",
        "        out1 = self.layernorm1(inputs + attn_output)\n",
        "        ffn_output = self.ffn(out1)\n",
        "        ffn_output = self.dropout2(ffn_output, training=training)\n",
        "        return self.layernorm2(out1 + ffn_output)\n",
        "\n",
        "class PositionalEncoding(Layer):\n",
        "    def __init__(self, sequence_length, embed_dim):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        pos_enc = np.array([[pos / np.power(10000, 2 * (i // 2) / embed_dim) for i in range(embed_dim)] for pos in range(sequence_length)])\n",
        "        pos_enc[:, 0::2] = np.sin(pos_enc[:, 0::2])\n",
        "        pos_enc[:, 1::2] = np.cos(pos_enc[:, 1::2])\n",
        "        self.pos_encoding = tf.cast(pos_enc, dtype=tf.float32)\n",
        "    def call(self, inputs):\n",
        "        return inputs + self.pos_encoding\n",
        "\n",
        "inputs = Input(shape=(sequence_length, len(features)))\n",
        "x = PositionalEncoding(sequence_length, len(features))(inputs)\n",
        "x = TransformerBlock(embed_dim=len(features), num_heads=8, ff_dim=256)(x, training=True)\n",
        "x = TransformerBlock(embed_dim=len(features), num_heads=8, ff_dim=256)(x, training=True)\n",
        "x = TransformerBlock(embed_dim=len(features), num_heads=8, ff_dim=256)(x, training=True)\n",
        "x = TransformerBlock(embed_dim=len(features), num_heads=8, ff_dim=256)(x, training=True)\n",
        "x = tf.keras.layers.GlobalAveragePooling1D()(x)\n",
        "x = Dense(128, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.06))(x)\n",
        "x = Dropout(0.8)(x)\n",
        "outputs = Dense(1)(x)\n",
        "transformer_model = Model(inputs, outputs)\n",
        "transformer_model.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n",
        "transformer_model.fit(X_train, y_train, epochs=200, batch_size=32, validation_data=(X_test, y_test),\n",
        "                     callbacks=[tf.keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True),\n",
        "                                ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-5)], verbose=0)\n",
        "joblib.dump(transformer_model, 'transformer_model_v9.joblib')\n",
        "\n",
        "# Evaluate models\n",
        "y_pred_rnn = rnn_model.predict(X_test, verbose=0).flatten()\n",
        "y_pred_rnn_log = y_scaler.inverse_transform(y_pred_rnn.reshape(-1, 1)).flatten()\n",
        "y_test_log = y_scaler.inverse_transform(y_test.reshape(-1, 1)).flatten()\n",
        "rnn_r2 = r2_score(y_test_log, y_pred_rnn_log)\n",
        "rnn_rmse_log = np.sqrt(mean_squared_error(y_test_log, y_pred_rnn_log))\n",
        "rnn_rmse_rm = np.sqrt(mean_squared_error(np.expm1(y_test_log), np.expm1(y_pred_rnn_log)))\n",
        "print(\"RNN y_pred_log (sample):\", y_pred_rnn_log[:5])\n",
        "print(\"RNN y_test_log (sample):\", y_test_log[:5])\n",
        "\n",
        "y_pred_gru = gru_model.predict(X_test, verbose=0).flatten()\n",
        "y_pred_gru_log = y_scaler.inverse_transform(y_pred_gru.reshape(-1, 1)).flatten()\n",
        "gru_r2 = r2_score(y_test_log, y_pred_gru_log)\n",
        "gru_rmse_log = np.sqrt(mean_squared_error(y_test_log, y_pred_gru_log))\n",
        "gru_rmse_rm = np.sqrt(mean_squared_error(np.expm1(y_test_log), np.expm1(y_pred_gru_log)))\n",
        "print(\"GRU y_pred_log (sample):\", y_pred_gru_log[:5])\n",
        "\n",
        "y_pred_transformer = transformer_model.predict(X_test, verbose=0).flatten()\n",
        "y_pred_transformer_log = y_scaler.inverse_transform(y_pred_transformer.reshape(-1, 1)).flatten()\n",
        "transformer_r2 = r2_score(y_test_log, y_pred_transformer_log)\n",
        "transformer_rmse_log = np.sqrt(mean_squared_error(y_test_log, y_pred_transformer_log))\n",
        "transformer_rmse_rm = np.sqrt(mean_squared_error(np.expm1(y_test_log), np.expm1(y_pred_transformer_log)))\n",
        "print(\"Transformer y_pred_log (sample):\", y_pred_transformer_log[:5])\n",
        "\n",
        "print(\"RNN R:\", rnn_r2)\n",
        "print(\"RNN RMSE (log-scale):\", rnn_rmse_log)\n",
        "print(\"RNN RMSE (RM):\", rnn_rmse_rm)\n",
        "print(\"GRU R:\", gru_r2)\n",
        "print(\"GRU RMSE (log-scale):\", gru_rmse_log)\n",
        "print(\"GRU RMSE (RM):\", gru_rmse_rm)\n",
        "print(\"Transformer R:\", transformer_r2)\n",
        "print(\"Transformer RMSE (log-scale):\", transformer_rmse_log)\n",
        "print(\"Transformer RMSE (RM):\", transformer_rmse_rm)\n",
        "\n",
        "# Preprocessing function for samples\n",
        "def preprocess_sample(sample, scheme_encoding, scaler, y_scaler, features, area_cap, year_max=2025.0, sequence_length=3):\n",
        "    df_sample = pd.DataFrame([sample])\n",
        "    df_sample['Year'] = np.clip(df_sample['Year'], 2021.0, year_max).astype(np.float32)\n",
        "    df_sample['Year'] = (df_sample['Year'] - 2023) / 2.0  # Pre-scale Year\n",
        "    print(f\"\\nSample: {sample}\")\n",
        "    print(f\"Year capped to {df_sample['Year'].iloc[0] * 2.0 + 2023} (training range: 20212025)\")\n",
        "    df_sample['ParcelArea'] = np.log1p(np.clip(df_sample['ParcelArea'], 0, area_cap)).astype(np.float32)\n",
        "    raw_scheme_encoding = df_sample['SchemeName'].map(scheme_encoding).fillna(scheme_encoding.mean()).astype(np.float32)\n",
        "    print(f\"Raw Scheme_Name_encoded: {raw_scheme_encoding.iloc[0]} (log-scale, mean={scheme_encoding.mean():.4f})\")\n",
        "    df_sample['Scheme_Name_encoded'] = raw_scheme_encoding\n",
        "    df_sample['Tenure'] = df_sample['Tenure'].map({'Freehold': 1, 'Leasehold': 0}).fillna(0).astype(np.float32)\n",
        "    unit_level_map = {'03A': 4, '12B': 12, '13A': 14, '23A': 24, '33A': 34, '43A': 44, '53A': 54,\n",
        "                      'B': 0, 'D': 0, 'G': 0, 'LG': 0, 'MZ': 0, 'P': 0, 'UG': 0,\n",
        "                      '1/5/2025': 0, '2/3/2025': 0, '1/4/2025': 0}\n",
        "    df_sample['UnitLevel_clean'] = df_sample['UnitLevel'].replace(unit_level_map)\n",
        "    df_sample['UnitLevel_clean'] = pd.to_numeric(df_sample['UnitLevel_clean'], errors='coerce').fillna(10.0).astype(np.float32)\n",
        "    df_sample['UnitLevel_binned'] = pd.cut(df_sample['UnitLevel_clean'], bins=[-float('inf'), 5, 15, 25, float('inf')], labels=['Low', 'Mid-Low', 'Mid-High', 'High'], right=False)\n",
        "    print(f\"UnitLevel_clean: {df_sample['UnitLevel_clean'].iloc[0]}, UnitLevel_binned: {df_sample['UnitLevel_binned'].iloc[0]}\")\n",
        "    level_dummies = pd.get_dummies(df_sample['UnitLevel_binned'], prefix='UnitLevel', dtype=np.float32)\n",
        "    if 'UnitLevel_Mid-High' not in level_dummies:\n",
        "        level_dummies['UnitLevel_Mid-High'] = 0.0\n",
        "    if 'UnitLevel_High' not in level_dummies:\n",
        "        level_dummies['UnitLevel_High'] = 0.0\n",
        "    level_dummies = level_dummies[['UnitLevel_Mid-High', 'UnitLevel_High']].astype(np.float32)\n",
        "    df_sample['Mukim_Mukim Setapak_Tenure'] = (df_sample['Mukim'].eq('Mukim Setapak').astype(np.float32) * df_sample['Tenure']).astype(np.float32)\n",
        "    df_sample['Mukim_Mukim Setapak_ParcelArea'] = (df_sample['Mukim'].eq('Mukim Setapak').astype(np.float32) * df_sample['ParcelArea']).astype(np.float32)\n",
        "    df_sample['ParcelArea_UnitLevel'] = (df_sample['ParcelArea'] * df_sample['UnitLevel_clean']).astype(np.float32)\n",
        "    X_sample = pd.concat([df_sample[['Scheme_Name_encoded', 'ParcelArea', 'Year', 'ParcelArea_UnitLevel']],\n",
        "                          df_sample[['Mukim_Mukim Setapak_Tenure', 'Mukim_Mukim Setapak_ParcelArea']],\n",
        "                          level_dummies[['UnitLevel_Mid-High', 'UnitLevel_High']]], axis=1).astype(np.float32)\n",
        "    X_sample_seq = np.zeros((1, sequence_length, len(features)), dtype=np.float32)\n",
        "    X_sample_seq[0, -1] = X_sample[features].values\n",
        "    for t in range(1, sequence_length):\n",
        "        prev_year = (df_sample['Year'].iloc[0] * 2.0 + 2023) - t\n",
        "        if prev_year >= 2021:\n",
        "            X_sample_seq[0, sequence_length - t - 1] = X_sample[features].values\n",
        "            X_sample_seq[0, sequence_length - t - 1, 2] = (prev_year - 2023) / 2.0\n",
        "    print(\"Year before scaling:\", X_sample_seq[0, :, 2])\n",
        "    X_sample_seq[:, :, [0, 1, 2, 7]] = scaler.transform(X_sample_seq[:, :, [0, 1, 2, 7]].reshape(-1, 4)).reshape(1, sequence_length, 4)\n",
        "    print(\"Year after scaling:\", X_sample_seq[0, :, 2])\n",
        "    print(\"Preprocessed X_sample:\\n\", X_sample_seq[0])\n",
        "    return X_sample_seq\n",
        "\n",
        "# Define sample inputs\n",
        "sample_inputs = [\n",
        "    {'SchemeName': 'The Edge', 'ParcelArea': 80.0, 'Year': 2025.0, 'Mukim': 'Mukim Setapak', 'Tenure': 'Freehold', 'UnitLevel': 15},\n",
        "    {'SchemeName': 'The Edge', 'ParcelArea': 80.0, 'Year': 2025.0, 'Mukim': 'Mukim Setapak', 'Tenure': 'Freehold', 'UnitLevel': 25}\n",
        "]\n",
        "\n",
        "# Predict for both inputs\n",
        "area_cap = 90.0\n",
        "features = ['Scheme_Name_encoded', 'ParcelArea', 'Year', 'Mukim_Mukim Setapak_Tenure', 'Mukim_Mukim Setapak_ParcelArea', 'UnitLevel_Mid-High', 'UnitLevel_High', 'ParcelArea_UnitLevel']\n",
        "for sample in sample_inputs:\n",
        "    X_sample = preprocess_sample(sample, scheme_encoding, scaler, y_scaler, features, area_cap)\n",
        "    y_pred_rnn = rnn_model.predict(X_sample, verbose=0).flatten()[0]\n",
        "    y_pred_rnn_log = y_scaler.inverse_transform([[y_pred_rnn]])[0, 0]\n",
        "    y_pred_rnn_rm = np.expm1(y_pred_rnn_log)\n",
        "    print(\"RNN y_pred (scaled):\", y_pred_rnn, \"y_pred_log:\", y_pred_rnn_log, \"y_pred_rm:\", y_pred_rnn_rm)\n",
        "    y_pred_gru = gru_model.predict(X_sample, verbose=0).flatten()[0]\n",
        "    y_pred_gru_log = y_scaler.inverse_transform([[y_pred_gru]])[0, 0]\n",
        "    y_pred_gru_rm = np.expm1(y_pred_gru_log)\n",
        "    print(\"GRU y_pred (scaled):\", y_pred_gru, \"y_pred_log:\", y_pred_gru_log, \"y_pred_rm:\", y_pred_gru_rm)\n",
        "    y_pred_transformer = transformer_model.predict(X_sample, verbose=0).flatten()[0]\n",
        "    y_pred_transformer_log = y_scaler.inverse_transform([[y_pred_transformer]])[0, 0]\n",
        "    y_pred_transformer_rm = np.expm1(y_pred_transformer_log)\n",
        "    print(\"Transformer y_pred (scaled):\", y_pred_transformer, \"y_pred_log:\", y_pred_transformer_log, \"y_pred_rm:\", y_pred_transformer_rm)\n",
        "    print(\"RNN Predicted TransactionPrice (log-scale):\", y_pred_rnn_log)\n",
        "    print(\"RNN Predicted TransactionPrice (RM):\", y_pred_rnn_rm)\n",
        "    print(\"GRU Predicted TransactionPrice (log-scale):\", y_pred_gru_log)\n",
        "    print(\"GRU Predicted TransactionPrice (RM):\", y_pred_gru_rm)\n",
        "    print(\"Transformer Predicted TransactionPrice (log-scale):\", y_pred_transformer_log)\n",
        "    print(\"Transformer Predicted TransactionPrice (RM):\", y_pred_transformer_rm)\n",
        "    print(\"Difference (RNN - GRU, RM):\", y_pred_rnn_rm - y_pred_gru_rm)\n",
        "    print(\"Difference (RNN - Transformer, RM):\", y_pred_rnn_rm - y_pred_transformer_rm)\n",
        "    print(\"Difference (GRU - Transformer, RM):\", y_pred_gru_rm - y_pred_transformer_rm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mKifQOY7IRJx",
        "outputId": "0b88d708-d354-467a-e424-d37d29caaa0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<>:16: SyntaxWarning: invalid escape sequence '\\d'\n",
            "<>:16: SyntaxWarning: invalid escape sequence '\\d'\n",
            "/tmp/ipython-input-355538090.py:16: SyntaxWarning: invalid escape sequence '\\d'\n",
            "  df['ParcelArea'] = df['ParcelArea'].astype(str).str.extract('(\\d+\\.?\\d*)').astype(np.float32)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "y_scaler mean: [13.38469146] y_scaler scale: [0.71261604]\n",
            "Scaler center: [13.185597   4.7004805  0.        57.549488 ] Scaler scale: [ 0.94179726  0.42017126  1.         68.26673889]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import RobustScaler, StandardScaler\n",
        "from sklearn.metrics import r2_score, mean_squared_error\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, SimpleRNN, GRU, Dense, Layer, MultiHeadAttention, LayerNormalization, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "import joblib\n",
        "\n",
        "# Load data\n",
        "url = \"https://raw.githubusercontent.com/englian1123/KL-High-Rise-Data/refs/heads/main/KLHighRise.csv\"\n",
        "df = pd.read_csv(url)\n",
        "df.rename(columns={'TransactionPrice  ': 'TransactionPrice', 'Parcel Area': 'ParcelArea', 'Scheme Name/Area': 'SchemeName'}, inplace=True)\n",
        "df['ParcelArea'] = df['ParcelArea'].astype(str).str.extract('(\\d+\\.?\\d*)').astype(np.float32)\n",
        "df['Tenure'] = df['Tenure'].map({'Freehold': 1, 'Leasehold': 0}).fillna(0).astype(np.float32)\n",
        "\n",
        "# Outlier capping (only ParcelArea)\n",
        "area_cap = df['ParcelArea'].quantile(0.90)\n",
        "df['ParcelArea'] = np.clip(df['ParcelArea'], 0, area_cap).astype(np.float32)\n",
        "\n",
        "# Log-transform\n",
        "df['TransactionPrice'] = np.log1p(df['TransactionPrice']).astype(np.float32)\n",
        "df['ParcelArea'] = np.log1p(df['ParcelArea']).astype(np.float32)\n",
        "\n",
        "# Target encode SchemeName\n",
        "scheme_encoding = df.groupby('SchemeName')['TransactionPrice'].mean().astype(np.float32)\n",
        "joblib.dump(scheme_encoding, 'scheme_encoding_rnn_gru_transformer_v10.joblib')\n",
        "df['Scheme_Name_encoded'] = df['SchemeName'].map(scheme_encoding).fillna(scheme_encoding.mean()).astype(np.float32)\n",
        "\n",
        "\n",
        "# Add Year and pre-scale\n",
        "df['TransactionDate'] = pd.to_datetime(df['TransactionDate'], format='%b-%y')\n",
        "df['Year'] = df['TransactionDate'].dt.year.astype(np.float32)\n",
        "df['Year'] = (df['Year'] - 2023) / 2.0\n",
        "\n",
        "# Clean UnitLevel\n",
        "unit_level_map = {'03A': 4, '12B': 12, '13A': 14, '23A': 24, '33A': 34, '43A': 44, '53A': 54,\n",
        "                  'B': 0, 'D': 0, 'G': 0, 'LG': 0, 'MZ': 0, 'P': 0, 'UG': 0,\n",
        "                  '1/5/2025': 0, '2/3/2025': 0, '1/4/2025': 0}\n",
        "df['UnitLevel_clean'] = df['UnitLevel'].replace(unit_level_map)\n",
        "unit_level_mean = pd.to_numeric(df['UnitLevel_clean'], errors='coerce').mean()\n",
        "df['UnitLevel_clean'] = pd.to_numeric(df['UnitLevel_clean'], errors='coerce').fillna(unit_level_mean).astype(np.float32)\n",
        "df['UnitLevel_binned'] = pd.cut(df['UnitLevel_clean'], bins=[-float('inf'), 5, 15, 25, float('inf')], labels=['Low', 'Mid-Low', 'Mid-High', 'High'], right=False)\n",
        "level_dummies = pd.get_dummies(df['UnitLevel_binned'], prefix='UnitLevel', dtype=np.float32)\n",
        "\n",
        "# Setapak interactions\n",
        "mukim_dummies = pd.get_dummies(df['Mukim'], prefix='Mukim', dtype=np.float32)\n",
        "df['Mukim_Mukim Setapak_Tenure'] = (mukim_dummies.get('Mukim_Mukim Setapak', pd.Series(0, index=df.index)) * df['Tenure']).astype(np.float32)\n",
        "df['Mukim_Mukim Setapak_ParcelArea'] = (mukim_dummies.get('Mukim_Mukim Setapak', pd.Series(0, index=df.index)) * df['ParcelArea']).astype(np.float32)\n",
        "df['ParcelArea_UnitLevel'] = (df['ParcelArea'] * df['UnitLevel_clean']).astype(np.float32)\n",
        "\n",
        "# Features\n",
        "features = ['Scheme_Name_encoded', 'ParcelArea', 'Year', 'Mukim_Mukim Setapak_Tenure', 'Mukim_Mukim Setapak_ParcelArea', 'UnitLevel_Mid-High', 'UnitLevel_High', 'ParcelArea_UnitLevel']\n",
        "X = pd.concat([df[['Scheme_Name_encoded', 'ParcelArea', 'Year', 'ParcelArea_UnitLevel']],\n",
        "               df[['Mukim_Mukim Setapak_Tenure', 'Mukim_Mukim Setapak_ParcelArea']],\n",
        "               level_dummies[['UnitLevel_Mid-High', 'UnitLevel_High']]], axis=1).astype(np.float32)\n",
        "y = df['TransactionPrice'].astype(np.float32)\n",
        "\n",
        "# Standardize target\n",
        "y_scaler = StandardScaler()\n",
        "y = y_scaler.fit_transform(y.values.reshape(-1, 1)).flatten().astype(np.float32)\n",
        "joblib.dump(y_scaler, 'y_scaler_rnn_gru_transformer_v10.joblib')\n",
        "print(\"y_scaler mean:\", y_scaler.mean_, \"y_scaler scale:\", y_scaler.scale_)\n",
        "\n",
        "# Create sequences (3 timesteps)\n",
        "sequence_length = 3\n",
        "X_seq = []\n",
        "y_seq = []\n",
        "for idx in range(len(X)):\n",
        "    year = X.iloc[idx]['Year']  # Already pre-scaled\n",
        "    sample = X.iloc[idx][features].values\n",
        "    seq = np.zeros((sequence_length, len(features)), dtype=np.float32)\n",
        "    seq[-1] = sample  # Current year\n",
        "    for t in range(1, sequence_length):\n",
        "        prev_year = year * 2.0 + 2023 - t  # Reverse scaling to get original year\n",
        "        if prev_year >= 2021:\n",
        "            seq[sequence_length - t - 1] = sample.copy()\n",
        "            seq[sequence_length - t - 1][2] = (prev_year - 2023) / 2.0\n",
        "    X_seq.append(seq)\n",
        "    y_seq.append(y[idx])\n",
        "X_seq = np.array(X_seq)\n",
        "y_seq = np.array(y_seq)\n",
        "\n",
        "# Split data\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_seq, y_seq, test_size=0.2, random_state=42)\n",
        "\n",
        "# Scale features\n",
        "scaler = RobustScaler()\n",
        "for t in range(sequence_length):\n",
        "    X_train[:, t, [0, 1, 2, 7]] = scaler.fit_transform(X_train[:, t, [0, 1, 2, 7]]).astype(np.float32)\n",
        "    X_test[:, t, [0, 1, 2, 7]] = scaler.transform(X_test[:, t, [0, 1, 2, 7]]).astype(np.float32)\n",
        "joblib.dump(scaler, 'scaler_rnn_gru_transformer_v10.joblib')\n",
        "print(\"Scaler center:\", scaler.center_, \"Scaler scale:\", scaler.scale_)\n",
        "\n",
        "# RNN Model\n",
        "inputs = Input(shape=(sequence_length, len(features)))\n",
        "x = SimpleRNN(512, return_sequences=True, kernel_regularizer=tf.keras.regularizers.l2(0.06))(inputs)\n",
        "x = SimpleRNN(256, return_sequences=False, kernel_regularizer=tf.keras.regularizers.l2(0.06))(x)\n",
        "x = Dropout(0.8)(x)\n",
        "x = Dense(128, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.06))(x)\n",
        "x = Dropout(0.8)(x)\n",
        "outputs = Dense(1)(x)\n",
        "rnn_model = Model(inputs, outputs)\n",
        "rnn_model.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n",
        "rnn_model.fit(X_train, y_train, epochs=200, batch_size=32, validation_data=(X_test, y_test),\n",
        "              callbacks=[tf.keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True),\n",
        "                         ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-5)], verbose=0)\n",
        "joblib.dump(rnn_model, 'rnn_model_v10.joblib')\n",
        "\n",
        "# GRU Model\n",
        "x = GRU(512, return_sequences=True, kernel_regularizer=tf.keras.regularizers.l2(0.06))(inputs)\n",
        "x = GRU(256, return_sequences=False, kernel_regularizer=tf.keras.regularizers.l2(0.06))(x)\n",
        "x = Dropout(0.8)(x)\n",
        "x = Dense(128, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.06))(x)\n",
        "x = Dropout(0.8)(x)\n",
        "outputs = Dense(1)(x)\n",
        "gru_model = Model(inputs, outputs)\n",
        "gru_model.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n",
        "gru_model.fit(X_train, y_train, epochs=200, batch_size=32, validation_data=(X_test, y_test),\n",
        "              callbacks=[tf.keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True),\n",
        "                         ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-5)], verbose=0)\n",
        "joblib.dump(gru_model, 'gru_model_v10.joblib')\n",
        "\n",
        "# Transformer Model\n",
        "class TransformerBlock(Layer):\n",
        "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.8):\n",
        "        super(TransformerBlock, self).__init__()\n",
        "        self.att = MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.ffn = tf.keras.Sequential([Dense(ff_dim, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.06)),\n",
        "                                        Dense(embed_dim)])\n",
        "        self.layernorm1 = LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = LayerNormalization(epsilon=1e-6)\n",
        "        self.dropout1 = Dropout(rate)\n",
        "        self.dropout2 = Dropout(rate)\n",
        "    def call(self, inputs, training=False):\n",
        "        attn_output = self.att(inputs, inputs)\n",
        "        attn_output = self.dropout1(attn_output, training=training)\n",
        "        out1 = self.layernorm1(inputs + attn_output)\n",
        "        ffn_output = self.ffn(out1)\n",
        "        ffn_output = self.dropout2(ffn_output, training=training)\n",
        "        return self.layernorm2(out1 + ffn_output)\n",
        "\n",
        "class PositionalEncoding(Layer):\n",
        "    def __init__(self, sequence_length, embed_dim):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        pos_enc = np.array([[pos / np.power(10000, 2 * (i // 2) / embed_dim) for i in range(embed_dim)] for pos in range(sequence_length)])\n",
        "        pos_enc[:, 0::2] = np.sin(pos_enc[:, 0::2])\n",
        "        pos_enc[:, 1::2] = np.cos(pos_enc[:, 1::2])\n",
        "        self.pos_encoding = tf.cast(pos_enc, dtype=tf.float32)\n",
        "    def call(self, inputs):\n",
        "        return inputs + self.pos_encoding\n",
        "\n",
        "inputs = Input(shape=(sequence_length, len(features)))\n",
        "x = PositionalEncoding(sequence_length, len(features))(inputs)\n",
        "x = TransformerBlock(embed_dim=len(features), num_heads=8, ff_dim=256)(x, training=True)\n",
        "x = TransformerBlock(embed_dim=len(features), num_heads=8, ff_dim=256)(x, training=True)\n",
        "x = TransformerBlock(embed_dim=len(features), num_heads=8, ff_dim=256)(x, training=True)\n",
        "x = TransformerBlock(embed_dim=len(features), num_heads=8, ff_dim=256)(x, training=True)\n",
        "x = tf.keras.layers.GlobalAveragePooling1D()(x)\n",
        "x = Dense(128, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.06))(x)\n",
        "x = Dropout(0.8)(x)\n",
        "outputs = Dense(1)(x)\n",
        "transformer_model = Model(inputs, outputs)\n",
        "transformer_model.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n",
        "transformer_model.fit(X_train, y_train, epochs=200, batch_size=32, validation_data=(X_test, y_test),\n",
        "                     callbacks=[tf.keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True),\n",
        "                                ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-5)], verbose=0)\n",
        "joblib.dump(transformer_model, 'transformer_model_v10.joblib')\n",
        "\n",
        "# Evaluate models\n",
        "y_pred_rnn = rnn_model.predict(X_test, verbose=0).flatten()\n",
        "y_pred_rnn_log = y_scaler.inverse_transform(y_pred_rnn.reshape(-1, 1)).flatten()\n",
        "y_test_log = y_scaler.inverse_transform(y_test.reshape(-1, 1)).flatten()\n",
        "rnn_r2 = r2_score(y_test_log, y_pred_rnn_log)\n",
        "rnn_rmse_log = np.sqrt(mean_squared_error(y_test_log, y_pred_rnn_log))\n",
        "rnn_rmse_rm = np.sqrt(mean_squared_error(np.expm1(y_test_log), np.expm1(y_pred_rnn_log)))\n",
        "print(\"RNN y_pred_log (sample):\", y_pred_rnn_log[:5])\n",
        "print(\"RNN y_test_log (sample):\", y_test_log[:5])\n",
        "\n",
        "y_pred_gru = gru_model.predict(X_test, verbose=0).flatten()\n",
        "y_pred_gru_log = y_scaler.inverse_transform(y_pred_gru.reshape(-1, 1)).flatten()\n",
        "gru_r2 = r2_score(y_test_log, y_pred_gru_log)\n",
        "gru_rmse_log = np.sqrt(mean_squared_error(y_test_log, y_pred_gru_log))\n",
        "gru_rmse_rm = np.sqrt(mean_squared_error(np.expm1(y_test_log), np.expm1(y_pred_gru_log)))\n",
        "print(\"GRU y_pred_log (sample):\", y_pred_gru_log[:5])\n",
        "\n",
        "y_pred_transformer = transformer_model.predict(X_test, verbose=0).flatten()\n",
        "y_pred_transformer_log = y_scaler.inverse_transform(y_pred_transformer.reshape(-1, 1)).flatten()\n",
        "transformer_r2 = r2_score(y_test_log, y_pred_transformer_log)\n",
        "transformer_rmse_log = np.sqrt(mean_squared_error(y_test_log, y_pred_transformer_log))\n",
        "transformer_rmse_rm = np.sqrt(mean_squared_error(np.expm1(y_test_log), np.expm1(y_pred_transformer_log)))\n",
        "print(\"Transformer y_pred_log (sample):\", y_pred_transformer_log[:5])\n",
        "\n",
        "print(\"RNN R:\", rnn_r2)\n",
        "print(\"RNN RMSE (log-scale):\", rnn_rmse_log)\n",
        "print(\"RNN RMSE (RM):\", rnn_rmse_rm)\n",
        "print(\"GRU R:\", gru_r2)\n",
        "print(\"GRU RMSE (log-scale):\", gru_rmse_log)\n",
        "print(\"GRU RMSE (RM):\", gru_rmse_rm)\n",
        "print(\"Transformer R:\", transformer_r2)\n",
        "print(\"Transformer RMSE (log-scale):\", transformer_rmse_log)\n",
        "print(\"Transformer RMSE (RM):\", transformer_rmse_rm)\n",
        "\n",
        "# Preprocessing function for samples\n",
        "def preprocess_sample(sample, scheme_encoding, scaler, y_scaler, features, area_cap, year_max=2025.0, sequence_length=3):\n",
        "    df_sample = pd.DataFrame([sample])\n",
        "    df_sample['Year'] = np.clip(df_sample['Year'], 2021.0, year_max).astype(np.float32)\n",
        "    df_sample['Year'] = (df_sample['Year'] - 2023) / 2.0  # Pre-scale Year\n",
        "    print(f\"\\nSample: {sample}\")\n",
        "    print(f\"Year capped to {df_sample['Year'].iloc[0] * 2.0 + 2023} (training range: 20212025)\")\n",
        "    df_sample['ParcelArea'] = np.log1p(np.clip(df_sample['ParcelArea'], 0, area_cap)).astype(np.float32)\n",
        "    raw_scheme_encoding = df_sample['SchemeName'].map(scheme_encoding).fillna(scheme_encoding.mean()).astype(np.float32)\n",
        "    print(f\"Raw Scheme_Name_encoded: {raw_scheme_encoding.iloc[0]} (log-scale, mean={scheme_encoding.mean():.4f})\")\n",
        "    df_sample['Scheme_Name_encoded'] = raw_scheme_encoding\n",
        "    df_sample['Tenure'] = df_sample['Tenure'].map({'Freehold': 1, 'Leasehold': 0}).fillna(0).astype(np.float32)\n",
        "    unit_level_map = {'03A': 4, '12B': 12, '13A': 14, '23A': 24, '33A': 34, '43A': 44, '53A': 54,\n",
        "                      'B': 0, 'D': 0, 'G': 0, 'LG': 0, 'MZ': 0, 'P': 0, 'UG': 0,\n",
        "                      '1/5/2025': 0, '2/3/2025': 0, '1/4/2025': 0}\n",
        "    df_sample['UnitLevel_clean'] = df_sample['UnitLevel'].replace(unit_level_map)\n",
        "    df_sample['UnitLevel_clean'] = pd.to_numeric(df_sample['UnitLevel_clean'], errors='coerce').fillna(10.0).astype(np.float32)\n",
        "    df_sample['UnitLevel_binned'] = pd.cut(df_sample['UnitLevel_clean'], bins=[-float('inf'), 5, 15, 25, float('inf')], labels=['Low', 'Mid-Low', 'Mid-High', 'High'], right=False)\n",
        "    print(f\"UnitLevel_clean: {df_sample['UnitLevel_clean'].iloc[0]}, UnitLevel_binned: {df_sample['UnitLevel_binned'].iloc[0]}\")\n",
        "    level_dummies = pd.get_dummies(df_sample['UnitLevel_binned'], prefix='UnitLevel', dtype=np.float32)\n",
        "    if 'UnitLevel_Mid-High' not in level_dummies:\n",
        "        level_dummies['UnitLevel_Mid-High'] = 0.0\n",
        "    if 'UnitLevel_High' not in level_dummies:\n",
        "        level_dummies['UnitLevel_High'] = 0.0\n",
        "    level_dummies = level_dummies[['UnitLevel_Mid-High', 'UnitLevel_High']].astype(np.float32)\n",
        "    df_sample['Mukim_Mukim Setapak_Tenure'] = (df_sample['Mukim'].eq('Mukim Setapak').astype(np.float32) * df_sample['Tenure']).astype(np.float32)\n",
        "    df_sample['Mukim_Mukim Setapak_ParcelArea'] = (df_sample['Mukim'].eq('Mukim Setapak').astype(np.float32) * df_sample['ParcelArea']).astype(np.float32)\n",
        "    df_sample['ParcelArea_UnitLevel'] = (df_sample['ParcelArea'] * df_sample['UnitLevel_clean']).astype(np.float32)\n",
        "    X_sample = pd.concat([df_sample[['Scheme_Name_encoded', 'ParcelArea', 'Year', 'ParcelArea_UnitLevel']],\n",
        "                          df_sample[['Mukim_Mukim Setapak_Tenure', 'Mukim_Mukim Setapak_ParcelArea']],\n",
        "                          level_dummies[['UnitLevel_Mid-High', 'UnitLevel_High']]], axis=1).astype(np.float32)\n",
        "    X_sample_seq = np.zeros((1, sequence_length, len(features)), dtype=np.float32)\n",
        "    X_sample_seq[0, -1] = X_sample[features].values\n",
        "    for t in range(1, sequence_length):\n",
        "        prev_year = (df_sample['Year'].iloc[0] * 2.0 + 2023) - t\n",
        "        if prev_year >= 2021:\n",
        "            X_sample_seq[0, sequence_length - t - 1] = X_sample[features].values\n",
        "            X_sample_seq[0, sequence_length - t - 1, 2] = (prev_year - 2023) / 2.0\n",
        "    print(\"Year before scaling:\", X_sample_seq[0, :, 2])\n",
        "    X_sample_seq[:, :, [0, 1, 2, 7]] = scaler.transform(X_sample_seq[:, :, [0, 1, 2, 7]].reshape(-1, 4)).reshape(1, sequence_length, 4)\n",
        "    print(\"Year after scaling:\", X_sample_seq[0, :, 2])\n",
        "    print(\"Preprocessed X_sample:\\n\", X_sample_seq[0])\n",
        "    return X_sample_seq\n",
        "\n",
        "# Load saved models and preprocessing objects\n",
        "rnn_model = joblib.load('rnn_model_v9.joblib')\n",
        "gru_model = joblib.load('gru_model_v9.joblib')\n",
        "transformer_model = joblib.load('transformer_model_v9.joblib')\n",
        "scaler = joblib.load('scaler_rnn_gru_transformer_v10.joblib') # Note: Using scaler from v10 as it was the last successful scaling\n",
        "y_scaler = joblib.load('y_scaler_rnn_gru_transformer_v10.joblib')\n",
        "scheme_encoding = joblib.load('scheme_encoding_rnn_gru_transformer_v10.joblib')\n",
        "\n",
        "\n",
        "# Define sample inputs\n",
        "sample_inputs = [\n",
        "    {'SchemeName': 'The Edge', 'ParcelArea': 80.0, 'Year': 2025.0, 'Mukim': 'Mukim Setapak', 'Tenure': 'Freehold', 'UnitLevel': 15},\n",
        "    {'SchemeName': 'The Edge', 'ParcelArea': 80.0, 'Year': 2025.0, 'Mukim': 'Mukim Setapak', 'Tenure': 'Freehold', 'UnitLevel': 25}\n",
        "]\n",
        "\n",
        "# Predict for both inputs\n",
        "area_cap = 90.0\n",
        "features = ['Scheme_Name_encoded', 'ParcelArea', 'Year', 'Mukim_Mukim Setapak_Tenure', 'Mukim_Mukim Setapak_ParcelArea', 'UnitLevel_Mid-High', 'UnitLevel_High', 'ParcelArea_UnitLevel']\n",
        "for sample in sample_inputs:\n",
        "    X_sample = preprocess_sample(sample, scheme_encoding, scaler, y_scaler, features, area_cap)\n",
        "    y_pred_rnn = rnn_model.predict(X_sample, verbose=0).flatten()[0]\n",
        "    y_pred_rnn_log = y_scaler.inverse_transform([[y_pred_rnn]])[0, 0]\n",
        "    y_pred_rnn_rm = np.expm1(y_pred_rnn_log)\n",
        "    print(\"RNN y_pred (scaled):\", y_pred_rnn, \"y_pred_log:\", y_pred_rnn_log, \"y_pred_rm:\", y_pred_rnn_rm)\n",
        "    y_pred_gru = gru_model.predict(X_sample, verbose=0).flatten()[0]\n",
        "    y_pred_gru_log = y_scaler.inverse_transform([[y_pred_gru]])[0, 0]\n",
        "    y_pred_gru_rm = np.expm1(y_pred_gru_log)\n",
        "    print(\"GRU y_pred (scaled):\", y_pred_gru, \"y_pred_log:\", y_pred_gru_log, \"y_pred_rm:\", y_pred_gru_rm)\n",
        "    y_pred_transformer = transformer_model.predict(X_sample, verbose=0).flatten()[0]\n",
        "    y_pred_transformer_log = y_scaler.inverse_transform([[y_pred_transformer]])[0, 0]\n",
        "    y_pred_transformer_rm = np.expm1(y_pred_transformer_log)\n",
        "    print(\"Transformer y_pred (scaled):\", y_pred_transformer, \"y_pred_log:\", y_pred_transformer_log, \"y_pred_rm:\", y_pred_transformer_rm)\n",
        "    print(\"RNN Predicted TransactionPrice (log-scale):\", y_pred_rnn_log)\n",
        "    print(\"RNN Predicted TransactionPrice (RM):\", y_pred_rnn_rm)\n",
        "    print(\"GRU Predicted TransactionPrice (log-scale):\", y_pred_gru_log)\n",
        "    print(\"GRU Predicted TransactionPrice (RM):\", y_pred_gru_rm)\n",
        "    print(\"Transformer Predicted TransactionPrice (log-scale):\", y_pred_transformer_log)\n",
        "    print(\"Transformer Predicted TransactionPrice (RM):\", y_pred_transformer_rm)\n",
        "    print(\"Difference (RNN - GRU, RM):\", y_pred_rnn_rm - y_pred_gru_rm)\n",
        "    print(\"Difference (RNN - Transformer, RM):\", y_pred_rnn_rm - y_pred_transformer_rm)\n",
        "    print(\"Difference (GRU - Transformer, RM):\", y_pred_gru_rm - y_pred_transformer_rm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "qA9laNfNnWpW",
        "outputId": "ec2f59e2-fc0f-4717-bf46-20d6456ed944"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<>:16: SyntaxWarning: invalid escape sequence '\\d'\n",
            "<>:16: SyntaxWarning: invalid escape sequence '\\d'\n",
            "/tmp/ipython-input-4030157872.py:16: SyntaxWarning: invalid escape sequence '\\d'\n",
            "  df['ParcelArea'] = df['ParcelArea'].astype(str).str.extract('(\\d+\\.?\\d*)').astype(np.float32)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "y_scaler mean: [13.38469146] y_scaler scale: [0.71261604]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"/tmp/ipython-input-4030157872.py\", line 73, in <cell line: 0>\n",
            "    sample = X.iloc[idx][features].values\n",
            "             ~~~~~~~~~~~^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pandas/core/series.py\", line 1153, in __getitem__\n",
            "    return self._get_with(key)\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pandas/core/series.py\", line 1172, in _get_with\n",
            "    key_type = lib.infer_dtype(key, skipna=False)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"lib.pyx\", line 1610, in pandas._libs.lib.infer_dtype\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pandas/core/dtypes/cast.py\", line 1600, in construct_1d_object_array_from_listlike\n",
            "    result = np.empty(len(values), dtype=\"object\")\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
            "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
            "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/inspect.py\", line 1769, in getinnerframes\n",
            "    traceback_info = getframeinfo(tb, context)\n",
            "                     ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/inspect.py\", line 1714, in getframeinfo\n",
            "    filename = getsourcefile(frame) or getfile(frame)\n",
            "               ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/inspect.py\", line 970, in getsourcefile\n",
            "    module = getmodule(object, filename)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/inspect.py\", line 1016, in getmodule\n",
            "    os.path.realpath(f)] = module.__name__\n",
            "    ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"<frozen posixpath>\", line 427, in realpath\n",
            "  File \"<frozen posixpath>\", line 469, in _joinrealpath\n",
            "  File \"<frozen posixpath>\", line 85, in join\n",
            "KeyboardInterrupt\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "object of type 'NoneType' has no len()",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-4030157872.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0myear\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Year'\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Already pre-scaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m     \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0mseq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1153\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_get_with\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1172\u001b[0;31m         \u001b[0mkey_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfer_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mlib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.infer_dtype\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/dtypes/cast.py\u001b[0m in \u001b[0;36mconstruct_1d_object_array_from_listlike\u001b[0;34m(values)\u001b[0m\n\u001b[1;32m   1599\u001b[0m     \u001b[0;31m# making a 1D array that contains list-likes is a bit tricky:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1600\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"object\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1601\u001b[0m     \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2098\u001b[0m                         \u001b[0;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2099\u001b[0;31m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2100\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'KeyboardInterrupt' object has no attribute '_render_traceback_'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2099\u001b[0m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2100\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2101\u001b[0;31m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0m\u001b[1;32m   2102\u001b[0m                                             value, tb, tb_offset=tb_offset)\n\u001b[1;32m   2103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1365\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1366\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1367\u001b[0;31m         return FormattedTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1368\u001b[0m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[1;32m   1369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1265\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose_modes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1266\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1267\u001b[0;31m             return VerboseTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1268\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1269\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1122\u001b[0m         \u001b[0;34m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1124\u001b[0;31m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0m\u001b[1;32m   1125\u001b[0m                                                                tb_offset)\n\u001b[1;32m   1126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1080\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m         \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[0;34m(etype, value, records)\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[0;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "# Load data\n",
        "url = \"https://raw.githubusercontent.com/englian1123/KL-High-Rise-Data/main/KLHighRise.csv\"\n",
        "df = pd.read_csv(url)\n",
        "df.rename(columns={'TransactionPrice  ': 'TransactionPrice', 'Parcel Area': 'ParcelArea', 'Scheme Name/Area': 'SchemeName'}, inplace=True)\n",
        "\n",
        "\n",
        "# Preprocess\n",
        "df = df[df['UnitLevel'].str.isnumeric() | (df['UnitLevel'] == 'G')]  # Drop non-numeric UnitLevel\n",
        "df['UnitLevel'] = df['UnitLevel'].replace('G', 0).astype(float)\n",
        "df['Price per sq.m'] = df['TransactionPrice'] / df['ParcelArea'] # Corrected 'Price' to 'TransactionPrice' and 'Parcel Area' to 'ParcelArea']\n",
        "\n",
        "# No outlier removal in this run\n",
        "\n",
        "# Continue preprocessing\n",
        "df['Tenure'] = df['Tenure'].map({'Freehold': 1, 'Leasehold': 0})\n",
        "mukim_dummies = pd.get_dummies(df['Mukim'], prefix='Mukim')\n",
        "\n",
        "# Target encoding for SchemeName\n",
        "global_mean = df['Price per sq.m'].mean()  # ~5,533\n",
        "m = 10  # Smoothing\n",
        "scheme_means = df.groupby('SchemeName')['Price per sq.m'].agg(['mean', 'count'])\n",
        "scheme_means['Encoded'] = (scheme_means['count'] * scheme_means['mean'] + m * global_mean) / (scheme_means['count'] + m)\n",
        "df = df.merge(scheme_means['Encoded'], left_on='SchemeName', right_index=True)\n",
        "\n",
        "# Convert TransactionDate to numerical (Year)\n",
        "df['TransactionDate'] = pd.to_datetime(df['TransactionDate'], format='%b-%y').dt.year.astype(float)\n",
        "\n",
        "\n",
        "# Features and target\n",
        "features = ['ParcelArea', 'UnitLevel', 'TransactionDate', 'Tenure', 'Encoded']\n",
        "X = pd.concat([df[features], mukim_dummies], axis=1)\n",
        "y = df['Price per sq.m']\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)  # Validation split\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_val_scaled = scaler.transform(X_val)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Convert to PyTorch tensors\n",
        "X_train_t = torch.tensor(X_train_scaled, dtype=torch.float32).unsqueeze(1)  # (batch, seq_len=1, features)\n",
        "y_train_t = torch.tensor(y_train.values, dtype=torch.float32).view(-1, 1)\n",
        "X_val_t = torch.tensor(X_val_scaled, dtype=torch.float32).unsqueeze(1)\n",
        "y_val_t = torch.tensor(y_val.values, dtype=torch.float32).view(-1, 1)\n",
        "X_test_t = torch.tensor(X_test_scaled, dtype=torch.float32).unsqueeze(1)\n",
        "y_test_t = torch.tensor(y_test.values, dtype=torch.float32).view(-1, 1)\n",
        "\n",
        "# Create DataLoader for mini-batch\n",
        "train_dataset = TensorDataset(X_train_t, y_train_t)\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "# Define Transformer model\n",
        "class TransformerRegressor(nn.Module):\n",
        "    def __init__(self, input_size, num_layers=1, num_heads=1, hidden_size=64, dropout=0.2): # Changed num_heads to 1\n",
        "        super(TransformerRegressor, self).__init__()\n",
        "        self.pos_encoder = nn.Parameter(torch.zeros(1, 1, input_size))  # Positional encoding\n",
        "        encoder_layer = nn.TransformerEncoderLayer(d_model=input_size, nhead=num_heads, dim_feedforward=hidden_size, dropout=dropout, batch_first=True)\n",
        "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
        "        self.fc = nn.Linear(input_size, 1)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.pos_encoder  # Add positional encoding\n",
        "        out = self.transformer_encoder(x)\n",
        "        out = self.relu(out.mean(dim=1))  # Mean pool over sequence\n",
        "        out = self.dropout(out)\n",
        "        out = self.fc(out)\n",
        "        return out\n",
        "\n",
        "# Initialize model\n",
        "input_size = X_train_scaled.shape[1]\n",
        "model = TransformerRegressor(input_size)\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0005)\n",
        "\n",
        "# Early stopping parameters\n",
        "patience = 10\n",
        "min_val_loss = float('inf')\n",
        "patience_counter = 0\n",
        "best_model_state = None\n",
        "\n",
        "# Train with mini-batch and early stopping\n",
        "epochs = 200\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    for X_batch, y_batch in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(X_batch)\n",
        "        loss = criterion(outputs, y_batch)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    # Validation loss\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        val_outputs = model(X_val_t)\n",
        "        val_loss = criterion(val_outputs, y_val_t).item()\n",
        "\n",
        "    if val_loss < min_val_loss:\n",
        "        min_val_loss = val_loss\n",
        "        best_model_state = model.state_dict()\n",
        "        patience_counter = 0\n",
        "    else:\n",
        "        patience_counter += 1\n",
        "        if patience_counter >= patience:\n",
        "            print(f\"Transformer Early stopping at epoch {epoch+1}\")\n",
        "            break\n",
        "\n",
        "# Load best model\n",
        "model.load_state_dict(best_model_state)\n",
        "\n",
        "# Evaluate on test set\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    y_pred = model(X_test_t)\n",
        "\n",
        "y_pred_np = y_pred.numpy().flatten()\n",
        "y_test_np = y_test_t.numpy().flatten()\n",
        "\n",
        "mse = mean_squared_error(y_test_np, y_pred_np)\n",
        "rmse = np.sqrt(mse)\n",
        "mae = mean_absolute_error(y_test_np, y_pred_np)\n",
        "r2 = r2_score(y_test_np, y_pred_np)\n",
        "print(f\"Transformer Metrics: MSE={mse:.0f}, RMSE={rmse:.0f}, MAE={mae:.0f}, R={r2:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UVQCeRCDqp0q",
        "outputId": "2a7061f8-bdc0-4de8-d6ff-0a1e8d5ecfc3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/transformer.py:392: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transformer Metrics: MSE=3637195, RMSE=1907, MAE=844, R=0.64\n"
          ]
        }
      ]
    }
  ]
}